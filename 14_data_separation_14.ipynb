{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14- data_separation_14.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfgkEDP8mC6-",
        "outputId": "e3fe6ad4-606a-47f3-b887-dec9e4488b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-19 22:04:01--  https://perso.esiee.fr/~gueurett/LV_Research/WS_analysis_results.csv\n",
            "Resolving perso.esiee.fr (perso.esiee.fr)... 147.215.150.8\n",
            "Connecting to perso.esiee.fr (perso.esiee.fr)|147.215.150.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 958567 (936K) [text/csv]\n",
            "Saving to: ‘WS_analysis_results.csv’\n",
            "\n",
            "WS_analysis_results 100%[===================>] 936.10K  1.86MB/s    in 0.5s    \n",
            "\n",
            "2022-07-19 22:04:02 (1.86 MB/s) - ‘WS_analysis_results.csv’ saved [958567/958567]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://perso.esiee.fr/~gueurett/LV_Research/WS_analysis_results_14.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://perso.esiee.fr/~gueurett/LV_Research/Acoustic_Analysis_Results.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA1d82j3mOCk",
        "outputId": "36075427-021e-4724-a570-097bbb4b161d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-19 22:04:04--  https://perso.esiee.fr/~gueurett/LV_Research/Acoustic_Analysis_Results.csv\n",
            "Resolving perso.esiee.fr (perso.esiee.fr)... 147.215.150.8\n",
            "Connecting to perso.esiee.fr (perso.esiee.fr)|147.215.150.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68157 (67K) [text/csv]\n",
            "Saving to: ‘Acoustic_Analysis_Results.csv’\n",
            "\n",
            "Acoustic_Analysis_R 100%[===================>]  66.56K   408KB/s    in 0.2s    \n",
            "\n",
            "2022-07-19 22:04:05 (408 KB/s) - ‘Acoustic_Analysis_Results.csv’ saved [68157/68157]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from keras import layers, initializers\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "5gxuIOKKmHhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prints = False\n",
        "\n",
        "data = pd.read_csv('WS_analysis_results_14.csv', delimiter=',', dtype=None, encoding=None)\n",
        "data = data.rename(columns={'MOMENTS': 'Filename'}) # rename the MOMENTS column to the filename column\n",
        "\n",
        "data_2 = pd.read_csv('Acoustic_Analysis_Results.csv', delimiter=',', dtype=None, encoding=None)\n",
        "data_2 = data_2.rename(columns={'Unnamed: 0': 'Filename'}) # rename the not-named column to the filename column\n",
        "data_2 = data_2.fillna(data_2.mean(numeric_only=True))\n",
        "\n",
        "n_samples = 200\n",
        "n_windows = 14\n",
        "n_features = 35\n",
        "\n",
        "dataset = np.ones(shape=(n_samples * n_windows, n_features))\n",
        "dataset_incr = np.ones(shape=(n_samples * (n_windows+1), n_features))\n",
        "labels  = np.zeros(shape=(n_samples * n_windows))\n",
        "labels_incr = np.zeros(shape=(n_samples * (n_windows+1)))\n",
        "\n",
        "for column_name in data.columns:\n",
        "  if column_name == 'Filename': continue\n",
        "  data[column_name] = (data[column_name] - np.mean(data[column_name])) / np.std(data[column_name])\n",
        "\n",
        "for column_name in data_2.columns:\n",
        "  if column_name == 'Filename': continue\n",
        "  data_2[column_name] = (data_2[column_name] - np.mean(data_2[column_name])) / np.std(data_2[column_name])\n",
        "\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "\n",
        "  filename = row['Filename'][:-4]\n",
        "  if prints: print(\"filename without wav: \", filename)\n",
        "\n",
        "  label, n_sample, n_part = filename.split('_')\n",
        "  n_sample = int(n_sample)\n",
        "  n_part   = int(n_part)\n",
        "\n",
        "  if prints:\n",
        "    print(\"label: \", label)\n",
        "    print(\"n_sample: \", n_sample)\n",
        "    print(\"n_part: \", n_part)\n",
        "\n",
        "  if label == 'I':\n",
        "    labels[index] = 1\n",
        "    labels_incr[index] = 1\n",
        "\n",
        "  row = data.iloc[index].to_numpy()[1:]\n",
        "  if prints:\n",
        "    print(\"row.shape: \", row.shape)\n",
        "    print(\"dataset.shape:  \", dataset.shape)\n",
        "    print(\"dataset[n_sample, n_part, :].shape:  \", dataset[n_sample, n_part, :].shape, '\\n\\n')\n",
        "  dataset[index, :] = row\n",
        "  dataset_incr[index, :] = row\n",
        "\n",
        "index += 1\n",
        "for index_data_2, row in data_2.iterrows():\n",
        "\n",
        "  label = row['Filename'][0]\n",
        "  if label == 'I':\n",
        "    labels_incr[index + index_data_2] = 1\n",
        "\n",
        "data_2 = data_2.drop(columns=['Filename'])\n",
        "data_2 = data_2.to_numpy()\n",
        "\n",
        "for index_data_2, features in enumerate(data_2):\n",
        "  dataset_incr[index + index_data_2] = features\n",
        "\n",
        "rng     = np.random.default_rng() # shuffle time\n",
        "shuffle = rng.choice(n_samples*n_windows, size=(n_samples * n_windows), replace=False)\n",
        "data    = dataset[shuffle]\n",
        "labels  = labels[shuffle]\n",
        "\n",
        "shuffle_incr = rng.choice(n_samples*(n_windows+1), size=(n_samples * (n_windows+1)), replace=False)\n",
        "data_incr    = dataset_incr[shuffle_incr]\n",
        "labels_incr  = labels_incr[shuffle_incr]\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "print(\"|  data.shape:   \", data.shape, \"   |\")\n",
        "print(\"|  labels.shape: \", labels.shape, \"      |\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"|  data_incr.shape:\", data_incr.shape, \" |\")\n",
        "print(\"|  labels.shape:   \", labels_incr.shape, \"    |\")\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtX5LcA9mJaE",
        "outputId": "cc16d78c-7f33-44f3-d5c6-57bbf600ccb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "|  data.shape:    (2800, 35)    |\n",
            "|  labels.shape:  (2800,)       |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "|  data_incr.shape: (3000, 35)  |\n",
            "|  labels.shape:    (3000,)     |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_things(history):\n",
        "  fig = plt.figure(figsize=(10, 8))\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(history.history['binary_accuracy'])\n",
        "  plt.plot(history.history['val_binary_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 8))\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FrtRbLA2mQyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(dropout_rate=0.3, nb_neurons=20):\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(nb_neurons, input_shape=(n_features,)))\n",
        "  model.add(layers.ReLU())\n",
        "  model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = Adam(0.001, beta_1=0.1)\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "mxXJiZnMmQ0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "history = model.fit(data, labels, epochs=100, validation_split=0.3, callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXxA7ETcmQ21",
        "outputId": "d8bc2f12-d8c3-43ac-b996-d88f43bde891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 1s 6ms/step - loss: 0.6474 - binary_accuracy: 0.6789 - val_loss: 0.5935 - val_binary_accuracy: 0.6885\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5661 - binary_accuracy: 0.7254 - val_loss: 0.5622 - val_binary_accuracy: 0.6944\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5300 - binary_accuracy: 0.7320 - val_loss: 0.5472 - val_binary_accuracy: 0.7051\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5155 - binary_accuracy: 0.7463 - val_loss: 0.5356 - val_binary_accuracy: 0.7182\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4965 - binary_accuracy: 0.7611 - val_loss: 0.5286 - val_binary_accuracy: 0.7241\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4739 - binary_accuracy: 0.7703 - val_loss: 0.5219 - val_binary_accuracy: 0.7277\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4662 - binary_accuracy: 0.7677 - val_loss: 0.5157 - val_binary_accuracy: 0.7337\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4574 - binary_accuracy: 0.7846 - val_loss: 0.5114 - val_binary_accuracy: 0.7384\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.7917 - val_loss: 0.5074 - val_binary_accuracy: 0.7515\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4363 - binary_accuracy: 0.7912 - val_loss: 0.5057 - val_binary_accuracy: 0.7503\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4314 - binary_accuracy: 0.8030 - val_loss: 0.5014 - val_binary_accuracy: 0.7562\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4225 - binary_accuracy: 0.8009 - val_loss: 0.4993 - val_binary_accuracy: 0.7551\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4271 - binary_accuracy: 0.7984 - val_loss: 0.4948 - val_binary_accuracy: 0.7610\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8019 - val_loss: 0.4923 - val_binary_accuracy: 0.7646\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4135 - binary_accuracy: 0.8086 - val_loss: 0.4897 - val_binary_accuracy: 0.7681\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4125 - binary_accuracy: 0.8147 - val_loss: 0.4895 - val_binary_accuracy: 0.7669\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4046 - binary_accuracy: 0.8096 - val_loss: 0.4887 - val_binary_accuracy: 0.7646\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4049 - binary_accuracy: 0.8096 - val_loss: 0.4852 - val_binary_accuracy: 0.7776\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.4013 - binary_accuracy: 0.8101 - val_loss: 0.4836 - val_binary_accuracy: 0.7765\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3953 - binary_accuracy: 0.8086 - val_loss: 0.4835 - val_binary_accuracy: 0.7812\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3883 - binary_accuracy: 0.8239 - val_loss: 0.4815 - val_binary_accuracy: 0.7812\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3869 - binary_accuracy: 0.8224 - val_loss: 0.4785 - val_binary_accuracy: 0.7824\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3827 - binary_accuracy: 0.8224 - val_loss: 0.4776 - val_binary_accuracy: 0.7800\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3796 - binary_accuracy: 0.8290 - val_loss: 0.4792 - val_binary_accuracy: 0.7800\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3748 - binary_accuracy: 0.8336 - val_loss: 0.4770 - val_binary_accuracy: 0.7812\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3813 - binary_accuracy: 0.8264 - val_loss: 0.4767 - val_binary_accuracy: 0.7824\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3815 - binary_accuracy: 0.8193 - val_loss: 0.4778 - val_binary_accuracy: 0.7848\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3732 - binary_accuracy: 0.8295 - val_loss: 0.4797 - val_binary_accuracy: 0.7776\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3759 - binary_accuracy: 0.8213 - val_loss: 0.4750 - val_binary_accuracy: 0.7848\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8372 - val_loss: 0.4756 - val_binary_accuracy: 0.7824\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8275 - val_loss: 0.4765 - val_binary_accuracy: 0.7800\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3670 - binary_accuracy: 0.8280 - val_loss: 0.4768 - val_binary_accuracy: 0.7824\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3762 - binary_accuracy: 0.8315 - val_loss: 0.4731 - val_binary_accuracy: 0.7824\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3626 - binary_accuracy: 0.8397 - val_loss: 0.4721 - val_binary_accuracy: 0.7848\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3613 - binary_accuracy: 0.8326 - val_loss: 0.4718 - val_binary_accuracy: 0.7895\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3582 - binary_accuracy: 0.8377 - val_loss: 0.4727 - val_binary_accuracy: 0.7907\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8418 - val_loss: 0.4723 - val_binary_accuracy: 0.7955\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3534 - binary_accuracy: 0.8412 - val_loss: 0.4712 - val_binary_accuracy: 0.7907\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3616 - binary_accuracy: 0.8387 - val_loss: 0.4745 - val_binary_accuracy: 0.7919\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3480 - binary_accuracy: 0.8428 - val_loss: 0.4722 - val_binary_accuracy: 0.7955\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3518 - binary_accuracy: 0.8412 - val_loss: 0.4705 - val_binary_accuracy: 0.7967\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3540 - binary_accuracy: 0.8361 - val_loss: 0.4726 - val_binary_accuracy: 0.7931\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3466 - binary_accuracy: 0.8402 - val_loss: 0.4704 - val_binary_accuracy: 0.7931\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8458 - val_loss: 0.4718 - val_binary_accuracy: 0.7931\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8438 - val_loss: 0.4728 - val_binary_accuracy: 0.7943\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3534 - binary_accuracy: 0.8412 - val_loss: 0.4718 - val_binary_accuracy: 0.7907\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8474 - val_loss: 0.4717 - val_binary_accuracy: 0.7967\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8571 - val_loss: 0.4711 - val_binary_accuracy: 0.7967\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8453 - val_loss: 0.4743 - val_binary_accuracy: 0.7967\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8479 - val_loss: 0.4727 - val_binary_accuracy: 0.7990\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8515 - val_loss: 0.4744 - val_binary_accuracy: 0.8014\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3391 - binary_accuracy: 0.8479 - val_loss: 0.4689 - val_binary_accuracy: 0.7967\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3360 - binary_accuracy: 0.8484 - val_loss: 0.4701 - val_binary_accuracy: 0.8002\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3220 - binary_accuracy: 0.8612 - val_loss: 0.4729 - val_binary_accuracy: 0.7990\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8469 - val_loss: 0.4741 - val_binary_accuracy: 0.7990\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3321 - binary_accuracy: 0.8550 - val_loss: 0.4725 - val_binary_accuracy: 0.7990\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8525 - val_loss: 0.4734 - val_binary_accuracy: 0.7990\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8566 - val_loss: 0.4735 - val_binary_accuracy: 0.8002\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3294 - binary_accuracy: 0.8525 - val_loss: 0.4700 - val_binary_accuracy: 0.8062\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3250 - binary_accuracy: 0.8617 - val_loss: 0.4700 - val_binary_accuracy: 0.8014\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3272 - binary_accuracy: 0.8448 - val_loss: 0.4705 - val_binary_accuracy: 0.8038\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3221 - binary_accuracy: 0.8576 - val_loss: 0.4691 - val_binary_accuracy: 0.8002\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3230 - binary_accuracy: 0.8525 - val_loss: 0.4715 - val_binary_accuracy: 0.7979\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3312 - binary_accuracy: 0.8504 - val_loss: 0.4726 - val_binary_accuracy: 0.7979\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3255 - binary_accuracy: 0.8581 - val_loss: 0.4727 - val_binary_accuracy: 0.8002\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8586 - val_loss: 0.4742 - val_binary_accuracy: 0.7979\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.3186 - binary_accuracy: 0.8642 - val_loss: 0.4728 - val_binary_accuracy: 0.8038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_things(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "fQGNQrnmqnXL",
        "outputId": "6b51826a-742b-4457-8a04-c266374ab41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_splits = 8\n",
        "number_runs   = 5\n",
        "results_acc   = np.zeros(shape=(number_runs, number_splits))\n",
        "results_loss  = np.zeros(shape=(number_runs, number_splits))\n",
        "\n",
        "\n",
        "for run in range(number_runs):\n",
        "  \n",
        "  print(\"\\n\\n\\nDoing the run number \", run+1)\n",
        "  kfold = KFold(n_splits=number_splits, shuffle=True)\n",
        "\n",
        "  # K-fold Cross Validation model evaluation\n",
        "  fold_no = 1\n",
        "\n",
        "  for split,(fold_train, fold_test) in enumerate(kfold.split(data, labels)):\n",
        "\n",
        "    model = get_model()\n",
        "    print(\"Training the fold number \", fold_no,\"\\n\")\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "    history = model.fit(data[fold_train], labels[fold_train], epochs=75, callbacks=[callback])\n",
        "\n",
        "    scores = model.evaluate(data[fold_test], labels[fold_test], verbose=0)\n",
        "    print(\"For the fold number \",  fold_no, \":\\nloss = \", scores[0], \"\\naccuracy = \", scores[1]*100,\"%\")\n",
        "    results_acc[run][split] = scores[1] * 100\n",
        "    results_loss[run][split] = scores[0]\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "\n",
        "results_acc = np.mean(results_acc, axis=1)\n",
        "results_loss = np.mean(results_loss, axis=1)\n",
        "\n",
        "results_acc = np.mean(results_acc)\n",
        "results_loss = np.mean(results_loss)\n",
        "\n",
        "print(\"\\n\\n\\nWe obtain the following results:\\nmean accuracy: \",results_acc,\"%\", \"\\nmean loss:\",results_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxby5uysq3jr",
        "outputId": "6c09554e-205b-4a9c-8c33-358bb28c9132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3827 - binary_accuracy: 0.8331\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3738 - binary_accuracy: 0.8339\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3768 - binary_accuracy: 0.8298\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3740 - binary_accuracy: 0.8241\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3721 - binary_accuracy: 0.8249\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3652 - binary_accuracy: 0.8408\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3661 - binary_accuracy: 0.8269\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8318\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3570 - binary_accuracy: 0.8388\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3584 - binary_accuracy: 0.8396\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3595 - binary_accuracy: 0.8367\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3545 - binary_accuracy: 0.8339\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3547 - binary_accuracy: 0.8363\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3566 - binary_accuracy: 0.8408\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3437 - binary_accuracy: 0.8404\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3496 - binary_accuracy: 0.8408\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8469\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3502 - binary_accuracy: 0.8441\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3462 - binary_accuracy: 0.8392\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3470 - binary_accuracy: 0.8494\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3447 - binary_accuracy: 0.8461\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3429 - binary_accuracy: 0.8445\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3508 - binary_accuracy: 0.8416\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3433 - binary_accuracy: 0.8465\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3418 - binary_accuracy: 0.8522\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3352 - binary_accuracy: 0.8510\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3330 - binary_accuracy: 0.8535\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3434 - binary_accuracy: 0.8498\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3398 - binary_accuracy: 0.8400\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3374 - binary_accuracy: 0.8527\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3340 - binary_accuracy: 0.8465\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8473\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8535\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3338 - binary_accuracy: 0.8445\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3258 - binary_accuracy: 0.8543\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3288 - binary_accuracy: 0.8465\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3287 - binary_accuracy: 0.8502\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3259 - binary_accuracy: 0.8502\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3293 - binary_accuracy: 0.8494\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3259 - binary_accuracy: 0.8576\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3314 - binary_accuracy: 0.8494\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3259 - binary_accuracy: 0.8543\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3294 - binary_accuracy: 0.8494\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3317 - binary_accuracy: 0.8502\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3172 - binary_accuracy: 0.8555\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3179 - binary_accuracy: 0.8596\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3211 - binary_accuracy: 0.8543\n",
            "For the fold number  8 :\n",
            "loss =  0.38753563165664673 \n",
            "accuracy =  84.85714197158813 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  2\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.7300 - binary_accuracy: 0.6498\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6064 - binary_accuracy: 0.6939\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5510 - binary_accuracy: 0.7220\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5169 - binary_accuracy: 0.7461\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - binary_accuracy: 0.7547\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4942 - binary_accuracy: 0.7433\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4816 - binary_accuracy: 0.7600\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4687 - binary_accuracy: 0.7718\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4626 - binary_accuracy: 0.7739\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4470 - binary_accuracy: 0.7833\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4488 - binary_accuracy: 0.7829\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4428 - binary_accuracy: 0.7890\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4375 - binary_accuracy: 0.7935\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4282 - binary_accuracy: 0.8012\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4264 - binary_accuracy: 0.7955\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4197 - binary_accuracy: 0.7980\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4137 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4122 - binary_accuracy: 0.7984\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8012\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3989 - binary_accuracy: 0.8106\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4001 - binary_accuracy: 0.8049\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3968 - binary_accuracy: 0.8131\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3894 - binary_accuracy: 0.8229\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3933 - binary_accuracy: 0.8127\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3825 - binary_accuracy: 0.8261\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3904 - binary_accuracy: 0.8176\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3881 - binary_accuracy: 0.8261\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3940 - binary_accuracy: 0.8273\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3750 - binary_accuracy: 0.8155\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3727 - binary_accuracy: 0.8359\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3848 - binary_accuracy: 0.8204\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3763 - binary_accuracy: 0.8220\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3730 - binary_accuracy: 0.8278\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3664 - binary_accuracy: 0.8359\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3714 - binary_accuracy: 0.8294\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3734 - binary_accuracy: 0.8343\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3720 - binary_accuracy: 0.8265\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3659 - binary_accuracy: 0.8359\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3669 - binary_accuracy: 0.8306\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3655 - binary_accuracy: 0.8286\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3630 - binary_accuracy: 0.8298\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3526 - binary_accuracy: 0.8384\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3518 - binary_accuracy: 0.8347\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3546 - binary_accuracy: 0.8437\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3644 - binary_accuracy: 0.8327\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8384\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8424\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8371\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3555 - binary_accuracy: 0.8380\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3554 - binary_accuracy: 0.8453\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3460 - binary_accuracy: 0.8465\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8424\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8392\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3551 - binary_accuracy: 0.8453\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3492 - binary_accuracy: 0.8388\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8473\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3414 - binary_accuracy: 0.8518\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3471 - binary_accuracy: 0.8424\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3424 - binary_accuracy: 0.8469\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8429\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3384 - binary_accuracy: 0.8465\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3418 - binary_accuracy: 0.8478\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3393 - binary_accuracy: 0.8461\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3285 - binary_accuracy: 0.8592\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3425 - binary_accuracy: 0.8424\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3311 - binary_accuracy: 0.8506\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3339 - binary_accuracy: 0.8551\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8531\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3335 - binary_accuracy: 0.8522\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3286 - binary_accuracy: 0.8555\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3321 - binary_accuracy: 0.8506\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3412 - binary_accuracy: 0.8547\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3344 - binary_accuracy: 0.8494\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8551\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3346 - binary_accuracy: 0.8510\n",
            "For the fold number  1 :\n",
            "loss =  0.36093637347221375 \n",
            "accuracy =  81.42856955528259 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.8982 - binary_accuracy: 0.4543\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6288 - binary_accuracy: 0.6420\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5543 - binary_accuracy: 0.7261\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5206 - binary_accuracy: 0.7445\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5049 - binary_accuracy: 0.7571\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4878 - binary_accuracy: 0.7649\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4702 - binary_accuracy: 0.7853\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.7796\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4525 - binary_accuracy: 0.7841\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4478 - binary_accuracy: 0.7955\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.7910\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4389 - binary_accuracy: 0.7935\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4383 - binary_accuracy: 0.7963\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4294 - binary_accuracy: 0.8012\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4257 - binary_accuracy: 0.8049\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4207 - binary_accuracy: 0.8037\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4143 - binary_accuracy: 0.8098\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4138 - binary_accuracy: 0.8131\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4113 - binary_accuracy: 0.8114\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4171 - binary_accuracy: 0.8065\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4135 - binary_accuracy: 0.8131\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4061 - binary_accuracy: 0.8204\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4018 - binary_accuracy: 0.8176\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4028 - binary_accuracy: 0.8114\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4005 - binary_accuracy: 0.8143\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3991 - binary_accuracy: 0.8216\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3925 - binary_accuracy: 0.8204\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3932 - binary_accuracy: 0.8220\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3933 - binary_accuracy: 0.8188\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3940 - binary_accuracy: 0.8220\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3739 - binary_accuracy: 0.8347\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3907 - binary_accuracy: 0.8233\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.8184\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3860 - binary_accuracy: 0.8265\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3830 - binary_accuracy: 0.8163\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3884 - binary_accuracy: 0.8122\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3800 - binary_accuracy: 0.8208\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3720 - binary_accuracy: 0.8318\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3806 - binary_accuracy: 0.8339\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3794 - binary_accuracy: 0.8286\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3665 - binary_accuracy: 0.8384\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3693 - binary_accuracy: 0.8327\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3689 - binary_accuracy: 0.8343\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3763 - binary_accuracy: 0.8314\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3672 - binary_accuracy: 0.8314\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3722 - binary_accuracy: 0.8298\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8343\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3634 - binary_accuracy: 0.8314\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3634 - binary_accuracy: 0.8367\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3670 - binary_accuracy: 0.8339\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3583 - binary_accuracy: 0.8392\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3594 - binary_accuracy: 0.8327\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3617 - binary_accuracy: 0.8396\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8465\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3568 - binary_accuracy: 0.8404\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3572 - binary_accuracy: 0.8380\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3583 - binary_accuracy: 0.8449\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3503 - binary_accuracy: 0.8388\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8490\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8449\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8453\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3600 - binary_accuracy: 0.8339\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3456 - binary_accuracy: 0.8498\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8392\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3420 - binary_accuracy: 0.8494\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8535\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8506\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3409 - binary_accuracy: 0.8433\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3489 - binary_accuracy: 0.8449\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3422 - binary_accuracy: 0.8465\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3428 - binary_accuracy: 0.8363\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8461\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3503 - binary_accuracy: 0.8449\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8482\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3420 - binary_accuracy: 0.8445\n",
            "For the fold number  2 :\n",
            "loss =  0.3842494785785675 \n",
            "accuracy =  84.28571224212646 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.7795 - binary_accuracy: 0.5482\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.6833\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5849 - binary_accuracy: 0.7098\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5519 - binary_accuracy: 0.7359\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5213 - binary_accuracy: 0.7527\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5085 - binary_accuracy: 0.7535\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5004 - binary_accuracy: 0.7567\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4917 - binary_accuracy: 0.7620\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4784 - binary_accuracy: 0.7755\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.7739\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4758 - binary_accuracy: 0.7808\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4581 - binary_accuracy: 0.7800\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4482 - binary_accuracy: 0.7922\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.7894\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4457 - binary_accuracy: 0.7902\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.7869\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.7931\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4271 - binary_accuracy: 0.8016\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4351 - binary_accuracy: 0.7914\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4290 - binary_accuracy: 0.7955\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4232 - binary_accuracy: 0.8049\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4214 - binary_accuracy: 0.8106\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4235 - binary_accuracy: 0.8024\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4200 - binary_accuracy: 0.7996\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4094 - binary_accuracy: 0.8114\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8086\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4090 - binary_accuracy: 0.8204\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4130 - binary_accuracy: 0.8061\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8086\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3996 - binary_accuracy: 0.8139\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_accuracy: 0.8110\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4026 - binary_accuracy: 0.8212\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3957 - binary_accuracy: 0.8171\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3974 - binary_accuracy: 0.8216\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3874 - binary_accuracy: 0.8249\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3971 - binary_accuracy: 0.8171\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3933 - binary_accuracy: 0.8176\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8180\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3852 - binary_accuracy: 0.8241\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3815 - binary_accuracy: 0.8302\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3902 - binary_accuracy: 0.8143\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3868 - binary_accuracy: 0.8237\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3774 - binary_accuracy: 0.8245\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3847 - binary_accuracy: 0.8208\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3765 - binary_accuracy: 0.8335\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8241\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3831 - binary_accuracy: 0.8220\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3795 - binary_accuracy: 0.8208\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3817 - binary_accuracy: 0.8265\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3692 - binary_accuracy: 0.8298\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3608 - binary_accuracy: 0.8351\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3696 - binary_accuracy: 0.8322\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.8314\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8257\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3821 - binary_accuracy: 0.8237\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3677 - binary_accuracy: 0.8278\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3667 - binary_accuracy: 0.8322\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3640 - binary_accuracy: 0.8339\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3677 - binary_accuracy: 0.8335\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8384\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3580 - binary_accuracy: 0.8433\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3563 - binary_accuracy: 0.8404\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8347\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8294\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3543 - binary_accuracy: 0.8380\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8310\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3561 - binary_accuracy: 0.8347\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8457\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8384\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3627 - binary_accuracy: 0.8290\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8449\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8449\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3543 - binary_accuracy: 0.8327\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3539 - binary_accuracy: 0.8392\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8510\n",
            "For the fold number  3 :\n",
            "loss =  0.3175814151763916 \n",
            "accuracy =  86.8571400642395 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 1.0134 - binary_accuracy: 0.3588\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7198 - binary_accuracy: 0.5388\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6127 - binary_accuracy: 0.6678\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5729 - binary_accuracy: 0.7065\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5372 - binary_accuracy: 0.7335\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5249 - binary_accuracy: 0.7429\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5204 - binary_accuracy: 0.7522\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5074 - binary_accuracy: 0.7543\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4945 - binary_accuracy: 0.7678\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4869 - binary_accuracy: 0.7710\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4831 - binary_accuracy: 0.7841\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4635 - binary_accuracy: 0.7865\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4635 - binary_accuracy: 0.7824\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4602 - binary_accuracy: 0.7882\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4592 - binary_accuracy: 0.7951\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8078\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4379 - binary_accuracy: 0.7996\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8057\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.7971\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4294 - binary_accuracy: 0.8016\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4383 - binary_accuracy: 0.8041\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4286 - binary_accuracy: 0.8029\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4308 - binary_accuracy: 0.8057\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4270 - binary_accuracy: 0.8094\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4197 - binary_accuracy: 0.8110\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4234 - binary_accuracy: 0.8098\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4236 - binary_accuracy: 0.8163\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - binary_accuracy: 0.8086\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4092 - binary_accuracy: 0.8098\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4073 - binary_accuracy: 0.8171\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4058 - binary_accuracy: 0.8196\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4041 - binary_accuracy: 0.8196\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3985 - binary_accuracy: 0.8176\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3941 - binary_accuracy: 0.8257\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4040 - binary_accuracy: 0.8196\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3993 - binary_accuracy: 0.8241\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3919 - binary_accuracy: 0.8249\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3956 - binary_accuracy: 0.8155\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3940 - binary_accuracy: 0.8229\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3923 - binary_accuracy: 0.8249\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3951 - binary_accuracy: 0.8220\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3870 - binary_accuracy: 0.8204\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3854 - binary_accuracy: 0.8269\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3860 - binary_accuracy: 0.8331\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3839 - binary_accuracy: 0.8306\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3830 - binary_accuracy: 0.8265\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3796 - binary_accuracy: 0.8273\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8253\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3836 - binary_accuracy: 0.8237\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3801 - binary_accuracy: 0.8322\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3825 - binary_accuracy: 0.8241\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3797 - binary_accuracy: 0.8306\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8347\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3785 - binary_accuracy: 0.8322\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3738 - binary_accuracy: 0.8363\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3787 - binary_accuracy: 0.8363\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3703 - binary_accuracy: 0.8396\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3745 - binary_accuracy: 0.8322\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3631 - binary_accuracy: 0.8424\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3676 - binary_accuracy: 0.8351\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3716 - binary_accuracy: 0.8392\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3699 - binary_accuracy: 0.8339\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3660 - binary_accuracy: 0.8359\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3680 - binary_accuracy: 0.8339\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8310\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3617 - binary_accuracy: 0.8396\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3612 - binary_accuracy: 0.8441\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3676 - binary_accuracy: 0.8302\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3587 - binary_accuracy: 0.8384\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8363\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8404\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3594 - binary_accuracy: 0.8396\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.8331\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8392\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3641 - binary_accuracy: 0.8376\n",
            "For the fold number  4 :\n",
            "loss =  0.39445608854293823 \n",
            "accuracy =  81.71428442001343 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.7843 - binary_accuracy: 0.5286\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6266 - binary_accuracy: 0.6759\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5719 - binary_accuracy: 0.7163\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5447 - binary_accuracy: 0.7339\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5136 - binary_accuracy: 0.7502\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5019 - binary_accuracy: 0.7633\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4901 - binary_accuracy: 0.7682\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4709 - binary_accuracy: 0.7678\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4710 - binary_accuracy: 0.7714\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4668 - binary_accuracy: 0.7845\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4584 - binary_accuracy: 0.7808\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4543 - binary_accuracy: 0.7873\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.7996\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.7976\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4421 - binary_accuracy: 0.7935\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4281 - binary_accuracy: 0.7980\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4314 - binary_accuracy: 0.7918\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4216 - binary_accuracy: 0.8078\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4279 - binary_accuracy: 0.7976\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.8045\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4136 - binary_accuracy: 0.8110\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8147\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - binary_accuracy: 0.8127\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4041 - binary_accuracy: 0.8176\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4080 - binary_accuracy: 0.8159\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3984 - binary_accuracy: 0.8171\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3912 - binary_accuracy: 0.8204\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3889 - binary_accuracy: 0.8249\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3942 - binary_accuracy: 0.8229\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3947 - binary_accuracy: 0.8159\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8233\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3773 - binary_accuracy: 0.8359\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3906 - binary_accuracy: 0.8212\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3891 - binary_accuracy: 0.8233\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8306\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8298\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3682 - binary_accuracy: 0.8339\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3728 - binary_accuracy: 0.8245\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8359\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8331\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3630 - binary_accuracy: 0.8367\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8392\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3700 - binary_accuracy: 0.8298\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8490\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8465\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8404\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8412\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3574 - binary_accuracy: 0.8429\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8482\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3548 - binary_accuracy: 0.8384\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3600 - binary_accuracy: 0.8322\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8392\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3573 - binary_accuracy: 0.8482\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8412\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3518 - binary_accuracy: 0.8531\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8514\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8420\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8441\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8457\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8469\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8433\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.8482\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8486\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8490\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3378 - binary_accuracy: 0.8457\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8486\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8514\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3355 - binary_accuracy: 0.8490\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3374 - binary_accuracy: 0.8473\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8490\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3327 - binary_accuracy: 0.8547\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3320 - binary_accuracy: 0.8567\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8514\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8424\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3312 - binary_accuracy: 0.8551\n",
            "For the fold number  5 :\n",
            "loss =  0.3863772451877594 \n",
            "accuracy =  81.99999928474426 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7632 - binary_accuracy: 0.5347\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5986 - binary_accuracy: 0.6865\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5565 - binary_accuracy: 0.7184\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5406 - binary_accuracy: 0.7339\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5136 - binary_accuracy: 0.7473\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5071 - binary_accuracy: 0.7518\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4922 - binary_accuracy: 0.7563\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4783 - binary_accuracy: 0.7657\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4693 - binary_accuracy: 0.7776\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.7820\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.7812\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4572 - binary_accuracy: 0.7804\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4525 - binary_accuracy: 0.7894\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4374 - binary_accuracy: 0.7943\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4386 - binary_accuracy: 0.7947\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4357 - binary_accuracy: 0.7882\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4244 - binary_accuracy: 0.7984\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4332 - binary_accuracy: 0.7996\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4242 - binary_accuracy: 0.8086\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4217 - binary_accuracy: 0.8049\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4158 - binary_accuracy: 0.8073\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4099 - binary_accuracy: 0.8073\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4141 - binary_accuracy: 0.8098\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4077 - binary_accuracy: 0.8184\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4051 - binary_accuracy: 0.8184\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_accuracy: 0.8147\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3951 - binary_accuracy: 0.8253\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3966 - binary_accuracy: 0.8237\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3905 - binary_accuracy: 0.8253\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3943 - binary_accuracy: 0.8253\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3908 - binary_accuracy: 0.8216\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3915 - binary_accuracy: 0.8188\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3919 - binary_accuracy: 0.8204\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3801 - binary_accuracy: 0.8278\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3823 - binary_accuracy: 0.8237\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3876 - binary_accuracy: 0.8269\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3847 - binary_accuracy: 0.8302\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3845 - binary_accuracy: 0.8273\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3806 - binary_accuracy: 0.8290\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8278\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3855 - binary_accuracy: 0.8212\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3730 - binary_accuracy: 0.8269\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3792 - binary_accuracy: 0.8273\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8302\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8290\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8318\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3698 - binary_accuracy: 0.8310\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3618 - binary_accuracy: 0.8457\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3727 - binary_accuracy: 0.8302\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3628 - binary_accuracy: 0.8371\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8351\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3651 - binary_accuracy: 0.8343\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8347\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3654 - binary_accuracy: 0.8371\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8408\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3602 - binary_accuracy: 0.8404\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8388\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8384\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8384\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8404\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3584 - binary_accuracy: 0.8388\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8404\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8465\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3531 - binary_accuracy: 0.8384\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3586 - binary_accuracy: 0.8306\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8429\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8388\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8335\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3567 - binary_accuracy: 0.8376\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3454 - binary_accuracy: 0.8437\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8441\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8563\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8445\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8437\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8420\n",
            "For the fold number  6 :\n",
            "loss =  0.3958490788936615 \n",
            "accuracy =  85.71428656578064 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.6383 - binary_accuracy: 0.6620\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5782 - binary_accuracy: 0.7082\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5389 - binary_accuracy: 0.7376\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5165 - binary_accuracy: 0.7555\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4883 - binary_accuracy: 0.7620\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4775 - binary_accuracy: 0.7616\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4754 - binary_accuracy: 0.7616\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4643 - binary_accuracy: 0.7747\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4596 - binary_accuracy: 0.7792\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4478 - binary_accuracy: 0.7837\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.7857\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4402 - binary_accuracy: 0.7943\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4291 - binary_accuracy: 0.8016\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4337 - binary_accuracy: 0.7927\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4214 - binary_accuracy: 0.8004\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4216 - binary_accuracy: 0.8037\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4187 - binary_accuracy: 0.8073\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4116 - binary_accuracy: 0.8082\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4105 - binary_accuracy: 0.8184\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4090 - binary_accuracy: 0.8086\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4065 - binary_accuracy: 0.8114\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4035 - binary_accuracy: 0.8143\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4042 - binary_accuracy: 0.8159\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4013 - binary_accuracy: 0.8102\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8261\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3969 - binary_accuracy: 0.8237\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3961 - binary_accuracy: 0.8180\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3893 - binary_accuracy: 0.8224\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3919 - binary_accuracy: 0.8224\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3863 - binary_accuracy: 0.8220\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3848 - binary_accuracy: 0.8343\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8310\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3833 - binary_accuracy: 0.8265\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3809 - binary_accuracy: 0.8286\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3814 - binary_accuracy: 0.8265\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3709 - binary_accuracy: 0.8290\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3646 - binary_accuracy: 0.8290\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3688 - binary_accuracy: 0.8302\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3710 - binary_accuracy: 0.8298\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3721 - binary_accuracy: 0.8306\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8363\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8367\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3710 - binary_accuracy: 0.8318\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3617 - binary_accuracy: 0.8347\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8376\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3678 - binary_accuracy: 0.8335\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8420\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3647 - binary_accuracy: 0.8310\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8433\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8453\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3493 - binary_accuracy: 0.8457\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8392\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3533 - binary_accuracy: 0.8416\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8371\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8457\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8371\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8457\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8465\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8420\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8543\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3453 - binary_accuracy: 0.8482\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8473\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8388\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8429\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8457\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8412\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8514\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3395 - binary_accuracy: 0.8433\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3314 - binary_accuracy: 0.8567\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8531\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3335 - binary_accuracy: 0.8522\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3382 - binary_accuracy: 0.8424\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3358 - binary_accuracy: 0.8457\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8543\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3355 - binary_accuracy: 0.8469\n",
            "For the fold number  7 :\n",
            "loss =  0.374438613653183 \n",
            "accuracy =  83.1428587436676 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7937 - binary_accuracy: 0.5531\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6049 - binary_accuracy: 0.6824\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5554 - binary_accuracy: 0.7261\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5236 - binary_accuracy: 0.7478\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5207 - binary_accuracy: 0.7461\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4936 - binary_accuracy: 0.7620\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4864 - binary_accuracy: 0.7682\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4738 - binary_accuracy: 0.7751\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.7767\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4505 - binary_accuracy: 0.7878\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.7906\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4492 - binary_accuracy: 0.7816\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4417 - binary_accuracy: 0.7959\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4357 - binary_accuracy: 0.7927\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4355 - binary_accuracy: 0.7971\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4292 - binary_accuracy: 0.8090\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4209 - binary_accuracy: 0.8102\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.8061\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4119 - binary_accuracy: 0.8151\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4148 - binary_accuracy: 0.8098\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4130 - binary_accuracy: 0.8090\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4060 - binary_accuracy: 0.8122\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4081 - binary_accuracy: 0.8188\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4008 - binary_accuracy: 0.8143\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3926 - binary_accuracy: 0.8200\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3867 - binary_accuracy: 0.8220\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8273\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3913 - binary_accuracy: 0.8196\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8220\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3822 - binary_accuracy: 0.8282\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8290\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3819 - binary_accuracy: 0.8188\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3791 - binary_accuracy: 0.8253\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8351\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3725 - binary_accuracy: 0.8306\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8343\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3737 - binary_accuracy: 0.8294\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3729 - binary_accuracy: 0.8335\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3682 - binary_accuracy: 0.8335\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3622 - binary_accuracy: 0.8416\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8318\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3755 - binary_accuracy: 0.8286\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8412\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3573 - binary_accuracy: 0.8331\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3644 - binary_accuracy: 0.8347\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8347\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3702 - binary_accuracy: 0.8282\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8412\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3537 - binary_accuracy: 0.8424\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8359\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8429\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3588 - binary_accuracy: 0.8363\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3482 - binary_accuracy: 0.8424\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8404\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8351\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8461\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8412\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8473\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8490\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8449\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8388\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8420\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8449\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3494 - binary_accuracy: 0.8433\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3410 - binary_accuracy: 0.8424\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3359 - binary_accuracy: 0.8555\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8494\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8473\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8461\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3405 - binary_accuracy: 0.8482\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3343 - binary_accuracy: 0.8482\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3416 - binary_accuracy: 0.8445\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8478\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8429\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3380 - binary_accuracy: 0.8490\n",
            "For the fold number  8 :\n",
            "loss =  0.3773452639579773 \n",
            "accuracy =  81.99999928474426 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  3\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6939 - binary_accuracy: 0.5527\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5819 - binary_accuracy: 0.7012\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5426 - binary_accuracy: 0.7376\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5227 - binary_accuracy: 0.7420\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4982 - binary_accuracy: 0.7624\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4830 - binary_accuracy: 0.7682\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4714 - binary_accuracy: 0.7706\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4594 - binary_accuracy: 0.7853\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4578 - binary_accuracy: 0.7845\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4508 - binary_accuracy: 0.7890\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.7882\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.7812\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4400 - binary_accuracy: 0.7869\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4318 - binary_accuracy: 0.8012\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4256 - binary_accuracy: 0.7984\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4265 - binary_accuracy: 0.8004\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4236 - binary_accuracy: 0.8016\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4104 - binary_accuracy: 0.8033\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4121 - binary_accuracy: 0.8049\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4069 - binary_accuracy: 0.8078\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4071 - binary_accuracy: 0.8082\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4004 - binary_accuracy: 0.8139\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3909 - binary_accuracy: 0.8200\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8192\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4017 - binary_accuracy: 0.8151\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4004 - binary_accuracy: 0.8118\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8163\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3867 - binary_accuracy: 0.8237\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3848 - binary_accuracy: 0.8261\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3885 - binary_accuracy: 0.8241\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3830 - binary_accuracy: 0.8233\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3806 - binary_accuracy: 0.8257\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3820 - binary_accuracy: 0.8188\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8286\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3773 - binary_accuracy: 0.8290\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3799 - binary_accuracy: 0.8298\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3774 - binary_accuracy: 0.8216\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3782 - binary_accuracy: 0.8257\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3651 - binary_accuracy: 0.8367\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.8347\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8229\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3689 - binary_accuracy: 0.8351\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3716 - binary_accuracy: 0.8314\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3590 - binary_accuracy: 0.8376\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3682 - binary_accuracy: 0.8335\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3636 - binary_accuracy: 0.8380\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3687 - binary_accuracy: 0.8327\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3581 - binary_accuracy: 0.8355\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3589 - binary_accuracy: 0.8371\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8376\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3663 - binary_accuracy: 0.8322\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8392\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3620 - binary_accuracy: 0.8376\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3557 - binary_accuracy: 0.8367\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8441\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8416\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8424\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8400\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8404\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8416\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8514\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8388\n",
            "For the fold number  1 :\n",
            "loss =  0.36986681818962097 \n",
            "accuracy =  83.1428587436676 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.6795 - binary_accuracy: 0.6208\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5767 - binary_accuracy: 0.7135\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5458 - binary_accuracy: 0.7318\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5200 - binary_accuracy: 0.7482\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5005 - binary_accuracy: 0.7563\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4838 - binary_accuracy: 0.7645\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4756 - binary_accuracy: 0.7686\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4760 - binary_accuracy: 0.7616\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.7837\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4482 - binary_accuracy: 0.7922\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.7910\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.7771\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4448 - binary_accuracy: 0.7882\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4285 - binary_accuracy: 0.8004\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4221 - binary_accuracy: 0.8029\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4321 - binary_accuracy: 0.7927\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4213 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4278 - binary_accuracy: 0.7922\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4181 - binary_accuracy: 0.8037\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4139 - binary_accuracy: 0.8078\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8053\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4118 - binary_accuracy: 0.8106\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3969 - binary_accuracy: 0.8224\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4020 - binary_accuracy: 0.8159\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8208\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3969 - binary_accuracy: 0.8224\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4049 - binary_accuracy: 0.8069\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3952 - binary_accuracy: 0.8204\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3894 - binary_accuracy: 0.8147\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4050 - binary_accuracy: 0.8082\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3891 - binary_accuracy: 0.8151\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3990 - binary_accuracy: 0.8073\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3806 - binary_accuracy: 0.8322\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3824 - binary_accuracy: 0.8249\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3880 - binary_accuracy: 0.8208\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3825 - binary_accuracy: 0.8208\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3735 - binary_accuracy: 0.8306\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3721 - binary_accuracy: 0.8261\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8237\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3792 - binary_accuracy: 0.8208\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3743 - binary_accuracy: 0.8318\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3716 - binary_accuracy: 0.8322\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3742 - binary_accuracy: 0.8269\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3711 - binary_accuracy: 0.8331\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8347\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3656 - binary_accuracy: 0.8343\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8429\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8322\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.8318\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8347\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8371\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8371\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.8392\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8437\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8473\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3515 - binary_accuracy: 0.8380\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8384\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8490\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8392\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3520 - binary_accuracy: 0.8351\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8469\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8420\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8408\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8486\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8355\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8457\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3455 - binary_accuracy: 0.8486\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8396\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8429\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8437\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3474 - binary_accuracy: 0.8416\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8482\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8482\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8490\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8396\n",
            "For the fold number  2 :\n",
            "loss =  0.32478269934654236 \n",
            "accuracy =  84.28571224212646 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6654 - binary_accuracy: 0.6294\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5701 - binary_accuracy: 0.7020\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5436 - binary_accuracy: 0.7237\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5172 - binary_accuracy: 0.7355\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4967 - binary_accuracy: 0.7494\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4774 - binary_accuracy: 0.7682\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4629 - binary_accuracy: 0.7829\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4575 - binary_accuracy: 0.7824\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4458 - binary_accuracy: 0.7869\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.7890\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4325 - binary_accuracy: 0.7988\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4288 - binary_accuracy: 0.7996\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4161 - binary_accuracy: 0.8106\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4125 - binary_accuracy: 0.8037\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4125 - binary_accuracy: 0.8008\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4067 - binary_accuracy: 0.8082\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4016 - binary_accuracy: 0.8151\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4044 - binary_accuracy: 0.8122\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8053\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3983 - binary_accuracy: 0.8094\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3876 - binary_accuracy: 0.8212\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3966 - binary_accuracy: 0.8216\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3894 - binary_accuracy: 0.8163\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3971 - binary_accuracy: 0.8167\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3812 - binary_accuracy: 0.8249\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3825 - binary_accuracy: 0.8167\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3814 - binary_accuracy: 0.8167\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3774 - binary_accuracy: 0.8245\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8327\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3795 - binary_accuracy: 0.8196\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3728 - binary_accuracy: 0.8196\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8302\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3708 - binary_accuracy: 0.8290\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3718 - binary_accuracy: 0.8322\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3628 - binary_accuracy: 0.8278\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3726 - binary_accuracy: 0.8253\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3644 - binary_accuracy: 0.8318\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3547 - binary_accuracy: 0.8416\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3541 - binary_accuracy: 0.8327\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8343\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3506 - binary_accuracy: 0.8412\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8355\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3491 - binary_accuracy: 0.8441\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8298\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8445\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8380\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8376\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8380\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8371\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8355\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_accuracy: 0.8371\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3400 - binary_accuracy: 0.8486\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8388\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8380\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3386 - binary_accuracy: 0.8388\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8441\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3421 - binary_accuracy: 0.8457\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3383 - binary_accuracy: 0.8465\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8486\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3480 - binary_accuracy: 0.8429\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8420\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8510\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8498\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3349 - binary_accuracy: 0.8429\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3416 - binary_accuracy: 0.8424\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8580\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3189 - binary_accuracy: 0.8547\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3329 - binary_accuracy: 0.8506\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3310 - binary_accuracy: 0.8453\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8449\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8543\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8461\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8535\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3370 - binary_accuracy: 0.8498\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3260 - binary_accuracy: 0.8514\n",
            "For the fold number  3 :\n",
            "loss =  0.4600768983364105 \n",
            "accuracy =  81.42856955528259 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7122 - binary_accuracy: 0.5829\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5876 - binary_accuracy: 0.6943\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5346 - binary_accuracy: 0.7257\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5201 - binary_accuracy: 0.7482\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5026 - binary_accuracy: 0.7592\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4823 - binary_accuracy: 0.7714\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4706 - binary_accuracy: 0.7788\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.7784\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.7808\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.7837\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4432 - binary_accuracy: 0.7963\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4339 - binary_accuracy: 0.7992\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4409 - binary_accuracy: 0.7865\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4352 - binary_accuracy: 0.7971\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4264 - binary_accuracy: 0.7976\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4164 - binary_accuracy: 0.8029\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4233 - binary_accuracy: 0.8057\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4115 - binary_accuracy: 0.8073\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4145 - binary_accuracy: 0.8073\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4175 - binary_accuracy: 0.8008\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4065 - binary_accuracy: 0.8114\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3995 - binary_accuracy: 0.8224\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4062 - binary_accuracy: 0.8143\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3943 - binary_accuracy: 0.8200\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3997 - binary_accuracy: 0.8139\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3956 - binary_accuracy: 0.8212\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3840 - binary_accuracy: 0.8229\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8265\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3939 - binary_accuracy: 0.8269\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3826 - binary_accuracy: 0.8196\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8229\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3827 - binary_accuracy: 0.8282\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3853 - binary_accuracy: 0.8282\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3801 - binary_accuracy: 0.8249\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3761 - binary_accuracy: 0.8294\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3732 - binary_accuracy: 0.8314\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3706 - binary_accuracy: 0.8388\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8298\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3695 - binary_accuracy: 0.8322\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3674 - binary_accuracy: 0.8322\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3686 - binary_accuracy: 0.8322\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3805 - binary_accuracy: 0.8302\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8355\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8408\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3617 - binary_accuracy: 0.8367\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8437\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3566 - binary_accuracy: 0.8335\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8371\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8461\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8433\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3555 - binary_accuracy: 0.8408\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8445\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8404\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8441\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8465\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3537 - binary_accuracy: 0.8371\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8490\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8473\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8363\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8441\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8486\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8518\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8539\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3463 - binary_accuracy: 0.8429\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3361 - binary_accuracy: 0.8551\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8494\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3374 - binary_accuracy: 0.8502\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8502\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8531\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3330 - binary_accuracy: 0.8571\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8571\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3332 - binary_accuracy: 0.8555\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3324 - binary_accuracy: 0.8510\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3286 - binary_accuracy: 0.8482\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3263 - binary_accuracy: 0.8539\n",
            "For the fold number  4 :\n",
            "loss =  0.383065402507782 \n",
            "accuracy =  80.8571457862854 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7119 - binary_accuracy: 0.6306\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.6976\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5413 - binary_accuracy: 0.7465\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5158 - binary_accuracy: 0.7547\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5035 - binary_accuracy: 0.7580\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4845 - binary_accuracy: 0.7571\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4775 - binary_accuracy: 0.7645\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4601 - binary_accuracy: 0.7812\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4544 - binary_accuracy: 0.7804\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.7829\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.7776\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4370 - binary_accuracy: 0.7833\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4339 - binary_accuracy: 0.7951\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4296 - binary_accuracy: 0.7918\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4333 - binary_accuracy: 0.7935\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4206 - binary_accuracy: 0.8045\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4244 - binary_accuracy: 0.7906\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8069\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4069 - binary_accuracy: 0.8135\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4079 - binary_accuracy: 0.8094\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4172 - binary_accuracy: 0.8033\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4074 - binary_accuracy: 0.8041\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3997 - binary_accuracy: 0.8086\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3903 - binary_accuracy: 0.8135\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3998 - binary_accuracy: 0.8082\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3971 - binary_accuracy: 0.8114\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3912 - binary_accuracy: 0.8184\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3945 - binary_accuracy: 0.8188\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3912 - binary_accuracy: 0.8176\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3926 - binary_accuracy: 0.8155\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3883 - binary_accuracy: 0.8151\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8245\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3868 - binary_accuracy: 0.8200\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8147\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3824 - binary_accuracy: 0.8188\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3802 - binary_accuracy: 0.8269\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3769 - binary_accuracy: 0.8224\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8298\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3787 - binary_accuracy: 0.8298\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3709 - binary_accuracy: 0.8322\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3663 - binary_accuracy: 0.8318\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3696 - binary_accuracy: 0.8249\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3683 - binary_accuracy: 0.8265\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3658 - binary_accuracy: 0.8298\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8347\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3616 - binary_accuracy: 0.8322\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8265\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3642 - binary_accuracy: 0.8343\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3542 - binary_accuracy: 0.8416\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3553 - binary_accuracy: 0.8331\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8327\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8335\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3553 - binary_accuracy: 0.8339\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3543 - binary_accuracy: 0.8351\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3555 - binary_accuracy: 0.8339\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8388\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8433\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8355\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8355\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3605 - binary_accuracy: 0.8310\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3435 - binary_accuracy: 0.8380\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8433\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3516 - binary_accuracy: 0.8335\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8473\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8420\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8396\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3418 - binary_accuracy: 0.8469\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8437\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3394 - binary_accuracy: 0.8469\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3414 - binary_accuracy: 0.8445\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3329 - binary_accuracy: 0.8522\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8380\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8449\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8437\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3400 - binary_accuracy: 0.8384\n",
            "For the fold number  5 :\n",
            "loss =  0.3672538101673126 \n",
            "accuracy =  82.85714387893677 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6546 - binary_accuracy: 0.6494\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5877 - binary_accuracy: 0.6955\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5539 - binary_accuracy: 0.7159\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5198 - binary_accuracy: 0.7367\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5017 - binary_accuracy: 0.7490\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4789 - binary_accuracy: 0.7624\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4725 - binary_accuracy: 0.7706\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.7735\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4488 - binary_accuracy: 0.7751\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.7902\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4386 - binary_accuracy: 0.7967\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4346 - binary_accuracy: 0.7935\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4235 - binary_accuracy: 0.8004\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4297 - binary_accuracy: 0.8029\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4270 - binary_accuracy: 0.8012\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4233 - binary_accuracy: 0.7984\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.8049\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4062 - binary_accuracy: 0.8118\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8147\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8098\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4101 - binary_accuracy: 0.8086\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3934 - binary_accuracy: 0.8180\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3949 - binary_accuracy: 0.8159\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3908 - binary_accuracy: 0.8200\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3927 - binary_accuracy: 0.8118\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3857 - binary_accuracy: 0.8245\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8212\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3817 - binary_accuracy: 0.8245\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8155\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3758 - binary_accuracy: 0.8245\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8241\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3787 - binary_accuracy: 0.8278\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3717 - binary_accuracy: 0.8204\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3751 - binary_accuracy: 0.8278\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3658 - binary_accuracy: 0.8298\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8249\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8290\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3717 - binary_accuracy: 0.8286\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8294\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3679 - binary_accuracy: 0.8273\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3596 - binary_accuracy: 0.8314\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8376\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3570 - binary_accuracy: 0.8371\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8388\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3572 - binary_accuracy: 0.8388\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3566 - binary_accuracy: 0.8380\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3540 - binary_accuracy: 0.8367\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8351\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3515 - binary_accuracy: 0.8400\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8327\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8351\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8412\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8437\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3429 - binary_accuracy: 0.8388\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3496 - binary_accuracy: 0.8359\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8486\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8388\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8363\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8433\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8498\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3336 - binary_accuracy: 0.8482\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8457\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8518\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8473\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8453\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3378 - binary_accuracy: 0.8429\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3404 - binary_accuracy: 0.8478\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3309 - binary_accuracy: 0.8465\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8563\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3338 - binary_accuracy: 0.8408\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8514\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3275 - binary_accuracy: 0.8584\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3259 - binary_accuracy: 0.8453\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3294 - binary_accuracy: 0.8494\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3196 - binary_accuracy: 0.8563\n",
            "For the fold number  6 :\n",
            "loss =  0.33823326230049133 \n",
            "accuracy =  85.14285683631897 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6210 - binary_accuracy: 0.6873\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5651 - binary_accuracy: 0.7167\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5287 - binary_accuracy: 0.7510\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5133 - binary_accuracy: 0.7433\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4999 - binary_accuracy: 0.7514\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4817 - binary_accuracy: 0.7547\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4782 - binary_accuracy: 0.7616\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4708 - binary_accuracy: 0.7661\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4564 - binary_accuracy: 0.7722\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.7788\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.7833\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4401 - binary_accuracy: 0.7861\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4306 - binary_accuracy: 0.7869\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4320 - binary_accuracy: 0.7939\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4285 - binary_accuracy: 0.7963\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4235 - binary_accuracy: 0.7922\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4182 - binary_accuracy: 0.7951\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4094 - binary_accuracy: 0.7980\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4087 - binary_accuracy: 0.8004\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4051 - binary_accuracy: 0.8102\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4091 - binary_accuracy: 0.8041\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4070 - binary_accuracy: 0.8102\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3957 - binary_accuracy: 0.8176\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8094\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3917 - binary_accuracy: 0.8155\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3885 - binary_accuracy: 0.8249\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3870 - binary_accuracy: 0.8192\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3908 - binary_accuracy: 0.8155\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3789 - binary_accuracy: 0.8273\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3841 - binary_accuracy: 0.8229\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3841 - binary_accuracy: 0.8216\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3765 - binary_accuracy: 0.8192\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3790 - binary_accuracy: 0.8237\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3791 - binary_accuracy: 0.8290\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8200\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3691 - binary_accuracy: 0.8302\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3825 - binary_accuracy: 0.8188\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3717 - binary_accuracy: 0.8412\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3689 - binary_accuracy: 0.8322\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3726 - binary_accuracy: 0.8322\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8351\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3636 - binary_accuracy: 0.8388\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3683 - binary_accuracy: 0.8253\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3669 - binary_accuracy: 0.8282\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3481 - binary_accuracy: 0.8486\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3622 - binary_accuracy: 0.8310\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8327\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8396\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8355\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8347\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8322\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8388\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8478\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3622 - binary_accuracy: 0.8306\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3536 - binary_accuracy: 0.8343\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8380\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8437\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8384\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8327\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8404\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8412\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8482\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8453\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8478\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8416\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8490\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8388\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8376\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3374 - binary_accuracy: 0.8478\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3384 - binary_accuracy: 0.8506\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8502\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8527\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3304 - binary_accuracy: 0.8527\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8420\n",
            "For the fold number  7 :\n",
            "loss =  0.3384532928466797 \n",
            "accuracy =  87.42856979370117 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6329 - binary_accuracy: 0.6792\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5638 - binary_accuracy: 0.7224\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5293 - binary_accuracy: 0.7416\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5043 - binary_accuracy: 0.7551\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4886 - binary_accuracy: 0.7624\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4705 - binary_accuracy: 0.7776\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.7882\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4443 - binary_accuracy: 0.7837\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.7829\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4369 - binary_accuracy: 0.7967\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4297 - binary_accuracy: 0.7988\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4264 - binary_accuracy: 0.8004\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4198 - binary_accuracy: 0.8049\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4137 - binary_accuracy: 0.8094\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8033\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4162 - binary_accuracy: 0.8098\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4046 - binary_accuracy: 0.8143\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4003 - binary_accuracy: 0.8216\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3969 - binary_accuracy: 0.8110\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8073\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4027 - binary_accuracy: 0.8122\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3932 - binary_accuracy: 0.8216\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3896 - binary_accuracy: 0.8208\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3871 - binary_accuracy: 0.8241\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3879 - binary_accuracy: 0.8212\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8261\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3844 - binary_accuracy: 0.8167\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8245\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3841 - binary_accuracy: 0.8269\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8257\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3790 - binary_accuracy: 0.8282\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3816 - binary_accuracy: 0.8224\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3770 - binary_accuracy: 0.8310\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8306\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3715 - binary_accuracy: 0.8355\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3651 - binary_accuracy: 0.8306\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3674 - binary_accuracy: 0.8314\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3580 - binary_accuracy: 0.8339\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3687 - binary_accuracy: 0.8298\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3636 - binary_accuracy: 0.8290\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3619 - binary_accuracy: 0.8318\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3612 - binary_accuracy: 0.8322\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3605 - binary_accuracy: 0.8335\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3587 - binary_accuracy: 0.8298\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3560 - binary_accuracy: 0.8437\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3515 - binary_accuracy: 0.8404\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3494 - binary_accuracy: 0.8400\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8376\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8408\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8400\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8457\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8429\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3408 - binary_accuracy: 0.8527\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8441\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8445\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3326 - binary_accuracy: 0.8522\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8420\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3412 - binary_accuracy: 0.8392\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3412 - binary_accuracy: 0.8445\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3399 - binary_accuracy: 0.8429\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8482\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3337 - binary_accuracy: 0.8522\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3317 - binary_accuracy: 0.8539\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3421 - binary_accuracy: 0.8355\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3321 - binary_accuracy: 0.8420\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3310 - binary_accuracy: 0.8543\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3204 - binary_accuracy: 0.8637\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3283 - binary_accuracy: 0.8461\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8461\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8416\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8551\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3412 - binary_accuracy: 0.8473\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3286 - binary_accuracy: 0.8571\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8527\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3259 - binary_accuracy: 0.8502\n",
            "For the fold number  8 :\n",
            "loss =  0.3392718732357025 \n",
            "accuracy =  83.71428847312927 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  4\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6364 - binary_accuracy: 0.6824\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5693 - binary_accuracy: 0.7229\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5424 - binary_accuracy: 0.7445\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5075 - binary_accuracy: 0.7580\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4865 - binary_accuracy: 0.7657\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4822 - binary_accuracy: 0.7673\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4740 - binary_accuracy: 0.7706\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4622 - binary_accuracy: 0.7829\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.7857\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4485 - binary_accuracy: 0.7824\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4378 - binary_accuracy: 0.7980\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4309 - binary_accuracy: 0.7894\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4261 - binary_accuracy: 0.8004\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4251 - binary_accuracy: 0.8049\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4229 - binary_accuracy: 0.8012\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4157 - binary_accuracy: 0.8057\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4200 - binary_accuracy: 0.8065\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4129 - binary_accuracy: 0.8057\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - binary_accuracy: 0.8110\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4061 - binary_accuracy: 0.8037\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.8200\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3996 - binary_accuracy: 0.8208\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4007 - binary_accuracy: 0.8216\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3990 - binary_accuracy: 0.8159\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3881 - binary_accuracy: 0.8245\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3924 - binary_accuracy: 0.8229\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8302\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3860 - binary_accuracy: 0.8261\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3799 - binary_accuracy: 0.8290\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3872 - binary_accuracy: 0.8237\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8208\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3807 - binary_accuracy: 0.8241\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3757 - binary_accuracy: 0.8253\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8253\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3739 - binary_accuracy: 0.8290\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3752 - binary_accuracy: 0.8273\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8371\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3751 - binary_accuracy: 0.8290\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3698 - binary_accuracy: 0.8318\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3644 - binary_accuracy: 0.8351\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8367\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8322\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3636 - binary_accuracy: 0.8294\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3677 - binary_accuracy: 0.8290\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8412\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8339\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8351\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3533 - binary_accuracy: 0.8449\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3561 - binary_accuracy: 0.8404\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8367\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3522 - binary_accuracy: 0.8404\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8371\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8449\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3499 - binary_accuracy: 0.8392\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8465\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8510\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8351\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3421 - binary_accuracy: 0.8514\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8473\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8355\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3408 - binary_accuracy: 0.8482\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8424\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3382 - binary_accuracy: 0.8482\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3496 - binary_accuracy: 0.8437\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8461\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8420\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3423 - binary_accuracy: 0.8478\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3379 - binary_accuracy: 0.8433\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8518\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3403 - binary_accuracy: 0.8400\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8453\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3321 - binary_accuracy: 0.8588\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3350 - binary_accuracy: 0.8502\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8531\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8486\n",
            "For the fold number  1 :\n",
            "loss =  0.41603198647499084 \n",
            "accuracy =  83.99999737739563 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6992 - binary_accuracy: 0.6057\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5883 - binary_accuracy: 0.6918\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5378 - binary_accuracy: 0.7302\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5148 - binary_accuracy: 0.7437\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4959 - binary_accuracy: 0.7571\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4858 - binary_accuracy: 0.7645\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4615 - binary_accuracy: 0.7714\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4618 - binary_accuracy: 0.7698\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4586 - binary_accuracy: 0.7845\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4506 - binary_accuracy: 0.7812\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.7808\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4382 - binary_accuracy: 0.7902\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4332 - binary_accuracy: 0.7988\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4360 - binary_accuracy: 0.7947\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4277 - binary_accuracy: 0.7894\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4219 - binary_accuracy: 0.8041\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4221 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4140 - binary_accuracy: 0.8061\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4160 - binary_accuracy: 0.8012\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4053 - binary_accuracy: 0.8086\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4109 - binary_accuracy: 0.8102\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4014 - binary_accuracy: 0.8159\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4021 - binary_accuracy: 0.8114\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3984 - binary_accuracy: 0.8131\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3999 - binary_accuracy: 0.8131\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4025 - binary_accuracy: 0.8139\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3973 - binary_accuracy: 0.8200\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3968 - binary_accuracy: 0.8249\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3945 - binary_accuracy: 0.8188\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8245\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3904 - binary_accuracy: 0.8253\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3842 - binary_accuracy: 0.8171\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8294\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3873 - binary_accuracy: 0.8278\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3918 - binary_accuracy: 0.8167\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3875 - binary_accuracy: 0.8261\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8245\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8167\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3778 - binary_accuracy: 0.8294\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3796 - binary_accuracy: 0.8204\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3791 - binary_accuracy: 0.8294\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3730 - binary_accuracy: 0.8380\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3703 - binary_accuracy: 0.8347\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8314\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3632 - binary_accuracy: 0.8376\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8420\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8335\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3655 - binary_accuracy: 0.8322\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3619 - binary_accuracy: 0.8437\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3586 - binary_accuracy: 0.8327\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8380\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3600 - binary_accuracy: 0.8367\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8404\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8355\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3653 - binary_accuracy: 0.8347\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3640 - binary_accuracy: 0.8327\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3653 - binary_accuracy: 0.8392\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3606 - binary_accuracy: 0.8343\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8392\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8371\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8453\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8343\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8396\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3539 - binary_accuracy: 0.8404\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8404\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3493 - binary_accuracy: 0.8490\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8424\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3408 - binary_accuracy: 0.8535\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8457\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8408\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3410 - binary_accuracy: 0.8457\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8437\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8457\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8510\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3398 - binary_accuracy: 0.8502\n",
            "For the fold number  2 :\n",
            "loss =  0.3810684084892273 \n",
            "accuracy =  83.71428847312927 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6402 - binary_accuracy: 0.6837\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5676 - binary_accuracy: 0.7327\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5340 - binary_accuracy: 0.7433\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5171 - binary_accuracy: 0.7576\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4969 - binary_accuracy: 0.7633\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4810 - binary_accuracy: 0.7718\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4607 - binary_accuracy: 0.7673\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4650 - binary_accuracy: 0.7771\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4539 - binary_accuracy: 0.7865\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4387 - binary_accuracy: 0.7861\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4401 - binary_accuracy: 0.7894\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4359 - binary_accuracy: 0.7980\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4326 - binary_accuracy: 0.7971\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4259 - binary_accuracy: 0.7886\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7959\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4165 - binary_accuracy: 0.8029\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4080 - binary_accuracy: 0.8049\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4125 - binary_accuracy: 0.8049\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4088 - binary_accuracy: 0.8053\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4031 - binary_accuracy: 0.8053\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4027 - binary_accuracy: 0.8057\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4035 - binary_accuracy: 0.8078\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4045 - binary_accuracy: 0.8045\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3885 - binary_accuracy: 0.8176\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3885 - binary_accuracy: 0.8139\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3851 - binary_accuracy: 0.8245\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3841 - binary_accuracy: 0.8273\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3827 - binary_accuracy: 0.8122\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3856 - binary_accuracy: 0.8229\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3678 - binary_accuracy: 0.8286\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3744 - binary_accuracy: 0.8273\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3744 - binary_accuracy: 0.8200\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3743 - binary_accuracy: 0.8278\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8237\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8265\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3641 - binary_accuracy: 0.8265\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3709 - binary_accuracy: 0.8220\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3636 - binary_accuracy: 0.8290\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3713 - binary_accuracy: 0.8224\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3675 - binary_accuracy: 0.8282\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3543 - binary_accuracy: 0.8449\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3707 - binary_accuracy: 0.8261\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8302\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3582 - binary_accuracy: 0.8396\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3651 - binary_accuracy: 0.8339\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3518 - binary_accuracy: 0.8359\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3544 - binary_accuracy: 0.8359\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3639 - binary_accuracy: 0.8290\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3580 - binary_accuracy: 0.8339\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3541 - binary_accuracy: 0.8355\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8339\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8388\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8437\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8396\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8351\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8388\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8424\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3463 - binary_accuracy: 0.8380\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8363\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3468 - binary_accuracy: 0.8347\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8441\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3508 - binary_accuracy: 0.8359\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3322 - binary_accuracy: 0.8457\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8420\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3376 - binary_accuracy: 0.8449\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3375 - binary_accuracy: 0.8445\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3323 - binary_accuracy: 0.8522\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8522\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3311 - binary_accuracy: 0.8408\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3348 - binary_accuracy: 0.8453\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8494\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3376 - binary_accuracy: 0.8396\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8490\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3344 - binary_accuracy: 0.8518\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3286 - binary_accuracy: 0.8473\n",
            "For the fold number  3 :\n",
            "loss =  0.3727656304836273 \n",
            "accuracy =  83.42857360839844 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6835 - binary_accuracy: 0.6200\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5891 - binary_accuracy: 0.7041\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5590 - binary_accuracy: 0.7278\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5323 - binary_accuracy: 0.7437\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5270 - binary_accuracy: 0.7380\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4995 - binary_accuracy: 0.7535\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4969 - binary_accuracy: 0.7555\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4755 - binary_accuracy: 0.7735\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4775 - binary_accuracy: 0.7739\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4668 - binary_accuracy: 0.7776\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.7767\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4555 - binary_accuracy: 0.7833\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.7918\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.7841\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4366 - binary_accuracy: 0.7951\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4361 - binary_accuracy: 0.7931\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4276 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4278 - binary_accuracy: 0.8008\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4216 - binary_accuracy: 0.8004\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4166 - binary_accuracy: 0.8069\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4228 - binary_accuracy: 0.7943\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4083 - binary_accuracy: 0.8045\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4108 - binary_accuracy: 0.8053\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8053\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4130 - binary_accuracy: 0.7996\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4084 - binary_accuracy: 0.8029\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.8098\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4021 - binary_accuracy: 0.8131\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3903 - binary_accuracy: 0.8216\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3858 - binary_accuracy: 0.8204\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3931 - binary_accuracy: 0.8135\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3907 - binary_accuracy: 0.8159\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3809 - binary_accuracy: 0.8261\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3821 - binary_accuracy: 0.8318\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8204\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3839 - binary_accuracy: 0.8229\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3791 - binary_accuracy: 0.8233\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8196\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3796 - binary_accuracy: 0.8220\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3714 - binary_accuracy: 0.8380\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3679 - binary_accuracy: 0.8343\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3686 - binary_accuracy: 0.8278\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8310\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3653 - binary_accuracy: 0.8396\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3738 - binary_accuracy: 0.8327\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3655 - binary_accuracy: 0.8367\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3631 - binary_accuracy: 0.8400\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_accuracy: 0.8355\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3663 - binary_accuracy: 0.8314\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8306\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8380\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8318\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8314\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3575 - binary_accuracy: 0.8449\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3480 - binary_accuracy: 0.8408\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8486\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8445\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8416\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8388\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8392\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8416\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3453 - binary_accuracy: 0.8376\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3534 - binary_accuracy: 0.8424\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8412\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8449\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8384\n",
            "For the fold number  4 :\n",
            "loss =  0.3640318810939789 \n",
            "accuracy =  81.14285469055176 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7641 - binary_accuracy: 0.5820\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6225 - binary_accuracy: 0.6869\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5762 - binary_accuracy: 0.7192\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5491 - binary_accuracy: 0.7355\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5321 - binary_accuracy: 0.7518\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5172 - binary_accuracy: 0.7543\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4887 - binary_accuracy: 0.7763\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4915 - binary_accuracy: 0.7694\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4764 - binary_accuracy: 0.7706\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4716 - binary_accuracy: 0.7763\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4609 - binary_accuracy: 0.7841\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.7890\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4398 - binary_accuracy: 0.7943\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4450 - binary_accuracy: 0.7886\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4382 - binary_accuracy: 0.7967\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4321 - binary_accuracy: 0.7980\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4234 - binary_accuracy: 0.8029\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4234 - binary_accuracy: 0.8082\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4202 - binary_accuracy: 0.8065\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8049\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4185 - binary_accuracy: 0.8086\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4100 - binary_accuracy: 0.8139\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4036 - binary_accuracy: 0.8167\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3967 - binary_accuracy: 0.8155\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4079 - binary_accuracy: 0.8135\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8163\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3999 - binary_accuracy: 0.8155\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8159\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3882 - binary_accuracy: 0.8265\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3848 - binary_accuracy: 0.8135\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8176\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3826 - binary_accuracy: 0.8220\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_accuracy: 0.8208\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8335\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8278\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8347\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3737 - binary_accuracy: 0.8331\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3745 - binary_accuracy: 0.8290\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3722 - binary_accuracy: 0.8261\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3754 - binary_accuracy: 0.8302\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.8314\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8449\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3580 - binary_accuracy: 0.8371\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3522 - binary_accuracy: 0.8388\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8335\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8371\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3480 - binary_accuracy: 0.8441\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3582 - binary_accuracy: 0.8384\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3572 - binary_accuracy: 0.8351\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3598 - binary_accuracy: 0.8380\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3494 - binary_accuracy: 0.8449\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8441\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3574 - binary_accuracy: 0.8363\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8412\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3580 - binary_accuracy: 0.8416\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8453\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8404\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8465\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8522\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3536 - binary_accuracy: 0.8371\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3449 - binary_accuracy: 0.8469\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8453\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3399 - binary_accuracy: 0.8486\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8469\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3456 - binary_accuracy: 0.8404\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8351\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3421 - binary_accuracy: 0.8376\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8510\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3390 - binary_accuracy: 0.8490\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3283 - binary_accuracy: 0.8584\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3300 - binary_accuracy: 0.8637\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8449\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8547\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3352 - binary_accuracy: 0.8490\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3315 - binary_accuracy: 0.8551\n",
            "For the fold number  5 :\n",
            "loss =  0.3835996389389038 \n",
            "accuracy =  82.85714387893677 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 0.6792 - binary_accuracy: 0.6318\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5916 - binary_accuracy: 0.6922\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5508 - binary_accuracy: 0.7257\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5252 - binary_accuracy: 0.7392\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5034 - binary_accuracy: 0.7629\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4801 - binary_accuracy: 0.7792\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4835 - binary_accuracy: 0.7645\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4611 - binary_accuracy: 0.7857\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4550 - binary_accuracy: 0.7776\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.7878\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.7927\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4341 - binary_accuracy: 0.7988\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4297 - binary_accuracy: 0.7939\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4289 - binary_accuracy: 0.7922\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4263 - binary_accuracy: 0.7996\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - binary_accuracy: 0.8082\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4095 - binary_accuracy: 0.8143\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4071 - binary_accuracy: 0.8135\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4065 - binary_accuracy: 0.8163\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8118\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4089 - binary_accuracy: 0.8118\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4018 - binary_accuracy: 0.8110\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3990 - binary_accuracy: 0.8122\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3927 - binary_accuracy: 0.8216\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3874 - binary_accuracy: 0.8257\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8155\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3821 - binary_accuracy: 0.8249\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3912 - binary_accuracy: 0.8237\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8224\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8290\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3744 - binary_accuracy: 0.8322\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3754 - binary_accuracy: 0.8245\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8314\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3807 - binary_accuracy: 0.8224\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3684 - binary_accuracy: 0.8310\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3729 - binary_accuracy: 0.8327\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8351\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3638 - binary_accuracy: 0.8339\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3690 - binary_accuracy: 0.8355\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3601 - binary_accuracy: 0.8351\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3614 - binary_accuracy: 0.8339\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8294\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8433\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3516 - binary_accuracy: 0.8416\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8449\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8449\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8429\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8441\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3549 - binary_accuracy: 0.8416\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3438 - binary_accuracy: 0.8445\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8441\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8457\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8420\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3530 - binary_accuracy: 0.8367\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8412\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8453\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.8482\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8408\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8351\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8461\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8490\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8514\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8433\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8473\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3368 - binary_accuracy: 0.8469\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3306 - binary_accuracy: 0.8498\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3367 - binary_accuracy: 0.8449\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8498\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3339 - binary_accuracy: 0.8543\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8490\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3263 - binary_accuracy: 0.8600\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3251 - binary_accuracy: 0.8555\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8486\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3293 - binary_accuracy: 0.8551\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3273 - binary_accuracy: 0.8490\n",
            "For the fold number  6 :\n",
            "loss =  0.35469189286231995 \n",
            "accuracy =  79.42857146263123 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7461 - binary_accuracy: 0.5604\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6169 - binary_accuracy: 0.6735\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5721 - binary_accuracy: 0.7110\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5243 - binary_accuracy: 0.7469\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5023 - binary_accuracy: 0.7555\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4968 - binary_accuracy: 0.7510\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4823 - binary_accuracy: 0.7710\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4622 - binary_accuracy: 0.7673\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4609 - binary_accuracy: 0.7763\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4518 - binary_accuracy: 0.7849\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.7788\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4408 - binary_accuracy: 0.7861\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4349 - binary_accuracy: 0.7869\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4361 - binary_accuracy: 0.7927\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4268 - binary_accuracy: 0.7939\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4301 - binary_accuracy: 0.8020\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4240 - binary_accuracy: 0.8024\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4264 - binary_accuracy: 0.8012\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8086\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_accuracy: 0.8114\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4048 - binary_accuracy: 0.8098\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8094\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8131\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_accuracy: 0.8110\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3995 - binary_accuracy: 0.8192\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3997 - binary_accuracy: 0.8131\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3934 - binary_accuracy: 0.8192\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3978 - binary_accuracy: 0.8196\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3975 - binary_accuracy: 0.8163\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3850 - binary_accuracy: 0.8237\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8216\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3876 - binary_accuracy: 0.8143\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8282\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3833 - binary_accuracy: 0.8196\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3784 - binary_accuracy: 0.8306\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3818 - binary_accuracy: 0.8249\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8343\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8314\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3820 - binary_accuracy: 0.8233\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3784 - binary_accuracy: 0.8233\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8257\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3698 - binary_accuracy: 0.8359\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3675 - binary_accuracy: 0.8294\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3649 - binary_accuracy: 0.8306\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3666 - binary_accuracy: 0.8241\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3563 - binary_accuracy: 0.8376\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3730 - binary_accuracy: 0.8306\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3662 - binary_accuracy: 0.8355\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3538 - binary_accuracy: 0.8400\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8429\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3685 - binary_accuracy: 0.8335\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3581 - binary_accuracy: 0.8367\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8392\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3461 - binary_accuracy: 0.8441\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8367\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3488 - binary_accuracy: 0.8424\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8433\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3601 - binary_accuracy: 0.8343\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8400\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8392\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3410 - binary_accuracy: 0.8441\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8482\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3558 - binary_accuracy: 0.8367\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8384\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8433\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8535\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8461\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8486\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8363\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8437\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3410 - binary_accuracy: 0.8482\n",
            "For the fold number  7 :\n",
            "loss =  0.39110666513442993 \n",
            "accuracy =  82.85714387893677 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 0.6352 - binary_accuracy: 0.6522\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5596 - binary_accuracy: 0.7147\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5352 - binary_accuracy: 0.7351\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5136 - binary_accuracy: 0.7555\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4967 - binary_accuracy: 0.7669\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4840 - binary_accuracy: 0.7710\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.7682\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.7833\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4475 - binary_accuracy: 0.7951\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.7829\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4390 - binary_accuracy: 0.7984\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4357 - binary_accuracy: 0.7959\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4279 - binary_accuracy: 0.7996\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4335 - binary_accuracy: 0.7992\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8053\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4174 - binary_accuracy: 0.8029\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4219 - binary_accuracy: 0.8004\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4122 - binary_accuracy: 0.8139\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4119 - binary_accuracy: 0.8135\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4106 - binary_accuracy: 0.8065\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4030 - binary_accuracy: 0.8151\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4023 - binary_accuracy: 0.8102\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4018 - binary_accuracy: 0.8151\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4032 - binary_accuracy: 0.8045\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3920 - binary_accuracy: 0.8212\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4020 - binary_accuracy: 0.8147\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4004 - binary_accuracy: 0.8171\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3959 - binary_accuracy: 0.8139\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8286\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3987 - binary_accuracy: 0.8163\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3864 - binary_accuracy: 0.8192\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3895 - binary_accuracy: 0.8278\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3767 - binary_accuracy: 0.8204\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3843 - binary_accuracy: 0.8192\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3885 - binary_accuracy: 0.8208\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3759 - binary_accuracy: 0.8278\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3715 - binary_accuracy: 0.8310\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3823 - binary_accuracy: 0.8241\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3745 - binary_accuracy: 0.8310\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3720 - binary_accuracy: 0.8331\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3681 - binary_accuracy: 0.8355\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3640 - binary_accuracy: 0.8331\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3683 - binary_accuracy: 0.8327\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3571 - binary_accuracy: 0.8388\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3617 - binary_accuracy: 0.8327\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8310\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8392\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3589 - binary_accuracy: 0.8343\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8327\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8359\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8278\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3524 - binary_accuracy: 0.8367\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3540 - binary_accuracy: 0.8384\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8335\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3556 - binary_accuracy: 0.8355\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8355\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8376\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8339\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8327\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3476 - binary_accuracy: 0.8429\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8388\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3443 - binary_accuracy: 0.8486\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3462 - binary_accuracy: 0.8437\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8437\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3481 - binary_accuracy: 0.8404\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8404\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8441\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3440 - binary_accuracy: 0.8380\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3351 - binary_accuracy: 0.8514\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8392\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8424\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8424\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.8420\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3359 - binary_accuracy: 0.8490\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8461\n",
            "For the fold number  8 :\n",
            "loss =  0.3353939354419708 \n",
            "accuracy =  83.1428587436676 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  5\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6457 - binary_accuracy: 0.6408\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5735 - binary_accuracy: 0.7241\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5422 - binary_accuracy: 0.7478\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5179 - binary_accuracy: 0.7527\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5056 - binary_accuracy: 0.7624\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4888 - binary_accuracy: 0.7698\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4827 - binary_accuracy: 0.7755\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4747 - binary_accuracy: 0.7759\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4601 - binary_accuracy: 0.7784\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4466 - binary_accuracy: 0.7833\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.7849\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4453 - binary_accuracy: 0.7865\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4384 - binary_accuracy: 0.7947\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4300 - binary_accuracy: 0.7996\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4234 - binary_accuracy: 0.7996\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4243 - binary_accuracy: 0.8033\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4130 - binary_accuracy: 0.8078\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4070 - binary_accuracy: 0.8155\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4128 - binary_accuracy: 0.8147\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4097 - binary_accuracy: 0.8106\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4115 - binary_accuracy: 0.8114\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4112 - binary_accuracy: 0.7988\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3995 - binary_accuracy: 0.8135\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3917 - binary_accuracy: 0.8188\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3890 - binary_accuracy: 0.8196\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3878 - binary_accuracy: 0.8196\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3921 - binary_accuracy: 0.8196\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3858 - binary_accuracy: 0.8229\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3881 - binary_accuracy: 0.8184\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3880 - binary_accuracy: 0.8180\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3820 - binary_accuracy: 0.8290\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3755 - binary_accuracy: 0.8261\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3740 - binary_accuracy: 0.8282\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8253\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3721 - binary_accuracy: 0.8290\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3842 - binary_accuracy: 0.8233\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8224\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8318\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3763 - binary_accuracy: 0.8278\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3681 - binary_accuracy: 0.8294\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3634 - binary_accuracy: 0.8322\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3655 - binary_accuracy: 0.8376\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8384\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8347\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3616 - binary_accuracy: 0.8335\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8392\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3640 - binary_accuracy: 0.8355\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8371\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8367\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3520 - binary_accuracy: 0.8473\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8392\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8449\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3581 - binary_accuracy: 0.8367\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8437\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8424\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3476 - binary_accuracy: 0.8420\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8437\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8339\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8351\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8437\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8473\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8404\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3488 - binary_accuracy: 0.8457\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8400\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3432 - binary_accuracy: 0.8510\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8433\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8502\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3395 - binary_accuracy: 0.8527\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8441\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8522\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8384\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3370 - binary_accuracy: 0.8424\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3366 - binary_accuracy: 0.8518\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8457\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3409 - binary_accuracy: 0.8424\n",
            "For the fold number  1 :\n",
            "loss =  0.32521358132362366 \n",
            "accuracy =  84.28571224212646 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6062 - binary_accuracy: 0.6747\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5430 - binary_accuracy: 0.7286\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5095 - binary_accuracy: 0.7408\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5081 - binary_accuracy: 0.7563\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4914 - binary_accuracy: 0.7637\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.7727\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4701 - binary_accuracy: 0.7710\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4570 - binary_accuracy: 0.7861\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.7816\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.7910\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4340 - binary_accuracy: 0.8008\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4340 - binary_accuracy: 0.8012\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4238 - binary_accuracy: 0.8037\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4259 - binary_accuracy: 0.8024\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4224 - binary_accuracy: 0.8065\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8041\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8127\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8082\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4079 - binary_accuracy: 0.8061\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4000 - binary_accuracy: 0.8216\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4032 - binary_accuracy: 0.8151\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3989 - binary_accuracy: 0.8159\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3914 - binary_accuracy: 0.8224\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3964 - binary_accuracy: 0.8224\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3934 - binary_accuracy: 0.8216\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8204\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3824 - binary_accuracy: 0.8265\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3800 - binary_accuracy: 0.8302\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3861 - binary_accuracy: 0.8261\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3750 - binary_accuracy: 0.8290\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3714 - binary_accuracy: 0.8384\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3753 - binary_accuracy: 0.8290\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3720 - binary_accuracy: 0.8310\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3767 - binary_accuracy: 0.8347\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8318\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8278\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3646 - binary_accuracy: 0.8367\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3705 - binary_accuracy: 0.8339\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8327\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3615 - binary_accuracy: 0.8343\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3621 - binary_accuracy: 0.8388\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8441\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8327\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3630 - binary_accuracy: 0.8396\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8461\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3611 - binary_accuracy: 0.8282\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3598 - binary_accuracy: 0.8412\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8327\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3532 - binary_accuracy: 0.8437\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8433\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8310\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8339\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8286\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8367\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8506\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8502\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3421 - binary_accuracy: 0.8465\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8482\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3404 - binary_accuracy: 0.8490\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8461\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8469\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8482\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8527\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3248 - binary_accuracy: 0.8629\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3287 - binary_accuracy: 0.8571\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3255 - binary_accuracy: 0.8518\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3412 - binary_accuracy: 0.8510\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3359 - binary_accuracy: 0.8531\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8510\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3321 - binary_accuracy: 0.8559\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3307 - binary_accuracy: 0.8457\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3317 - binary_accuracy: 0.8478\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3284 - binary_accuracy: 0.8531\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8567\n",
            "For the fold number  2 :\n",
            "loss =  0.360390305519104 \n",
            "accuracy =  81.14285469055176 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7939 - binary_accuracy: 0.5253\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6300 - binary_accuracy: 0.6571\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5626 - binary_accuracy: 0.7049\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5255 - binary_accuracy: 0.7359\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5050 - binary_accuracy: 0.7518\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5048 - binary_accuracy: 0.7580\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4847 - binary_accuracy: 0.7653\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4838 - binary_accuracy: 0.7686\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4639 - binary_accuracy: 0.7865\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4598 - binary_accuracy: 0.7759\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4437 - binary_accuracy: 0.7869\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.7829\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4318 - binary_accuracy: 0.8000\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4356 - binary_accuracy: 0.7890\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4188 - binary_accuracy: 0.8057\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4288 - binary_accuracy: 0.7988\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4295 - binary_accuracy: 0.7959\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4144 - binary_accuracy: 0.8049\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4159 - binary_accuracy: 0.8012\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4041 - binary_accuracy: 0.8122\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4073 - binary_accuracy: 0.8008\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8086\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4063 - binary_accuracy: 0.8082\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4055 - binary_accuracy: 0.8061\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3938 - binary_accuracy: 0.8176\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3930 - binary_accuracy: 0.8216\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3982 - binary_accuracy: 0.8143\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3889 - binary_accuracy: 0.8253\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3909 - binary_accuracy: 0.8167\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3806 - binary_accuracy: 0.8269\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3876 - binary_accuracy: 0.8216\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3776 - binary_accuracy: 0.8261\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3750 - binary_accuracy: 0.8269\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3805 - binary_accuracy: 0.8196\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3748 - binary_accuracy: 0.8282\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8200\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3741 - binary_accuracy: 0.8322\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3733 - binary_accuracy: 0.8265\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8208\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3679 - binary_accuracy: 0.8290\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3709 - binary_accuracy: 0.8286\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3683 - binary_accuracy: 0.8335\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3670 - binary_accuracy: 0.8351\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3661 - binary_accuracy: 0.8327\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3620 - binary_accuracy: 0.8335\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8371\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8380\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3633 - binary_accuracy: 0.8237\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3627 - binary_accuracy: 0.8351\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3542 - binary_accuracy: 0.8302\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8392\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3704 - binary_accuracy: 0.8278\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8465\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8392\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8335\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8318\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8376\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8400\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3525 - binary_accuracy: 0.8351\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8396\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8331\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8388\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8384\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8376\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3420 - binary_accuracy: 0.8335\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8465\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3402 - binary_accuracy: 0.8469\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8469\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8453\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8514\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8408\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8486\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3538 - binary_accuracy: 0.8404\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8441\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8445\n",
            "For the fold number  3 :\n",
            "loss =  0.3375031352043152 \n",
            "accuracy =  85.71428656578064 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7487 - binary_accuracy: 0.5763\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6112 - binary_accuracy: 0.6816\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5582 - binary_accuracy: 0.7241\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5242 - binary_accuracy: 0.7571\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5142 - binary_accuracy: 0.7465\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4996 - binary_accuracy: 0.7604\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4909 - binary_accuracy: 0.7620\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4658 - binary_accuracy: 0.7796\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4628 - binary_accuracy: 0.7833\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4564 - binary_accuracy: 0.7800\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4463 - binary_accuracy: 0.7890\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4400 - binary_accuracy: 0.7955\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4342 - binary_accuracy: 0.7935\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4284 - binary_accuracy: 0.7898\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4306 - binary_accuracy: 0.7992\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4244 - binary_accuracy: 0.8045\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8188\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8041\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4116 - binary_accuracy: 0.8171\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4140 - binary_accuracy: 0.8049\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4077 - binary_accuracy: 0.8151\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8094\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8192\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3987 - binary_accuracy: 0.8184\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3949 - binary_accuracy: 0.8224\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4014 - binary_accuracy: 0.8122\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3980 - binary_accuracy: 0.8184\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3927 - binary_accuracy: 0.8233\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3879 - binary_accuracy: 0.8220\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3786 - binary_accuracy: 0.8265\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3875 - binary_accuracy: 0.8265\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8380\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3833 - binary_accuracy: 0.8302\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8241\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3846 - binary_accuracy: 0.8233\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3818 - binary_accuracy: 0.8306\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3821 - binary_accuracy: 0.8212\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3716 - binary_accuracy: 0.8343\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3732 - binary_accuracy: 0.8367\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8257\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8286\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3724 - binary_accuracy: 0.8335\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3693 - binary_accuracy: 0.8318\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8331\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3677 - binary_accuracy: 0.8363\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3710 - binary_accuracy: 0.8322\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8363\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3596 - binary_accuracy: 0.8347\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3660 - binary_accuracy: 0.8322\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_accuracy: 0.8388\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3588 - binary_accuracy: 0.8465\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8380\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8380\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3560 - binary_accuracy: 0.8400\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3582 - binary_accuracy: 0.8339\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8433\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8408\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3556 - binary_accuracy: 0.8380\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3479 - binary_accuracy: 0.8449\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8416\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8420\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8461\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8416\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3496 - binary_accuracy: 0.8343\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8363\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8416\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8424\n",
            "For the fold number  4 :\n",
            "loss =  0.5091797113418579 \n",
            "accuracy =  83.1428587436676 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 0.6341 - binary_accuracy: 0.6649\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5612 - binary_accuracy: 0.7167\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5355 - binary_accuracy: 0.7306\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5112 - binary_accuracy: 0.7429\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4960 - binary_accuracy: 0.7498\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4696 - binary_accuracy: 0.7829\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4617 - binary_accuracy: 0.7755\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4630 - binary_accuracy: 0.7780\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.7869\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.7922\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4270 - binary_accuracy: 0.8004\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4278 - binary_accuracy: 0.8086\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4302 - binary_accuracy: 0.8004\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4291 - binary_accuracy: 0.7951\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.8061\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4139 - binary_accuracy: 0.8110\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4204 - binary_accuracy: 0.7988\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4157 - binary_accuracy: 0.8045\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4077 - binary_accuracy: 0.8069\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3962 - binary_accuracy: 0.8212\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3974 - binary_accuracy: 0.8151\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3890 - binary_accuracy: 0.8286\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3965 - binary_accuracy: 0.8110\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3906 - binary_accuracy: 0.8233\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3955 - binary_accuracy: 0.8135\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3924 - binary_accuracy: 0.8208\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3850 - binary_accuracy: 0.8241\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3795 - binary_accuracy: 0.8224\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3800 - binary_accuracy: 0.8220\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3843 - binary_accuracy: 0.8176\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3834 - binary_accuracy: 0.8290\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3757 - binary_accuracy: 0.8298\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3782 - binary_accuracy: 0.8302\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8212\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3695 - binary_accuracy: 0.8322\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3669 - binary_accuracy: 0.8380\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3636 - binary_accuracy: 0.8445\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3710 - binary_accuracy: 0.8302\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8318\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8310\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3704 - binary_accuracy: 0.8302\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.8278\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8396\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8331\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3628 - binary_accuracy: 0.8384\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3642 - binary_accuracy: 0.8343\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8331\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3565 - binary_accuracy: 0.8327\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8388\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3537 - binary_accuracy: 0.8355\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3548 - binary_accuracy: 0.8376\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8469\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3569 - binary_accuracy: 0.8371\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3591 - binary_accuracy: 0.8429\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8502\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3530 - binary_accuracy: 0.8453\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3569 - binary_accuracy: 0.8388\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3456 - binary_accuracy: 0.8461\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3434 - binary_accuracy: 0.8408\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3427 - binary_accuracy: 0.8502\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3389 - binary_accuracy: 0.8486\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3455 - binary_accuracy: 0.8494\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3447 - binary_accuracy: 0.8514\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3465 - binary_accuracy: 0.8445\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3403 - binary_accuracy: 0.8543\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3400 - binary_accuracy: 0.8469\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3412 - binary_accuracy: 0.8457\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3392 - binary_accuracy: 0.8494\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3393 - binary_accuracy: 0.8355\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8449\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3391 - binary_accuracy: 0.8449\n",
            "For the fold number  5 :\n",
            "loss =  0.3795791566371918 \n",
            "accuracy =  83.99999737739563 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7345 - binary_accuracy: 0.5755\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6083 - binary_accuracy: 0.6763\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5478 - binary_accuracy: 0.7396\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5328 - binary_accuracy: 0.7416\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5171 - binary_accuracy: 0.7633\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4974 - binary_accuracy: 0.7624\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4769 - binary_accuracy: 0.7780\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4777 - binary_accuracy: 0.7735\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.7890\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4547 - binary_accuracy: 0.7788\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.7902\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.8000\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4365 - binary_accuracy: 0.7955\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4227 - binary_accuracy: 0.8041\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4202 - binary_accuracy: 0.8086\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8024\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4214 - binary_accuracy: 0.8033\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4080 - binary_accuracy: 0.8139\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.4111 - binary_accuracy: 0.8029\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.4046 - binary_accuracy: 0.8098\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.4039 - binary_accuracy: 0.8118\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3994 - binary_accuracy: 0.8204\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3987 - binary_accuracy: 0.8273\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3966 - binary_accuracy: 0.8241\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3959 - binary_accuracy: 0.8139\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3833 - binary_accuracy: 0.8241\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3900 - binary_accuracy: 0.8208\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3958 - binary_accuracy: 0.8159\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 1s 12ms/step - loss: 0.3801 - binary_accuracy: 0.8237\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 1s 11ms/step - loss: 0.3882 - binary_accuracy: 0.8241\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3820 - binary_accuracy: 0.8224\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3803 - binary_accuracy: 0.8273\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3739 - binary_accuracy: 0.8335\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3786 - binary_accuracy: 0.8286\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8261\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3761 - binary_accuracy: 0.8318\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3678 - binary_accuracy: 0.8412\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3816 - binary_accuracy: 0.8298\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8343\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3686 - binary_accuracy: 0.8359\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8384\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.8261\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3667 - binary_accuracy: 0.8388\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3656 - binary_accuracy: 0.8343\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8371\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3694 - binary_accuracy: 0.8322\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3561 - binary_accuracy: 0.8437\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8433\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3511 - binary_accuracy: 0.8404\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3602 - binary_accuracy: 0.8371\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8400\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3588 - binary_accuracy: 0.8355\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8404\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8429\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3594 - binary_accuracy: 0.8412\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8412\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8453\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8437\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8429\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3515 - binary_accuracy: 0.8408\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3474 - binary_accuracy: 0.8408\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3531 - binary_accuracy: 0.8433\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8453\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8514\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3420 - binary_accuracy: 0.8490\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8510\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8604\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3371 - binary_accuracy: 0.8510\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3497 - binary_accuracy: 0.8445\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3480 - binary_accuracy: 0.8486\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3390 - binary_accuracy: 0.8514\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3417 - binary_accuracy: 0.8510\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3287 - binary_accuracy: 0.8547\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3335 - binary_accuracy: 0.8535\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3410 - binary_accuracy: 0.8527\n",
            "For the fold number  6 :\n",
            "loss =  0.35786786675453186 \n",
            "accuracy =  84.85714197158813 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 0.7412 - binary_accuracy: 0.5694\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6092 - binary_accuracy: 0.6824\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5649 - binary_accuracy: 0.7233\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5147 - binary_accuracy: 0.7527\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5145 - binary_accuracy: 0.7522\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4879 - binary_accuracy: 0.7641\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4730 - binary_accuracy: 0.7747\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4741 - binary_accuracy: 0.7808\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4598 - binary_accuracy: 0.7861\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.7971\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4442 - binary_accuracy: 0.7943\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.7939\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.7906\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4353 - binary_accuracy: 0.7963\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4263 - binary_accuracy: 0.7959\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8057\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4238 - binary_accuracy: 0.8000\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8078\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4101 - binary_accuracy: 0.8163\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4129 - binary_accuracy: 0.8033\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4013 - binary_accuracy: 0.8180\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3991 - binary_accuracy: 0.8184\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4042 - binary_accuracy: 0.8176\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.4027 - binary_accuracy: 0.8118\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3850 - binary_accuracy: 0.8282\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 1s 10ms/step - loss: 0.3933 - binary_accuracy: 0.8180\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.3863 - binary_accuracy: 0.8212\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.3920 - binary_accuracy: 0.8212\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3883 - binary_accuracy: 0.8167\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3940 - binary_accuracy: 0.8167\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3867 - binary_accuracy: 0.8273\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3816 - binary_accuracy: 0.8233\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3750 - binary_accuracy: 0.8314\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3849 - binary_accuracy: 0.8310\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3856 - binary_accuracy: 0.8143\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.3715 - binary_accuracy: 0.8302\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.3804 - binary_accuracy: 0.8224\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 1s 9ms/step - loss: 0.3685 - binary_accuracy: 0.8351\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 1s 19ms/step - loss: 0.3691 - binary_accuracy: 0.8327\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 1s 10ms/step - loss: 0.3681 - binary_accuracy: 0.8302\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3717 - binary_accuracy: 0.8290\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3707 - binary_accuracy: 0.8306\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3646 - binary_accuracy: 0.8335\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3689 - binary_accuracy: 0.8212\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3717 - binary_accuracy: 0.8363\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.3692 - binary_accuracy: 0.8327\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3631 - binary_accuracy: 0.8327\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3595 - binary_accuracy: 0.8343\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3593 - binary_accuracy: 0.8404\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3568 - binary_accuracy: 0.8404\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.3495 - binary_accuracy: 0.8429\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.3663 - binary_accuracy: 0.8322\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3564 - binary_accuracy: 0.8437\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3586 - binary_accuracy: 0.8416\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8408\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8429\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3486 - binary_accuracy: 0.8371\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8380\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8473\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3472 - binary_accuracy: 0.8498\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3530 - binary_accuracy: 0.8420\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8380\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8461\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3589 - binary_accuracy: 0.8392\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8420\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3458 - binary_accuracy: 0.8506\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8433\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8449\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3288 - binary_accuracy: 0.8559\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8482\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3443 - binary_accuracy: 0.8502\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8384\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3463 - binary_accuracy: 0.8433\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8522\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3307 - binary_accuracy: 0.8567\n",
            "For the fold number  7 :\n",
            "loss =  0.35402873158454895 \n",
            "accuracy =  83.71428847312927 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/75\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.6693 - binary_accuracy: 0.6698\n",
            "Epoch 2/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5856 - binary_accuracy: 0.7176\n",
            "Epoch 3/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5356 - binary_accuracy: 0.7400\n",
            "Epoch 4/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5206 - binary_accuracy: 0.7555\n",
            "Epoch 5/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4914 - binary_accuracy: 0.7637\n",
            "Epoch 6/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4873 - binary_accuracy: 0.7665\n",
            "Epoch 7/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4828 - binary_accuracy: 0.7633\n",
            "Epoch 8/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4699 - binary_accuracy: 0.7808\n",
            "Epoch 9/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.7829\n",
            "Epoch 10/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4525 - binary_accuracy: 0.7918\n",
            "Epoch 11/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4480 - binary_accuracy: 0.7943\n",
            "Epoch 12/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4426 - binary_accuracy: 0.7955\n",
            "Epoch 13/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4385 - binary_accuracy: 0.8045\n",
            "Epoch 14/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4387 - binary_accuracy: 0.7967\n",
            "Epoch 15/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4276 - binary_accuracy: 0.8086\n",
            "Epoch 16/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4232 - binary_accuracy: 0.8024\n",
            "Epoch 17/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4225 - binary_accuracy: 0.8004\n",
            "Epoch 18/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4221 - binary_accuracy: 0.8016\n",
            "Epoch 19/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4146 - binary_accuracy: 0.8110\n",
            "Epoch 20/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4141 - binary_accuracy: 0.8078\n",
            "Epoch 21/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8102\n",
            "Epoch 22/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8188\n",
            "Epoch 23/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4106 - binary_accuracy: 0.8024\n",
            "Epoch 24/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3987 - binary_accuracy: 0.8171\n",
            "Epoch 25/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3908 - binary_accuracy: 0.8143\n",
            "Epoch 26/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3905 - binary_accuracy: 0.8208\n",
            "Epoch 27/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3866 - binary_accuracy: 0.8224\n",
            "Epoch 28/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3900 - binary_accuracy: 0.8241\n",
            "Epoch 29/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3935 - binary_accuracy: 0.8192\n",
            "Epoch 30/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3804 - binary_accuracy: 0.8200\n",
            "Epoch 31/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3845 - binary_accuracy: 0.8171\n",
            "Epoch 32/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3858 - binary_accuracy: 0.8184\n",
            "Epoch 33/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3842 - binary_accuracy: 0.8188\n",
            "Epoch 34/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8253\n",
            "Epoch 35/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3777 - binary_accuracy: 0.8200\n",
            "Epoch 36/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8261\n",
            "Epoch 37/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3644 - binary_accuracy: 0.8310\n",
            "Epoch 38/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3735 - binary_accuracy: 0.8265\n",
            "Epoch 39/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3695 - binary_accuracy: 0.8286\n",
            "Epoch 40/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3630 - binary_accuracy: 0.8331\n",
            "Epoch 41/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8367\n",
            "Epoch 42/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3665 - binary_accuracy: 0.8384\n",
            "Epoch 43/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3581 - binary_accuracy: 0.8310\n",
            "Epoch 44/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3681 - binary_accuracy: 0.8286\n",
            "Epoch 45/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3601 - binary_accuracy: 0.8290\n",
            "Epoch 46/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3677 - binary_accuracy: 0.8282\n",
            "Epoch 47/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_accuracy: 0.8359\n",
            "Epoch 48/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8339\n",
            "Epoch 49/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3542 - binary_accuracy: 0.8376\n",
            "Epoch 50/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8396\n",
            "Epoch 51/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8306\n",
            "Epoch 52/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8494\n",
            "Epoch 53/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8327\n",
            "Epoch 54/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8384\n",
            "Epoch 55/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3566 - binary_accuracy: 0.8359\n",
            "Epoch 56/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3475 - binary_accuracy: 0.8396\n",
            "Epoch 57/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8376\n",
            "Epoch 58/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3498 - binary_accuracy: 0.8433\n",
            "Epoch 59/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8445\n",
            "Epoch 60/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3573 - binary_accuracy: 0.8384\n",
            "Epoch 61/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8392\n",
            "Epoch 62/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3397 - binary_accuracy: 0.8465\n",
            "Epoch 63/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8400\n",
            "Epoch 64/75\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3373 - binary_accuracy: 0.8482\n",
            "Epoch 65/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8433\n",
            "Epoch 66/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3326 - binary_accuracy: 0.8527\n",
            "Epoch 67/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3426 - binary_accuracy: 0.8420\n",
            "Epoch 68/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3384 - binary_accuracy: 0.8469\n",
            "Epoch 69/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8469\n",
            "Epoch 70/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8482\n",
            "Epoch 71/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8457\n",
            "Epoch 72/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3386 - binary_accuracy: 0.8449\n",
            "Epoch 73/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8408\n",
            "Epoch 74/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8433\n",
            "Epoch 75/75\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8465\n",
            "For the fold number  8 :\n",
            "loss =  0.38040828704833984 \n",
            "accuracy =  81.99999928474426 %\n",
            "\n",
            "\n",
            "\n",
            "We obtain the following results:\n",
            "mean accuracy:  83.45714271068573 % \n",
            "mean loss: 0.37669470310211184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "JL6iAPvCqFgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# **Data_incr**"
      ],
      "metadata": {
        "id": "6BeuV5FCpjq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_incr(dropout_rate=0.3, nb_neurons=30):\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(nb_neurons, input_shape=(n_features,)))\n",
        "  model.add(layers.ReLU())\n",
        "  model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = Adam(0.001, beta_1=0.1)\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "toSyBpJtprPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model_incr()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "history = model.fit(data_incr, labels_incr, epochs=200, validation_split=0.3, callbacks=[callback])"
      ],
      "metadata": {
        "id": "X8TBDOWKpthM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ed9b01-1b82-44c3-d1ba-bb5caf3410b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "66/66 [==============================] - 2s 10ms/step - loss: 0.6754 - binary_accuracy: 0.6381 - val_loss: 0.5764 - val_binary_accuracy: 0.7222\n",
            "Epoch 2/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.5703 - binary_accuracy: 0.7200 - val_loss: 0.5309 - val_binary_accuracy: 0.7411\n",
            "Epoch 3/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5268 - binary_accuracy: 0.7395 - val_loss: 0.5044 - val_binary_accuracy: 0.7633\n",
            "Epoch 4/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.5061 - binary_accuracy: 0.7543 - val_loss: 0.4861 - val_binary_accuracy: 0.7711\n",
            "Epoch 5/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4887 - binary_accuracy: 0.7562 - val_loss: 0.4728 - val_binary_accuracy: 0.7778\n",
            "Epoch 6/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.4715 - binary_accuracy: 0.7624 - val_loss: 0.4619 - val_binary_accuracy: 0.7811\n",
            "Epoch 7/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.4672 - binary_accuracy: 0.7667 - val_loss: 0.4555 - val_binary_accuracy: 0.7833\n",
            "Epoch 8/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4573 - binary_accuracy: 0.7800 - val_loss: 0.4482 - val_binary_accuracy: 0.7933\n",
            "Epoch 9/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.7862 - val_loss: 0.4439 - val_binary_accuracy: 0.8000\n",
            "Epoch 10/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.7852 - val_loss: 0.4382 - val_binary_accuracy: 0.8033\n",
            "Epoch 11/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.4355 - binary_accuracy: 0.7933 - val_loss: 0.4351 - val_binary_accuracy: 0.8078\n",
            "Epoch 12/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4285 - binary_accuracy: 0.7976 - val_loss: 0.4310 - val_binary_accuracy: 0.8044\n",
            "Epoch 13/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4266 - binary_accuracy: 0.7962 - val_loss: 0.4275 - val_binary_accuracy: 0.8133\n",
            "Epoch 14/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4160 - binary_accuracy: 0.7976 - val_loss: 0.4228 - val_binary_accuracy: 0.8156\n",
            "Epoch 15/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.4147 - binary_accuracy: 0.8071 - val_loss: 0.4202 - val_binary_accuracy: 0.8167\n",
            "Epoch 16/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.4102 - binary_accuracy: 0.8057 - val_loss: 0.4155 - val_binary_accuracy: 0.8244\n",
            "Epoch 17/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4076 - binary_accuracy: 0.8033 - val_loss: 0.4142 - val_binary_accuracy: 0.8222\n",
            "Epoch 18/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8114 - val_loss: 0.4099 - val_binary_accuracy: 0.8233\n",
            "Epoch 19/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.4077 - binary_accuracy: 0.8071 - val_loss: 0.4061 - val_binary_accuracy: 0.8222\n",
            "Epoch 20/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3979 - binary_accuracy: 0.8133 - val_loss: 0.4021 - val_binary_accuracy: 0.8222\n",
            "Epoch 21/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3915 - binary_accuracy: 0.8105 - val_loss: 0.3996 - val_binary_accuracy: 0.8244\n",
            "Epoch 22/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3919 - binary_accuracy: 0.8143 - val_loss: 0.3974 - val_binary_accuracy: 0.8189\n",
            "Epoch 23/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3867 - binary_accuracy: 0.8195 - val_loss: 0.3918 - val_binary_accuracy: 0.8244\n",
            "Epoch 24/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3842 - binary_accuracy: 0.8248 - val_loss: 0.3898 - val_binary_accuracy: 0.8256\n",
            "Epoch 25/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3857 - binary_accuracy: 0.8252 - val_loss: 0.3859 - val_binary_accuracy: 0.8300\n",
            "Epoch 26/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3811 - binary_accuracy: 0.8257 - val_loss: 0.3835 - val_binary_accuracy: 0.8367\n",
            "Epoch 27/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3741 - binary_accuracy: 0.8238 - val_loss: 0.3823 - val_binary_accuracy: 0.8389\n",
            "Epoch 28/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8295 - val_loss: 0.3819 - val_binary_accuracy: 0.8356\n",
            "Epoch 29/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3714 - binary_accuracy: 0.8229 - val_loss: 0.3791 - val_binary_accuracy: 0.8344\n",
            "Epoch 30/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3738 - binary_accuracy: 0.8343 - val_loss: 0.3753 - val_binary_accuracy: 0.8367\n",
            "Epoch 31/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8286 - val_loss: 0.3743 - val_binary_accuracy: 0.8356\n",
            "Epoch 32/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8271 - val_loss: 0.3718 - val_binary_accuracy: 0.8400\n",
            "Epoch 33/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3754 - binary_accuracy: 0.8248 - val_loss: 0.3701 - val_binary_accuracy: 0.8367\n",
            "Epoch 34/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3690 - binary_accuracy: 0.8338 - val_loss: 0.3694 - val_binary_accuracy: 0.8367\n",
            "Epoch 35/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3711 - binary_accuracy: 0.8314 - val_loss: 0.3688 - val_binary_accuracy: 0.8400\n",
            "Epoch 36/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3640 - binary_accuracy: 0.8362 - val_loss: 0.3657 - val_binary_accuracy: 0.8422\n",
            "Epoch 37/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8329 - val_loss: 0.3643 - val_binary_accuracy: 0.8444\n",
            "Epoch 38/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3547 - binary_accuracy: 0.8448 - val_loss: 0.3641 - val_binary_accuracy: 0.8433\n",
            "Epoch 39/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3546 - binary_accuracy: 0.8333 - val_loss: 0.3628 - val_binary_accuracy: 0.8444\n",
            "Epoch 40/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8414 - val_loss: 0.3622 - val_binary_accuracy: 0.8489\n",
            "Epoch 41/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3468 - binary_accuracy: 0.8462 - val_loss: 0.3591 - val_binary_accuracy: 0.8456\n",
            "Epoch 42/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3387 - binary_accuracy: 0.8443 - val_loss: 0.3582 - val_binary_accuracy: 0.8511\n",
            "Epoch 43/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8433 - val_loss: 0.3587 - val_binary_accuracy: 0.8522\n",
            "Epoch 44/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8405 - val_loss: 0.3577 - val_binary_accuracy: 0.8500\n",
            "Epoch 45/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3407 - binary_accuracy: 0.8429 - val_loss: 0.3543 - val_binary_accuracy: 0.8500\n",
            "Epoch 46/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8381 - val_loss: 0.3558 - val_binary_accuracy: 0.8489\n",
            "Epoch 47/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8548 - val_loss: 0.3529 - val_binary_accuracy: 0.8511\n",
            "Epoch 48/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8438 - val_loss: 0.3524 - val_binary_accuracy: 0.8500\n",
            "Epoch 49/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8481 - val_loss: 0.3524 - val_binary_accuracy: 0.8489\n",
            "Epoch 50/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8481 - val_loss: 0.3499 - val_binary_accuracy: 0.8522\n",
            "Epoch 51/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8357 - val_loss: 0.3501 - val_binary_accuracy: 0.8500\n",
            "Epoch 52/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3312 - binary_accuracy: 0.8510 - val_loss: 0.3502 - val_binary_accuracy: 0.8500\n",
            "Epoch 53/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8557 - val_loss: 0.3486 - val_binary_accuracy: 0.8511\n",
            "Epoch 54/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8467 - val_loss: 0.3484 - val_binary_accuracy: 0.8478\n",
            "Epoch 55/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3203 - binary_accuracy: 0.8624 - val_loss: 0.3489 - val_binary_accuracy: 0.8500\n",
            "Epoch 56/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3261 - binary_accuracy: 0.8614 - val_loss: 0.3485 - val_binary_accuracy: 0.8544\n",
            "Epoch 57/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3242 - binary_accuracy: 0.8486 - val_loss: 0.3506 - val_binary_accuracy: 0.8400\n",
            "Epoch 58/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3292 - binary_accuracy: 0.8510 - val_loss: 0.3486 - val_binary_accuracy: 0.8544\n",
            "Epoch 59/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3346 - binary_accuracy: 0.8495 - val_loss: 0.3469 - val_binary_accuracy: 0.8522\n",
            "Epoch 60/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3343 - binary_accuracy: 0.8481 - val_loss: 0.3461 - val_binary_accuracy: 0.8478\n",
            "Epoch 61/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8529 - val_loss: 0.3444 - val_binary_accuracy: 0.8500\n",
            "Epoch 62/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3250 - binary_accuracy: 0.8624 - val_loss: 0.3449 - val_binary_accuracy: 0.8467\n",
            "Epoch 63/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3278 - binary_accuracy: 0.8662 - val_loss: 0.3456 - val_binary_accuracy: 0.8444\n",
            "Epoch 64/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8605 - val_loss: 0.3440 - val_binary_accuracy: 0.8433\n",
            "Epoch 65/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3170 - binary_accuracy: 0.8605 - val_loss: 0.3433 - val_binary_accuracy: 0.8489\n",
            "Epoch 66/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3137 - binary_accuracy: 0.8590 - val_loss: 0.3432 - val_binary_accuracy: 0.8478\n",
            "Epoch 67/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3287 - binary_accuracy: 0.8538 - val_loss: 0.3429 - val_binary_accuracy: 0.8522\n",
            "Epoch 68/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3138 - binary_accuracy: 0.8690 - val_loss: 0.3427 - val_binary_accuracy: 0.8500\n",
            "Epoch 69/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3297 - binary_accuracy: 0.8562 - val_loss: 0.3427 - val_binary_accuracy: 0.8500\n",
            "Epoch 70/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3160 - binary_accuracy: 0.8662 - val_loss: 0.3413 - val_binary_accuracy: 0.8444\n",
            "Epoch 71/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8571 - val_loss: 0.3435 - val_binary_accuracy: 0.8467\n",
            "Epoch 72/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3147 - binary_accuracy: 0.8614 - val_loss: 0.3418 - val_binary_accuracy: 0.8433\n",
            "Epoch 73/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3086 - binary_accuracy: 0.8638 - val_loss: 0.3417 - val_binary_accuracy: 0.8467\n",
            "Epoch 74/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3140 - binary_accuracy: 0.8576 - val_loss: 0.3405 - val_binary_accuracy: 0.8467\n",
            "Epoch 75/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3142 - binary_accuracy: 0.8586 - val_loss: 0.3443 - val_binary_accuracy: 0.8489\n",
            "Epoch 76/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3126 - binary_accuracy: 0.8619 - val_loss: 0.3407 - val_binary_accuracy: 0.8444\n",
            "Epoch 77/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3091 - binary_accuracy: 0.8652 - val_loss: 0.3413 - val_binary_accuracy: 0.8422\n",
            "Epoch 78/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3054 - binary_accuracy: 0.8705 - val_loss: 0.3400 - val_binary_accuracy: 0.8489\n",
            "Epoch 79/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3137 - binary_accuracy: 0.8700 - val_loss: 0.3412 - val_binary_accuracy: 0.8444\n",
            "Epoch 80/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3073 - binary_accuracy: 0.8671 - val_loss: 0.3444 - val_binary_accuracy: 0.8467\n",
            "Epoch 81/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3085 - binary_accuracy: 0.8662 - val_loss: 0.3418 - val_binary_accuracy: 0.8478\n",
            "Epoch 82/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3076 - binary_accuracy: 0.8714 - val_loss: 0.3389 - val_binary_accuracy: 0.8456\n",
            "Epoch 83/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2970 - binary_accuracy: 0.8771 - val_loss: 0.3393 - val_binary_accuracy: 0.8489\n",
            "Epoch 84/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3021 - binary_accuracy: 0.8652 - val_loss: 0.3390 - val_binary_accuracy: 0.8456\n",
            "Epoch 85/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2984 - binary_accuracy: 0.8676 - val_loss: 0.3395 - val_binary_accuracy: 0.8489\n",
            "Epoch 86/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3026 - binary_accuracy: 0.8724 - val_loss: 0.3385 - val_binary_accuracy: 0.8522\n",
            "Epoch 87/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8595 - val_loss: 0.3402 - val_binary_accuracy: 0.8500\n",
            "Epoch 88/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3071 - binary_accuracy: 0.8676 - val_loss: 0.3366 - val_binary_accuracy: 0.8489\n",
            "Epoch 89/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3061 - binary_accuracy: 0.8667 - val_loss: 0.3385 - val_binary_accuracy: 0.8456\n",
            "Epoch 90/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2935 - binary_accuracy: 0.8710 - val_loss: 0.3395 - val_binary_accuracy: 0.8489\n",
            "Epoch 91/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2874 - binary_accuracy: 0.8767 - val_loss: 0.3357 - val_binary_accuracy: 0.8489\n",
            "Epoch 92/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3073 - binary_accuracy: 0.8638 - val_loss: 0.3363 - val_binary_accuracy: 0.8511\n",
            "Epoch 93/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3040 - binary_accuracy: 0.8624 - val_loss: 0.3359 - val_binary_accuracy: 0.8456\n",
            "Epoch 94/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3009 - binary_accuracy: 0.8690 - val_loss: 0.3357 - val_binary_accuracy: 0.8456\n",
            "Epoch 95/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3066 - binary_accuracy: 0.8652 - val_loss: 0.3355 - val_binary_accuracy: 0.8478\n",
            "Epoch 96/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3009 - binary_accuracy: 0.8686 - val_loss: 0.3360 - val_binary_accuracy: 0.8500\n",
            "Epoch 97/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.3005 - binary_accuracy: 0.8686 - val_loss: 0.3350 - val_binary_accuracy: 0.8478\n",
            "Epoch 98/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.3036 - binary_accuracy: 0.8643 - val_loss: 0.3385 - val_binary_accuracy: 0.8489\n",
            "Epoch 99/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2933 - binary_accuracy: 0.8767 - val_loss: 0.3358 - val_binary_accuracy: 0.8478\n",
            "Epoch 100/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2866 - binary_accuracy: 0.8757 - val_loss: 0.3356 - val_binary_accuracy: 0.8467\n",
            "Epoch 101/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2938 - binary_accuracy: 0.8733 - val_loss: 0.3351 - val_binary_accuracy: 0.8433\n",
            "Epoch 102/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2968 - binary_accuracy: 0.8681 - val_loss: 0.3379 - val_binary_accuracy: 0.8489\n",
            "Epoch 103/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2878 - binary_accuracy: 0.8762 - val_loss: 0.3361 - val_binary_accuracy: 0.8489\n",
            "Epoch 104/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2910 - binary_accuracy: 0.8762 - val_loss: 0.3356 - val_binary_accuracy: 0.8478\n",
            "Epoch 105/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2878 - binary_accuracy: 0.8771 - val_loss: 0.3330 - val_binary_accuracy: 0.8511\n",
            "Epoch 106/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2971 - binary_accuracy: 0.8710 - val_loss: 0.3343 - val_binary_accuracy: 0.8478\n",
            "Epoch 107/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2927 - binary_accuracy: 0.8738 - val_loss: 0.3344 - val_binary_accuracy: 0.8478\n",
            "Epoch 108/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2858 - binary_accuracy: 0.8790 - val_loss: 0.3385 - val_binary_accuracy: 0.8467\n",
            "Epoch 109/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2793 - binary_accuracy: 0.8781 - val_loss: 0.3348 - val_binary_accuracy: 0.8478\n",
            "Epoch 110/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2807 - binary_accuracy: 0.8781 - val_loss: 0.3339 - val_binary_accuracy: 0.8489\n",
            "Epoch 111/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2866 - binary_accuracy: 0.8776 - val_loss: 0.3365 - val_binary_accuracy: 0.8478\n",
            "Epoch 112/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2924 - binary_accuracy: 0.8610 - val_loss: 0.3348 - val_binary_accuracy: 0.8467\n",
            "Epoch 113/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2850 - binary_accuracy: 0.8752 - val_loss: 0.3318 - val_binary_accuracy: 0.8478\n",
            "Epoch 114/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2863 - binary_accuracy: 0.8738 - val_loss: 0.3358 - val_binary_accuracy: 0.8489\n",
            "Epoch 115/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2772 - binary_accuracy: 0.8843 - val_loss: 0.3342 - val_binary_accuracy: 0.8522\n",
            "Epoch 116/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2774 - binary_accuracy: 0.8829 - val_loss: 0.3337 - val_binary_accuracy: 0.8478\n",
            "Epoch 117/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2877 - binary_accuracy: 0.8771 - val_loss: 0.3357 - val_binary_accuracy: 0.8511\n",
            "Epoch 118/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2872 - binary_accuracy: 0.8805 - val_loss: 0.3364 - val_binary_accuracy: 0.8467\n",
            "Epoch 119/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2828 - binary_accuracy: 0.8748 - val_loss: 0.3369 - val_binary_accuracy: 0.8467\n",
            "Epoch 120/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2724 - binary_accuracy: 0.8852 - val_loss: 0.3353 - val_binary_accuracy: 0.8522\n",
            "Epoch 121/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2835 - binary_accuracy: 0.8833 - val_loss: 0.3358 - val_binary_accuracy: 0.8511\n",
            "Epoch 122/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2791 - binary_accuracy: 0.8771 - val_loss: 0.3334 - val_binary_accuracy: 0.8478\n",
            "Epoch 123/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2864 - binary_accuracy: 0.8795 - val_loss: 0.3343 - val_binary_accuracy: 0.8456\n",
            "Epoch 124/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2830 - binary_accuracy: 0.8833 - val_loss: 0.3361 - val_binary_accuracy: 0.8489\n",
            "Epoch 125/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2808 - binary_accuracy: 0.8795 - val_loss: 0.3350 - val_binary_accuracy: 0.8478\n",
            "Epoch 126/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2879 - binary_accuracy: 0.8767 - val_loss: 0.3316 - val_binary_accuracy: 0.8500\n",
            "Epoch 127/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2746 - binary_accuracy: 0.8805 - val_loss: 0.3348 - val_binary_accuracy: 0.8444\n",
            "Epoch 128/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2861 - binary_accuracy: 0.8786 - val_loss: 0.3377 - val_binary_accuracy: 0.8433\n",
            "Epoch 129/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2832 - binary_accuracy: 0.8795 - val_loss: 0.3356 - val_binary_accuracy: 0.8467\n",
            "Epoch 130/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2795 - binary_accuracy: 0.8786 - val_loss: 0.3356 - val_binary_accuracy: 0.8500\n",
            "Epoch 131/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2820 - binary_accuracy: 0.8738 - val_loss: 0.3333 - val_binary_accuracy: 0.8478\n",
            "Epoch 132/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2802 - binary_accuracy: 0.8843 - val_loss: 0.3322 - val_binary_accuracy: 0.8511\n",
            "Epoch 133/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2729 - binary_accuracy: 0.8876 - val_loss: 0.3305 - val_binary_accuracy: 0.8478\n",
            "Epoch 134/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2857 - binary_accuracy: 0.8795 - val_loss: 0.3320 - val_binary_accuracy: 0.8500\n",
            "Epoch 135/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2788 - binary_accuracy: 0.8805 - val_loss: 0.3341 - val_binary_accuracy: 0.8456\n",
            "Epoch 136/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2706 - binary_accuracy: 0.8876 - val_loss: 0.3357 - val_binary_accuracy: 0.8444\n",
            "Epoch 137/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2720 - binary_accuracy: 0.8871 - val_loss: 0.3391 - val_binary_accuracy: 0.8456\n",
            "Epoch 138/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2744 - binary_accuracy: 0.8881 - val_loss: 0.3361 - val_binary_accuracy: 0.8422\n",
            "Epoch 139/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2748 - binary_accuracy: 0.8838 - val_loss: 0.3349 - val_binary_accuracy: 0.8478\n",
            "Epoch 140/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2717 - binary_accuracy: 0.8824 - val_loss: 0.3351 - val_binary_accuracy: 0.8478\n",
            "Epoch 141/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2725 - binary_accuracy: 0.8810 - val_loss: 0.3362 - val_binary_accuracy: 0.8467\n",
            "Epoch 142/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2701 - binary_accuracy: 0.8895 - val_loss: 0.3321 - val_binary_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2674 - binary_accuracy: 0.8805 - val_loss: 0.3329 - val_binary_accuracy: 0.8489\n",
            "Epoch 144/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2708 - binary_accuracy: 0.8824 - val_loss: 0.3343 - val_binary_accuracy: 0.8489\n",
            "Epoch 145/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2611 - binary_accuracy: 0.8933 - val_loss: 0.3323 - val_binary_accuracy: 0.8533\n",
            "Epoch 146/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2648 - binary_accuracy: 0.8838 - val_loss: 0.3335 - val_binary_accuracy: 0.8522\n",
            "Epoch 147/200\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.2716 - binary_accuracy: 0.8876 - val_loss: 0.3333 - val_binary_accuracy: 0.8578\n",
            "Epoch 148/200\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.2809 - binary_accuracy: 0.8767 - val_loss: 0.3325 - val_binary_accuracy: 0.8544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_things(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "FKZI-HV-zKSr",
        "outputId": "7b28faa1-0535-4c3b-e176-46ee0c522155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAEDCAYAAABwP6PAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RU1drA4d9O7z0hpJFQE0InhN5BECkqUlSwYcfe9eq1f3qv5dpFsYCCVCmCIL1JCwm9hSSQDklI72Vmf3/sSYPQCYmwn7VYJHPaPiczc97z7iaklGiapmmapmmNg1lDF0DTNE3TNE2rpoMzTdM0TdO0RkQHZ5qmaZqmaY2IDs40TdM0TdMaER2caZqmaZqmNSI6ONM0TdM0TWtEdHCmado/nhBihhDivYtcN14IMaS+y6Rpmna5dHCmaZqmaZrWiOjgTNM0rZEQQlg0dBk0TWt4OjjTNO2aMFUnviiE2C+EKBRC/CiEaCKEWCmEyBdCrBVCuNZYf7QQ4pAQIkcIsVEIEVJjWWchxG7TdvMAmzOONVIIsde07TYhRIeLLOMtQog9Qog8IUSSEOKtM5b3Me0vx7T8PtPrtkKIT4QQCUKIXCHE36bXBgghkuu4DkNMP78lhFgohJglhMgD7hNChAshtpuOcVII8ZUQwqrG9qFCiDVCiCwhRJoQ4jUhhLcQokgI4V5jvS5CiAwhhOXFnLumaY2HDs40TbuWxgJDgdbAKGAl8Brgifo+egpACNEamAM8Y1q2AlgmhLAyBSpLgF8BN2CBab+Ytu0M/AQ8ArgD3wF/CCGsL6J8hcA9gAtwC/CYEOJW036bmcr7palMnYC9pu0+BroCvUxlegkwXuQ1GQMsNB1zNmAAngU8gJ7AYOBxUxkcgbXAX4AP0BJYJ6U8BWwExtfY72RgrpSy/CLLoWlaI6GDM03TrqUvpZRpUsoUYAuwU0q5R0pZAiwGOpvWmwD8KaVcYwouPgZsUcFPD8AS+ExKWS6lXAjsqnGMh4HvpJQ7pZQGKeVMoNS03XlJKTdKKQ9IKY1Syv2oALG/afFdwFop5RzTcTOllHuFEGbAA8DTUsoU0zG3SSlLL/KabJdSLjEds1hKGSWl3CGlrJBSxqOCy8oyjAROSSk/kVKWSCnzpZQ7TctmApMAhBDmwJ2oAFbTtH8YHZxpmnYtpdX4ubiO3x1MP/sACZULpJRGIAnwNS1LkVLKGtsm1Pi5GfC8qVowRwiRA/ibtjsvIUR3IcQGU3VgLvAoKoOFaR9xdWzmgapWrWvZxUg6owythRDLhRCnTFWd/3cRZQBYCrQVQgShspO5UsqIyyyTpmkNSAdnmqY1RqmoIAsAIYRABSYpwEnA1/RapYAaPycB70spXWr8s5NSzrmI4/4G/AH4SymdgWlA5XGSgBZ1bHMaKDnHskLArsZ5mKOqRGuSZ/z+LXAUaCWldEJV+9YsQ/O6Cm7KPs5HZc8mo7NmmvaPpYMzTdMao/nALUKIwaYG7c+jqia3AduBCuApIYSlEOJ2ILzGttOBR01ZMCGEsDc19He8iOM6AllSyhIhRDiqKrPSbGCIEGK8EMJCCOEuhOhkyur9BHwqhPARQpgLIXqa2rgdA2xMx7cEXgcu1PbNEcgDCoQQwcBjNZYtB5oKIZ4RQlgLIRyFEN1rLP8FuA8YjQ7ONO0fSwdnmqY1OlLKaFQG6EtUZmoUMEpKWSalLANuRwUhWaj2aYtqbBsJPAR8BWQDsaZ1L8bjwDtCiHzg36ggsXK/icAIVKCYheoM0NG0+AXgAKrtWxbwH8BMSplr2ucPqKxfIVCr92YdXkAFhfmoQHNejTLko6osRwGngBhgYI3lW1EdEXZLKWtW9Wqa9g8iajfb0DRN0/7JhBDrgd+klD80dFk0Tbs8OjjTNE27TgghugFrUG3m8hu6PJqmXR5dralpmnYdEELMRI2B9owOzDTtn01nzjRN0zRN0xoRnTnTNE3TNE1rRHRwpmmapmma1ohY1OfOhRDDgc8Bc+AHKeWHZyxvhhofyBPV/XySlDLZtOxe1JhAAO+ZpmA5Jw8PDxkYGHh1T0DTNE3TNK0eREVFnZZSnjkoNVCPbc5MI2EfQ43Jk4wa/+dOKeXhGussAJZLKWcKIQYB90spJwsh3IBIIAw1enYU0FVKmX2u44WFhcnIyMh6ORdN0zRN07SrSQgRJaUMq2tZfVZrhgOxUsrjpkEj5wJjzlinLbDe9POGGsuHAWuklFmmgGwNMLwey6ppmqZpmtYo1Gdw5kvtCX2TTa/VtA810jfAbYCjEML9IrfVNE3TNE277jR0h4AXgP5CiD1Af9T0JoaL3VgI8bAQIlIIEZmRkVFfZdQ0TdM0Tbtm6rNDQArgX+N3P9NrVaSUqZgyZ0IIB2CslDJHCJECDDhj241nHkBK+T3wPag2Z2cuLy8vJzk5mZKSkis6kX8CGxsb/Pz8sLS0bOiiaJqmaZp2BeozONsFtBJCBKGCsomoyXyrCCE8gCwppRF4FdVzE2AV8H9CCFfT7zeZll+S5ORkHB0dCQwMRAhxmafR+EkpyczMJDk5maCgoIYujqZpmqZpV6DeqjWllBXAE6hA6wgwX0p5SAjxjhBitGm1AUC0EOIY0AR437RtFvAuKsDbBbxjeu2SlJSU4O7ufl0HZgBCCNzd3W+IDKGmaZqmXe/qdZwzKeUKYMUZr/27xs8LgYXn2PYnqjNpl+16D8wq3SjnqWmapmmXSkrJl+tjGdq2CSFNnRq6OBfU0B0Crns5OTl88803l7zdiBEjyMnJqYcSaZqmadqNZWtsJp+uOcZriw/wT5hTXAdn9excwVlFRcV5t1uxYgUuLi71VSxN0zRNu2H88PdxhIA9iTlsjG78ozvo4KyevfLKK8TFxdGpUye6detG3759GT16NG3btgXg1ltvpWvXroSGhvL9999XbRcYGMjp06eJj48nJCSEhx56iNDQUG666SaKi4sb6nQ0TdM0rdHYfCyDW77Ywsncc98XY9Ly2RidwZMDWxLgZsfHq6MbffasXtucafDhhx9y8OBB9u7dy8aNG7nllls4ePBgVa/Kn376CTc3N4qLi+nWrRtjx47F3d291j5iYmKYM2cO06dPZ/z48fz+++9MmjSpIU5H0zRN02qJSshme9xpHhvQEnOzc7d/rjAY+W7zcfKKy/F0tMbT0Zpyg+RQai6HUvJIySnmyUEtmRgecFHHLa0w8PqSgyRmFfG/Ncf47x0d61zvhy0nsLE0477eQTRzt+f5BftYdegUw9s1BSCnqIyftsZzV3gA3s42l34B6sENE5y9vewQh1Pzruo+2/o48eao0EvaJjw8vNZwF1988QWLFy8GICkpiZiYmLOCs6CgIDp16gRA165diY+Pv7KCa5qmadoVKik38L+1x5i++ThGCY42ltzbK/Cc63+7MY5P1hzDytyMMoOx6nVbS3Pa+jjh4WjNK4sOkJxdzPM3tb5gR7eft8aTmFVEeJAbC6OSebBvc1o3cay1TkZ+KYv3pjCuqx9u9lbc2tmXbzbG8umaYwxt682Rk3k8OiuK5OxiUnOK+Xhc3QHetXbDBGeNhb29fdXPGzduZO3atWzfvh07OzsGDBhQ53AY1tbWVT+bm5vrak1N07RGqKisgvjTRbTxdjxvBul8DqbkMvW33fRu6cHEbv6093VulL3xD6Xm8uy8vRxLK+DOcH8SMov4eHU0I9o3xdPR+qz1D6bk8vm6GEZ39OHziZ3IK64gPb8EIQRBHvaYmwnKDUbeWHKQrzbEkpJTzH/GdsDKou7WVxn5pXy1PpYhIV58dEdH+n20gf+sPMqP93Wrtd6vOxIoqzDyQB+VFDE3Ezw7tDVP/LaHFxfsY/mBk7jbWzGwjSdL96bw0rA2eDk1fPbshgnOLjXDdbU4OjqSn59f57Lc3FxcXV2xs7Pj6NGj7Nix4xqXTtM0Tbta/r30EAujknGzt2JAa08GBnsxvJ03luYX37z783UxpOeVsmh3Mr/tTCTY25GXbw5mYBuv8263OzGb7XGZTOkThI2l+ZWeynkVlVUw+ccILMwEP9/fjYFtvIjLKGD4Z5v5YMURPp3Qqdb6JeUGnp23F3cHK94ZE4oQAmc7S5ztas9oY2luxge3t8ffzY6PVkWzNymHm9o2YWCwF12buda6jp+uiaak3MBrI0JwtbfisQEt+O9f0ew8nkn35u5Vx521I4EhIV608HSo2nZEu6YEe8eyaE8KfVp68PnETuSXVDDwk438sj2BF4a1qcerd3FumOCsobi7u9O7d2/atWuHra0tTZo0qVo2fPhwpk2bRkhICG3atKFHjx4NWFJN0zTtcqXkFLNkTwqDg71wtLFgQ3Q6i/akMLJDU76Y2Bmzi8ikxaTls+ZwGk8PbsWUvkH8sTeVn7ee4LFZUfz+WC9CfZzP2kZKyYxt8bz/5xEqjJIVB07y7d1dCXC3q4/TBGBuRBJZhWX8/lgvujZTE/m08HTg4X7N+XpDHBO6+VcFSACfrjlGTHoBM+7vhoud1Xn3LYRg6sCWtPC055ftCfz49wm+23wcRxsL+rVSAa+3kw1zdyXxQO8gmpuCrgd6B/HLtgQ+/OsoCx7pyeaYDGZsSyCrsIwpfZrXOoaZmeCziZ3YFZ/NXeEBmJsJ3B2sGRrShFk7E5g6sCW2VvUb4F6IaOw9Fi5WWFiYjIyMrPXakSNHCAkJaaASXXs32vlqmqY1Fm8vO8Sv2xPY9NJAfF1sMRgl326M5ePVx3hiYMta2Zj0vBLmRCRxZ3d/vByrq9Cen7+PFQdOsvWVQbjZqyAmI7+UUV/+jaWFYNkTfWoFN4WlFby66AB/7EtlSEgTxnTy4V+LDwDw2cRODAquTgZUyi0uZ/bOBFp7OTKgjScWl5DVAyirMDLgow34udox/9GetZYVlxkY8ukm7K3Nmf1gD6JP5ROVkM1n645xV3gA79/W/pKOBZBfUs7W2NOsP5rOhugMMvJLAXC1s2TjCwNrZd/m7Urk5d8P4GpnSXZROe72VtzbK5AnB7W8qKrhiBNZjP9uO+/e2o7JPZpdclkvlRAiSkoZVtcynTnTNE3TbghbYjKIjM8mpKkT7Xyd8HWxvSrtubIKy5gbkcSYTr74utgCqm3T1IEtSc4u5qsNsTRzt+OOrn4s23+SN5YcJLe4nLVH0pj3SA/srCxIySlm6d4UJvdsVhWYAXg6WvPtpC5M+G4HT83dy8/3dUNKyR/7UvliXQyJWUW8OKwNj/VvgZmZoKOfC4/OiuKBGZFM7tGM529qXRXQVTZ+T8gsAsDL0Zo7uvrRxtuRw6l5HEzNJf50EQFudrTzdaKdrzN9W3nWKs8f+1JJzS2pM9CytTLnzVFtefjXKLq9v7bq9c4BLrw24vISB442lgxv15Th7ZpiNEoOn8xj07EMOvm7nFUtOraLHysPnkIAE7r5Myi4yTnbrNWlW6ArHf2c+envE9wdHnBR2c76ojNn15Eb7Xw17XqVnl+Cm53VJWc1bkTFZQbiMgpo4+143rZdqw+d4rHZuzEYq+95jtYWWFtWb2NnZYGXozVeTtYEedjzzJDWF9Ve7H9rjvH5uhjWPNuPVmf0Fiw3GLn/513sPJFJrxYeVYHF2C6+vPnHIQaHNGHapK689+fhWpm3M82JSOTVRQe4uZ03h1LzSMwqItjbkX+PbEuvlh611i0pN/DhyqP8sj0eJ1tLnh/aGlsrC15fcgBnW0s+n9iZ3OJy5u9KYkN0OkYJVuZmBDd1JNDdnoSsIo6czKOswoi3kw2zH+pOC08HjEbJsM82Y24mWPl03zoDWyklP2+Np9xgpJ2vM22bOuFqf/6qzMZk2b5Unpyzh+n3hDG07dmZx6tJZ840TdP+IXbFZ3H39J3c1T2At0bXf0emtYfTmL7lON9O6lorQ1Jf3l1+mK2xp2nr40Q7H2c6+rvQJcDlghms+ZFJtYZDyi0u51BqLrHpBRglVb0A69rPttjTPDFnD+18nfnx3jCSsoo4mJpHbFo+FaZgTQIFJaoH4cGUPFYcOEW3QDcGXKAhfmFpBTO3xzO0bZOzAjNQjdy/mdSFsd9sY1vcaV4a3oaH+zbHwtwMg1Hy1rLD/GvxAZbuTWV0J586AzOAO8MD2J+cw5yIJDr4OfPGyDAGB3vVmd2xsTTnrdGhTOjmz9vLDvHG0kMA9Gjuxpd3dqnqTTks1Jv0vBIyC8to6eVQKxAtNxjZk5jD47OjmPDdDn57qDsJmUXEpBec8zqDajNW2TPyn+jmdt74utgyfcvxeg/Ozkdnzq4jN9r5atr1Jv50Ibd9s5XsonLsrczZ+a8hOFjX3zP0/uQcxn+3nZJyI6/fEsKDfZtfeKMrkJ5fQq8P1uPvZkd+SQWnC1T7oVAfJ54c1JKb2nrXGWxsOpbBvT9FYG9lXjVEhb21haqe9HEiu6icX3ck8MbItkw5IzDYm5TDXdN34Odqy/xHel6wQTqozFOnd1YzIcyft8e0O6ssH6w4QrdANwYGe3LkZD4frYpm0eO96BLges595pWUk19ScVbw9dYfh5ixLR6A1c/2O2ucrpoMRsmxtHyCvR0vujpWSsmqQ6dIzi7mvl6Bl5yNjU0v4K7pO6gwSjwcrCgqM7DxhQHXdVZ3/q4k0vNLLjio7pXSmTNN07RGLqeojAdm7ALgswmdeGbeXhbvSam3hsnJ2UVMmRmJh4M1DtYWLIxKZkqfoHodU2thVDIVRskP94bRwtOB9LwSNkZn8O2mOB6dtZvWTRx4a1RorWq6knIDby49SJCHPX890xdri7N70RmNkrS8Ev5vxRHaNnWiZwt3jEbJoj0pvLv8MB4O1vw6pftFBWagMk99Wnqw7mg6b42Wta7Jz1tPkJRVREJmEb/uSAAgPMjtvIEZgJONJU42lme9/sbIthSUVmBnZX7ewAxUO7aQpk4XdQ6VhBBVI+FfjpZeDsx/pCd3Td/BsbQC3hkTel0HZgDju/k3dBH03JqapmkNrazCyCO/qlHKv78njDGdfGjn68Ss7QnnnANQSslHq47ywoJ9l3y8vJJypsyIpKTcwM/3dWNSj2YcPZXPgZTcKz2VczIaJXMjkggPcqsac8rLyYbx3fxZ+1x/Pp/YiXKD5P4Zu9gel1m13febjxOfWcTbo0PrDMxADY3wyfiOBLrb8cRvu1l96BS3fbuNFxbsI9DDntkPdqfJJQ4sOjDYi+TsYmLTC6peyyos4++Y00zq2Yy9bw7llwfCeWxAC96+gupnczPBx+M68s4ZGbrGJNDDnnmP9OTFYW0YH9bwgcuNQAdnjYyDg8OFV9I0rVEqKK3gm42xTNsUx6Ldyfwdc5qcorLzbmMwSp6bv5edJ7L4aFwHugW6IYRgUvdmRKflE5mQfdY2RqPktcUH+XpDHAujkjly8uKnpssrKefhXyKJyyjg27u70qqJI6M6+mBtYcaCyORLPueLtf14JolZRdxVx7yJ5maCMZ18+f2xXvi72fHgzF3sT84hKauIrzfEMqK9N/1ae553/442lnw3OYzSCiMP/xpFak4xn4zryGLTPi9V5aCv64+mV73218FTVBglozr4YG1hTr/Wnrw8PPiSs1n/RP5udkwd2LLeB7jVFF2tqWnaP17EiSwqDMazeq1dSyXlBqbM2MXOE1m1Xne0tuDpIa24p2fgWd36pZS8vuQAy/ef5LURwYzp5Fu1bHQnH95fcYRZOxLoFuhW9brBKHn59/0sjErm3p7NmBORxILIZP49qu0Fy3gyt5j7f95FbHoBH4/rSJ9W6no521oyvJ03S/em8K9bQuq8AUspmbcriY7+LnUGIwmZheQWl1f97u9qV6uX3pyIxKrjnIubvRWzpnTnjmnbuPenCFp6OWBuJnhj5IXPDVQV3PR7wohKyOK+3kFX1F7Px8WWYG9H1h9N55H+LQBYvj+V5h72hPpc/8GY1rB0cFbPXnnlFfz9/Zk6dSoAb731FhYWFmzYsIHs7GzKy8t57733GDNmTAOXVNP+maSUvLBgH0VlFWx/dfAlTZVztZQbjEydvZuI+Cw+n9iJQcFeZOSXcjK3hO83H+e9P4/wW0Qi/xoRQu+WHthYmiOl5MOVR5kTkcTUgS14uF+LWvu0s7JgbBc/ftuZyBsjS/FwsOZ0QSlv/nGIP/ef5JkhrXh6cCsyCkpZsjeFV24OrhX8bY/LZH9yDqE+zoT6OHEyt4QHZuyioLSCGfeHVwVmlcaH+bN0byqrD6cxuqPPWec4e2ciry85iLWFGe/e2q6qequwtIIPVh5h1o7EWus72Vjw/T1h9GjuTmZBKasPpXF3j4ALZl68nW2YNaU7477bzq74bF4bEUxT57p7MNalZwt3erZwv/CKF2FwiBfTNh0nt6ic0goD249n8uSgVo1yrkvt+qKDs3o2YcIEnnnmmargbP78+axatYqnnnoKJycnTp8+TY8ePRg9erT+wGs3nAqDkQVRybXaIV2qwyfVmE8AG46mc1No7czM+qNpuNhZXbDB9uUyGlVwuO5oOu/e2q4q++VoY0lzTwd6tXBn/dF03l1+mCkzI7EwE7Rq4kgTJ2s2RmcwuUczXrip7rn8JvUIYMa2eKZtjMMo4beIBEorjLw8PJjHBqhgblyYPysOnGL90bSqht+nC0p55NdI8koqqvZlbibwdLBmwaM968x89Wzujq+LLQsik84Kzo6czOOd5Yfp3dIdKeGlhfvZk5jNyA4+vLroAEnZRTzQO4jeLVVQVGGUfLQqmnt+jOCjcR1IzyulzGDkzjqqNOsS6GHPnIe68+f+U9zfu+GGZRgU7MXXG+LYHJNBZkEpUsKoDpffuF7TLtaNE5ytfAVOHbi6+/RuDzd/eN5VOnfuTHp6OqmpqWRkZODq6oq3tzfPPvssmzdvxszMjJSUFNLS0vD2Pne6X9OuN6cLSnlqzh62xWXi7WTDkqm98Xa+tEbbAKsOnsJMgIudFfMjk2sFZ+n5JTw2azeudlZseGHAVZ8vL7e4nNeXHGTZvlReHNamzp6VQggGhzShTysP1h9J50BKLodS8zhyMo+7uwfw9ujQcz6YtfRypGdzd374+wTmZoLbOvvy2IAWtQLZfq088XayYX5kclVw9uHKoxSVGfj9sZ4Ulxk5mJpLRn4pD/YNOmcWysxMcEdXP75YH0NKTnHVkA9FZRU8OWdP1eClLraWfLLmGN9ujGNORBIBbnbMe7gn4UFutfbXI8idh3+N5Om5e3G0saBLgMsFeyOeee5PD7n49etDJ39XXO0s2XA0nQTToK91jWWmaVfbjROcNaBx48axcOFCTp06xYQJE5g9ezYZGRlERUVhaWlJYGAgJSUlDV1MTbtmdidm8/is3WQXlfHskNZ8vzmOKTN3Mf+RnthfYjuhvw6dIjzIjU7+rkzfcpz0/JKq+Qqnbz5OmcHIqbwSZmyLr8o2nelUbgnfbY4jLqOQL+/sjLPt2UMenGlLTAYvLdxPen4pLw5rw+Pn2Hclawtzbm7flJvbX1rm5V+3hPDngZPcFR5QZ8N2czPB7V18mbYpjrS8EpKyilgYlcyj/VvQtZkKmM6swjyXO7r68fm6GJ6as4fbu/gyKNiLz9bEEJdRwKwp3fFwUIOXvjw8mLBmruxLyuGR/i3q/Js521nyy5RwXlq4n6V7U7m7e/3PVXi1mZsJBrTxYvXhNApKK3hxWN0ZTk272m6c4OwCGa76NGHCBB566CFOnz7Npk2bmD9/Pl5eXlhaWrJhwwYSEhIarGyadqbfo5L5dUcCIU0dCfVxppO/C+18na/a/jcdy+DBmbvwdrbh98d60c7XmQ5+zkyZuYun5uzh+3vCLnrgx7iMAo6lFfDWqLb0be3JtE1xLNmTwsP9WpBZUMqsHYnc2smX3OJyvtkYy8Ru/rUaqSdnF/HtxjgWRCZjMA1Z8dy8vUy/J+yc8+rVbGPVwtOeRY/1oqO/y5VfmHNo5+t8wes/LsyfbzbGsSAyieX7T+LjbMNTg1te8rH83ez414gQZm6P51+LD1a9/sTAlvQ+o7PF4JAmDA45/wjq1hbm/G98Jx7q2/wf24h+YLAXi/ekADBSV2lq18iNE5w1oNDQUPLz8/H19aVp06bcfffdjBo1ivbt2xMWFkZwcHBDF1HTqkzfcpyTuSWcOF3InIgkAD6f2KlWT8LLZTBK3v/zMP6udix+vHfVxMUDg714e3Qobyw9xOOzo2jjrW7kZgI6+DnTs7lHnVWSfx08BcCwdt40dbalazNX5kcm81Df5vzw9wlKKgxMHdgSg1Ey/PPNfL0hltdNPf82RKczdfZuKgySO8L8eKx/CzZEp/PvpYf4fF0Mzw5tfdbxdsVn8cKCfSRmFfFgnyBeGNamUQwtEORhT7dAVz5bG0OFUTJtUhfsrC7v6/2hfs15sG8QsekFbIhOJ7OwjGeGtLrsspmZiasa3F9r/Vt5Ym4maOfjRDN3+4YujnaD0MHZNXLgQHV7Nw8PD7Zv317negUFBXW+rmnXQmJmEUdP5fP6LSFM6RNESk4x9/wUwawdCVclOFu+P5VjaQV8dVfnqsCs0uSegZzKK+HbjXGsOpRWa5m1hRk9W7gzIcy/VrXgqkOn6OTvUtWOalxXP15ZdICN0Rn8si2eEe2b0tJLtc8a28WPX7YncG+vQP6OPc3rSw7Spokj39/TFT9XVV04uUcz9iXl8vm6GNr7OjPENLdeXkk5X62PZfqW4/i52jL3oR50b351egReLePC/NkVn03/1p4MC72y9qtCqE4Lun2Vqp7998i2tGqix6DUrh0dnGmaVmX1YZWJGtq2CUII/FztGB/mz4crj3I8o4Dml9mjElTPzP+tOUawtyMjzjGdzIvDgnlxWHUmubTCQMSJLNYfTWfdkXQem72b/47twPhu/qTkFLM/OZdXbq5e/5YOTXl72WGemruHwjIDTw6qrtp7bmhrlu1L5e4fdpKYVUT/1p58fXeXWmNhCSF4/7Z2RKfl8ey8vfRr48mhlFziM1Vv0Lu7B/DaiJBLbhd3LYzq4MORk3k82Le57vl9ld3bK7Chi6DVp/Ji2Po5tB4OPp0aujSAniFA025IUkoKSyvOen314RnV9mUAACAASURBVDTaNHGsVX1ze2dfzM0EC6OubPT4RbtTiM8s4rmhrc/ZnutM1hbm9G3lyZujQlnzXD/6tvLglUX7WXHgZFWV5vAaWSJHG0tGtG9KfkkFw0KbEOxd3c7Jx8WW+3oHkphVxJ3h/vx4b1idg5TaWJozbVJXHGws2J+cQ7C3Ey/c1JpFj/fi/dvaN8rADMDWypw3R4WeNbG2pmnnYTTAoodg4wfww2DY+CEYyi+8XT1rnN8ymqZVMRgli3YnM7KDz1UZCqK0wsDU2XuIOJHJmuf6V805mFVYRmR8FlMH1m5I7lWRyoBWHvy+O5nnhrauPelx+lFwbwnm5/8qKasw8vm6GDr4OTO07fkbkZ+LtYU5303uyuQfI3h67h68HG0I9nYk0KN2O6B7ejZjY3Q6Tw8+u83YCze14aa2TegS4Hre7JKfqx3bXx18WeXUNO0fQkpY9RocWQYD/wWnY1SQFr0SbpsGXiENVrR6zZwJIYYLIaKFELFCiFfqWB4ghNgghNgjhNgvhBhhej1QCFEshNhr+jftcstwrkmDrzc3ynneiDYcTefFhfv5aeuJK95XSbmBh36JYu2RNArLDHy2NqZq2bojaRgl3NTWlImSEta9C1905hmPCNLyStkSc7p6Z3Hr4Zvu8GVn2DENSs/dXnJeZBIpOcU8f1ObK6pys7Oy4Kf7utHSy5GUnOI6pwLq6O9C1BtDaVtH70BLczO6NnPT1X6adqOREg4ugsNLIV9l3dn+NeycBj0eh/4vwdjpMP4XyE2C2eMaNINWb5kzIYQ58DUwFEgGdgkh/pBSHq6x2uvAfCnlt0KItsAKINC0LE5KeUWVvzY2NmRmZuLu7n5dfxlLKcnMzMTG5tIH8NSuAUO5GgA5aSek7gXfLtDpbrC+uPZb66PVxMsztsXzYN8grC3OkT0rK4RtX4Iwh7D7wb720AdFZRU8ODOS7ccz+c/Y9hw5mc+vOxKY0ieIll4OrD6cRlNnG9r5OoGhApY/A3t+BTNLQk//hZv90yyISmJgsJoQmv3zwdoJnHzhr5dh4/9B/1egx2NQ4/N2KDWXT1ZHE9bMlX4XOd7W+TjbWjJrnB+Jv79OC+dRYGh+wczddclohN0zITMWutwLnmdnCrVrSErYP0991ge9AZaX+X2cdQK2fgbOfuDfQ31fWOleolfEUA7Lnoa9s6tfcw6A3ERoOwZuer/69bZjIKAXZJ8A8wuPd1hf6vMbLRyIlVIeBxBCzAXGADWDMwlUPt46A6lXswB+fn4kJyeTkZFxNXfbKNnY2ODn59fQxdDOtPsXWPkylKsG5di5w/65sOH/IOwB6DgRLNTAnggzFeiYVQdfMj+Nlgc/Z5PtVk6UeBIzfwPtegwF365gXaMnXeJOWPIoZB1Xv2/5GDrdBV3vAxs1jMEb83bjkHSAv0JzaXPgKyrKijlueSsfrfLiswmd2RKTwYQwf0RFCSx8AKJXQL+XADDb8jGTOrzMt5FpZBWWYW9egTi0jB1WvdjS5G1GtU2hXew0zFa9CjmJMOz/wMyM/ck5TP4xAhdLIx/f0eHqPCRlROM+93bc85Lhz+Xw93sqIGw9vPraWTmcFZxeV3ISYelUOLFZvW+2fwWtb4ZeT6gbi9llVIpUlMKBBbDrB2h1Ewx87dK2Ly1QQcS1fhA+vhFWvw4th8KAV6o/T9dSfpp6mIleoX5P3QMTfwNb0/h3RVnw1ytQmAFjfwQ7t7r3U3gaZo1VmRtDmXpNmKuAYcRHl/+eNlSAofTSgzyjAaTx7CAl/Qj8+Ty4NIPh/we2Z0yNVpKnPoOX8z68VFJCaZ56UKzrvVdWBAvug5hV6uGx1VD1oJy0E5r3hxEfn11OB0/1rwGJ+qoOE0LcAQyXUj5o+n0y0F1K+USNdZoCqwFXwB4YIqWMEkIEAoeAY0Ae8LqUcsv5jhcWFiYjIyPr41Q07fzKiyF5FzTrU/tDfnQFzLsbmvWGblPALxycfSEpArZ9AUeWo55ParByBL+u4N8d8k9h3DcXKspI9+xOUdYpAo0JmCHVDblJqFoPoW6oLv5w67dg76nS9fvmqi/kM5lZQtOOUJCOzE1iesUIcnq+xK9bYvijVyxBsb9CXqq6GYQ/pL6Iv+nBqT7v0mNtC4a2bYJL4ho+qviQF63/zZKCEMoNEidrM/7nsoDBub9TEnwbh8P/wxszV/Kg5UrGyI2YuQWpdhyX0hsqOUrdbL1CVOCVFAG/jVfncPcCVc5tX0LittrbCTMY8w10uvPij3U+2QlQlKmyGOdjNELSDvDrdmVP3UkR4Bp09g1CStgzC/56FZAqCG4zQv39d01XZbR2Bv9u6r0RfIt6n5wp7ZD6u1bKOqG2L0gDey8oTIeb/wvdHzl/OaWExB3qbxC9Qh2r15MQejtYWKnl2fHqWB6tVPvEiw3eyoshZnXtqiW3IPDuoK5tWSGsfQsivlfv+cIM8ApV77GmHS7uGJVK8yElSr2vfDqD1dkzMdSpIEPd9Fe/ocoz5E11/ZY8Bh6tYdLvcHIfLHtKBWjCDFybwaRF6vNaU1kR/DJaZd7u+UNdr5QoFXxGfK8eskZ+BiEj6y5LURak7lbXx8GU3S7JU9nVHd+q4HvKanA//0wWVY6tgj+eUt8h3R6E8IfVw+X2r2D9eyrQK81X1370lyroOXVQLT+wAJoPhPEz6zfrV5AOy56B6D/Bsan63Pl3B8caTTMivlffz7d8or6HGxEhRJSUMqzOZQ0cnD1nKsMnQoiewI9AO8AScJBSZgohugJLgFApZd4Zx3gYeBggICCgqx5pX7vmirJgzp3qhhzYF8Z8Ba6BkBwJM0aqoOK+5XV/QWXGqZtwZYBmKKuu/kw7BOZWHPS8hSfjezHvtUlsjM7g3YU7+G2EOe0NRyFpJ4bEXZhXFPKXzc3MsHuAYjM77uoewIRuAeqLK24DSANrD6ex8uApXpt0C+6twlWVS2k+5X+9juWeGSQYvXA3y8eBYnUe/V5UT5WVvu4Bti6MKXqdfcm5/OryPT2Me7F4KYZCgxlbY0+z4Wg6G46mcVvRQl6xnEui9MJPZCDMLRGht8OJTeoG2u9F6Pv8hYOXnd/DyhfVz1aOKjBKilBfvJMXqxt1pZTdkHG0+ve9v0HidhXAtRh0OX9ZJTkKtn+p2qlICbd8rG5U57L5Y1j/rsrinOvGVJKr3h8pUSoAC721+loUZ6t5gPfPBVs3GPkphN6mluWfUlUzx/5SDwK3fq3ea5XKi1XD5oSt6jqlH1HBQN/n1TW3sFI36I0fqGEDpLF2uVoMVoFVYF+Yf48Ktib8CiGjzj4Ho0Eda9uXkBKpMiftx6u/ccZRcPRRQU5KpAr4Ktm6qZunf7j6/1yBkKFctfk5vuHsZRa26r2Ql6qqnno8rqoR47fAH0+qALXjRPWeAXUNvELU8TxMg+lmx6trlLTTdK0OVV8PMwsV4NQsp7OvOueMo9XbJO2szlT7dFFBoadpeqe4DTBvknqgKMmFJu3U8pI89X1hZa8CtyZtq6/nvMnnvuZph2Dxo3Bqv7rOA18Ft+bVy4+uUAFgoamWyDVIBconNqusUrM+kHFEZZemrDl/VqgkTzWS3/MreLVV+4peAeZW6v12OlqV75b/QV6KKlfGETXX9KkDYGkHrYepz4xPZ7hrAdhfxpiAsesgZk317+aVf5dwlbE7vASWP6eC4vCH1PssaafKKtdkbq3akrUdc+llqGcNFZz1BN6SUg4z/f4qgJTygxrrHEIFcEmm348DPaSU6WfsayPwgpTynKkxnTnTrrncFFUFkRWnniqjZgKSuJBHCYj+GQtbR8SUtZeXHi/NBym5/acDlBsky57sQ2mFgd4fbiDUx4mZD4SzfH8qL8zfQ3P7cry8fQCITS+gpNzI9lcHYVmjV+UtX2zB2sKMRY/3PutQ65f/hmfEfyh3DqLLxH/XnR3a9F/Y8D6pU3aTUWFPxzldod3t6om5Biklh0/mcWrTj3Q6MR2bzuOx7/M4ODZRgezKl+HAfPVF3u8lldkxq6MN3ZFl6mbV5mZoe2t1NYS9J9z+fXVm4FxKcuGnm9UX9QMr1fGKcyBqhqpy6vNs7Qye0QiRP6p2dJU36bJC0w3NWbXhyziqAqP+L8OAV8/OACXugJ9HgHc7dZPy6aKCQzs39ffcMwv2zIa0g9TKmDr5QvdH1c12xYvqJtPrCTixRWVCQm+HloNV1V15MQx5C8IfuXCVUWGm2mbfb+r8+74Am/4D6Yehyz3QY2qNamB7cPKp3vbMLE5A9+prsmc27PhaBTiuQdBzqqpCt7JX1zFunQracpNNmYxwFSicPlYd2Jw+pvZnZqGu09B3oFlP9ZqUqsp272y4+SNoMdD0N6oZHO2EijIY/gEE9a0ud2X1YfRf1a8ZyqCiWP1s66qyY4WmW4yVI/iFmQKxbuoYlWVMjqzeztEHygpUoAPqfVgZvPmFq//PfB+n7oHFj0HwCPWeqaxuTTsEv96umjp4mNoJluaroOfmj6D7w3X/PSvKYPNH8Pf/QBpUgNTtQdg7p/pvPOA19X2UuANO7lfn1utJ04PNLpg5SgWE9y6r+8Hh+CZ17fNSoPcz1dXEp2PV3zxhO/R9DtqPq37/V5SqZhoxq6HdWNVcw85NBYwL7wdnf5i8CFwC6j6vusSuq86Qm5umW6soqa4JsHWD4iwV/N32XXVQDKqKubRGHsfO/dzVyA2soYIzC1S15GAgBdgF3CWlPFRjnZXAPCnlDCFECLAO8AU8gCwppUEI0RzYArSXUmad63g6ONOuuqIs9SF3aUa5UfLXwVPc3M4bCzMBJ/fC3EkqCJg4W2WZchJJmTkF3+wIsqQDT9n9h57hPbi9i2/VCPaXIquwjK7vreGpQa2qphL6cl0Mn6w5xn29ApmxLZ5uga5MvycMFzv1BbbuSBpTZkYybVIXhpsGek3KKqLvfzfw2ohgHu53dpVGhcHIO8sPMz7M/9zT7JyOha+6wrAPVBZh/j0weUn1jfNSHF6qqoFyElRA0nOqCkAqv0CTIkw3kXamm8hFVjGdKTcFfhyqgq22Y1RwVFagbsgVxSo47PucCoaWTlXVR94d1I0XVMalxUAVyFg7qnY7y56GvbOg6/2q2rcy41WUBd/1UzfoRzarwGrhA6oKq/VwVbVUkqtu5C2HqJu5bxfVVnDbFyrrA+AZrKqmfbuo4239TI27ZCwH3zCVfanM/lyso3+qchdmgIO3Cqhb33Th7QpPq+tXmR2qya8b9Hrq3MH1hRRlqaqmpJ2qCiwnSQWkA1+Hvz9VQWT/V1SG6EoZjarTRGVQZyivzohVVpfXxVCuAumkCFVWKwcI6KG2dQ26srZ12Qmw9k2VparUcgj0fPzC2+adhIjvIPIn9Z4S5rWzo+dz9E+V0Ws1TGWTKtutlhWZqoi/U1XPt05TweqVStgGcyaq93JlVbtPZ/X3Ttqhrq2VPYz8HzTrpbY5uR9+vlll6e5fCTamZumGCvVgkWwKnD2D1XdHAzbav1INEpyZDjwC+AwwB36SUr4vhHgHiJRS/mHqoTkdcEA9Sr4kpVwthBgLvAOUA0bgTSnlsvMdSwdn2lVT+ZS49zf1tGbvRZJDexanOHKbbx7+BQfUjc7eCyYtVO23gG82xvLRX0d4o9kRAkLCmB5ty84T6nmiqbMNoT5OhPo4c1tn37PG5gI1zEXNeRoX70nm2Xn7WDq1d9XE2lmFZfT6cB0l5UZGdmjKx+M61tqmwmCkz3820MbbkZkPhAMwffNx3l9xhM0vDiTA/TIDHYBpfcDCRmV64v+G56Mvv5dkVbXYF6p6D8C9lbrxRa9UDamnrLnyRv1ph+Gn4VBeqJ7qez6hesFVZvCatFPZNaMBhr2vOlCc76YrJax7W2UvnP1VR4TOk1Ubo2OrYMoq1VkDIH6rqsIqy4eQ0SqD4Vfn97DKsqQdVmU8s5ffqYPqYaDDxMu/3oWZcPB3aH/HpWURcpNVZsZoGrBYCGg+QAUpV0tpAax5QwUbzv6qMXynSaqJwHXcy/6KlRaoz5BXyKW144yYDiteMFX3hqqg6fgmlXHr/igMfvPyH4jqkhGt2n1VNteozEw7+qjPe+oe9RnsOVV9/maMVAHzg2trZ3OvQw0WnF1LOjjTroiU6stj25fq6dLcSrVbadoBmbyL1AOb8DWeJMWsKT7t+yP8u6uG2I7eSCn5fF0Mn62NYXRHHz4d37FqoNYTpwtZeziNQ6m5HEzNIy6jAAszwQN9gnhyUCscrC2Iyyjg6w2xLN2byj09m/HvkW0RQvDEb7vZcTyLiNcG1xpRf25EItlF5TzSr3mdI+1/uuYYX66PYctLA/FztWPst9soLjOw4um+Z617SbZ8qgITc2voPEm1h7pSUqr2Yic2VbfjsbKHe5ZefMPlC8lJVNVnZ37RH16q2qx4BqtAoGYbtgs5tlq120r4W7WBqihW3fF7PVF7vdxkdTO6lCqdG1XsWvjjaVUFOnH2Pzoj0uglbFMBWdJOlYWyc1OfgaB+9Xvc0nz1sOHirx6SoHZwLsxUZvuBv6rb413HdHCm3XgqytSX+4WevI0GOLpcBWXJu1SblG4PqQampnZNUQnZjP12Gz2b2bM9oZC5D/egR41Jr+dHJvHSwv3c0dWP/4ztgPl5piZKzyvhv6uiWRiVjKejNZ39XVhzJA1rCzO6BLiyLS6Tu7oH8NaoUMLeW8OwUG8+Gtfxkk49OVtVYz45sCWTejQj/P/W8dzQ1jw1+BKrw86UdQK+MD2h3/cnBPa5sv3VRUr171p0wQdVVWJmfvkZmuQolWW1soeRn1+7cl+vjEb1t9AZs2vHaFBBUUNf89i16gFw4Gv1893SCJ0vOLsBR27UGrWKMtXOw7v95T85J+5U7Ry8QmDM1+fOiKQfhcWPqCoj1yA13k1lw+YaZu9IwMHagq8m92Twp5uYsTW+KjjLLizjgxVH6Bboyn/HdrjgnJFeTjZ8PK4jd3cP4O1lh9kel8mj/VswpU8Q7vZWfLQqmm82xnHsVD55JRUMCr5Aw/c6+Lna0a+VJ/Mjk3GzV21Q6hpJ/5K5Bakqu7xUCOh55fury7W+MV/p4LV+XeGOn65OWTQd3DaEy2kzWB9aDlH/NEAHZ1pjUdmTbuc0yD+pGo3eOg28gi9tP9F/qQEHHTxVT7Nve8Ow91QD7sqbvtGgxgFb/54apf/26aqtTx1fUlmFZSw/cJKJ3fxxd7DmzvAAvtsUR3J2EX6udvx31VHySip499Z2Fz2ZN0DnAFeWTD275+SLw9pgZWHGZ2tjsDQX9LnMEfXvDPfn0Vm7+WxdDM097WnldXGzEVzQ7dNVL7PG8oWuaZp2HdLBmdbwIn9WXf7LCiCov2oYuuVT1ftt8BtqHKMzg4GT+1TDVqOhuudV6m41aGLTDnD3QtWYf+lUWP4s7PqxehTrgnTVbb3NLTDqs6rqS4NRsvZIGj2au+Nsq7J2CyKTKKswMqlHMwAm9WjG95uP8+uOBIaHejN3VxJTegcR7H32PI6XQwjBM0Na4+FgTUFpBY42l5c9HBzSBA8Ha04XlHJXeMDVm77sarUD0zRN085JB2daw0rcqaYBCewNN71X1fORDhNU9//Vr6vBSJv1VEGYvacaDf3EZqSVA8LCRo3xU6n5AJgwq7qL+OQlqqHpwUUqkAMVjPV9Th3DFLRUGIy8uHA/i/ek4O1kw3/v6ECflh78FpFIeKAbrZuo/fm62DIstAlzI5LYcuw0Xo7WPDP06s9pWBkMXi5LczPGhfnx7cY4bjYNqaFpmqb9M+gOAVrDOXNsKJszxtiSUnX/P7xEBXGVA0c6NsUY/iiT94bg5OLOl8NdsEiJUD2But5/3rF+yiqMvPnHIYK9HZnQzR8bS3PKDUaembeXP/ef5L5egWyJySAuo5C+rTzYEnOaL+7szOiO1T39Ik5kMf677QB8eWdnRnVsnN29C0sr2BaXydC2TRq6KJqmadoZdIcArfGRUk21kn9Szfd2ZmAGKqvV/g71T0o1aGl2PAT0YsvxXLamREBKGu842fD26Dsvqurut50JzIlQ03t8tSGWh/s2Z1d8FqsPp/GvESE81K85JeUGPl4VzY9bT+DhYMXw0NqN6bsFutI5wAVnW0tGdmi8WSl7awsdmGmapv0D6eBMaxi7flBDWNz0XvWgnecjhBox2jSX4IytJ/B0tGZkh6b8vDWeQHd7Huhz/nGq8kvK+WJ9LD2bu/PU4FZ8tSGG91eoyZ/fHh3Kvb3Uvm0szXl9ZFtGd/LBTAisLGr3IBNCMP+RngjTz5qmaZp2NengTLv2olfCqn+pyaF7TD3vqjO2nsDa0pw7w6sH8TxxupAN0Rk8O6Q1Tw5qSWpOMe/+eZgANzuGnCdTNH3zcbIKy3h1RDAd/Fzo2cKdPYnZ5JdU0K/12fNfdvBzOee+as5bqWmapmlXkw7OtGtr96+qoX/TjmoC6/OMazR7ZwJvLTuMEODvalc1rMTMbfFYmgvu7O6PmZngswmdmfj9dh6dFUV4kBuDgr0YGOxFcw/7qsxWel4J07ecYGSHprWCrs4BrvV7vpqmaZp2ifTjv3ZtSAlbPoE/nlCThN+7rGqOPyklZ3ZM2XQsg38vPcSANp609HTgmXl7ycgvpaC0goVRyYzs4IOXo5qD0NbKnJ/u68aUvkGcLijlvT+PMPiTTdz+7TbWH01DSsln62IoNxh5cViba37qmqZpmnYpdObsRlacoxriX0m7qZI8NaJ+XYOSFmSouQeTIig/sRXLtH0c9RzGbLtXODXvKOn5pWTklZBRUIqzrRVju/gyvps/5QYjU2fvpnUTR766qwvJ2UWM+Worz83fy6BgLwpKK7jP1D6skruDNa/eHMKrN4eQlFXE6sNp/PT3CR6YEUnbpk5Ep+UzqXsAzdzPnnBc0zRN0xoTPZTGjSp+K8wcpQZs7fUkhIxRU9lICZmxkBGtpj9ya1538JYRreaj3D9PDRx755za0y0lR8LM0VBeiLSwYZ+xBctLO/Gj4WZc7W3wcrTG0/TPy9GG4xkFrDuajsEosbU0x8nWgiVTe9PU2RZQVZz/WnwQK3MzQn2dWPz42aPrn6ncYGTxnhS+2RBLdlE5657vj4eD9dW6gpqmaZp22fRQGlpt5SWq3ZejtxobbOED4ByggrHkCCjOrl7XzkONvu/sC5iCtKzjELsGLGygxWA4thKWPwOjv1KBXGYc/DYeHDwpuOV3Ji4r4nh2OT88EMZLzdzO6v1YKT2/hN+jUtgSk8FrI0KqAjOAu8ID2Bp7mhUHTp2VNTsXS3Mzxof5M7aLH8XlBhys9dtd0zRNa/x05uxGtOH/YNN/YNLv0HyQCq62fwOFGdVTIXm2gfTDkBQBSTuh8HT19taO0HkydJsC9h6w/n3Y/F8Y8Cp0exB+GAIluRRNXsndSzI5lJLHz/d3o3fLy5snslJBaQWbojMY3s4b80uYx1LTNE3TGpvzZc50cHajyYhWk4GH3gpjf7g6+5QSljyuplFyCYCCdMomLeGBtWZsP57J13d1YXg77wvvR9M0TdNuELpaU1OMRlj2jGrAP+yDq7dfIWD0F2q0/+MbMYz7hSe3WPJ3bBqfjOuoAzNN0zRNuwQ6OLsRFKSr6snolZC4TbUNczh70NUrYm4Jd83DmJ3ISxuKWHUomTdHtWVsV7+rexxN0zRNu87p4Ox6VVYIe2bDrulw+ph6zdwKOt4JnSfVyyGluRXvbC/j993JPDe0Nff3Pv90SpqmaZqmnU0HZ9ebklzY+oWau7IkB/y6wdB3IaCHGpXf4sqGkig3GNmfnEtnfxfMajTKL6sw8s7yQ8zakciUPkE8OajllZ6Jpmmapt2QdHB2vfnjSTj8B4SMhJ5PQkD3q7ZrKSUv/76fRbtT6BzgwlujQuno78LJ3GIem7WbvUk5PNKvOa/cHKwnBNc0TdO0y6SDs+tJ4k44vFQNaTHglcveTVRCNs/O28vLw4O5pUPTqtd/2Z7Aot0p3NK+KTtPZHHrN1sZ1cGHrbGnKa0w8u3dXbi5fdPz7FnTNE3TtAvRwdn1QkpY/To4eKsR/y9TucHIa4sOkJhVxNTfdpOaE8KDfYPYFZ/Nu8sPMyTEiy/v7ExhWQVfro/l560nCHS3Z9rkrrTwdLiKJ6RpmqZpNyYdnP0TFWWpgWFbDQMz02j7h5eq0f1HfaGGyrhMM7fFE52Wzxd3dmbVwVO8v+IIselqaiV/Nzs+ndAJMzOBo40lr41QgZuTjSU2lnXMralpmqZp2iXTwdk/TU4i/Hqbmv+yWR+49Wtw9IG1b4FnyHl7Yn665hhL96bQp6UHg4K96NXCA1ur6qDqVG4J/1tzjIFtPBnVoSkj2zfF19WW7zcfx87KnN8e6o6TjWWtfXo52tTXmWqapmnaDUkHZ/8kaYdg1lgoL1LtyrZ/rUb7bzEQsk/AXQvArO4MVkpOMdM2xuHjYsPiPSnM3pmItYUZ48L8eLR/C/xc7Xjvz8OUGyVvjQ5FCIEQ8NqIEDr6ueDlZE3rJo7X+IQ1TdM07cZTr8GZEGI48DlgDvwgpfzwjOUBwEzAxbTOK1LKFaZlrwJTAAPwlJRyVX2WtdFL2Aa/TQQrO7j/L2jSFjrdDUsfhyPLIKgftBp6zs2/Wh8LwOyHeuDhYEXEiSyW7zvJvF1JzI1IYmCwF2sOp/HMkFY0c69dLVqzU4CmaZqmafWr3oIzIYQ58DUwFEgGdgkh/pBSHq6x2uvAfCnlt0KItsAKIND080QgFPAB1gohWkspDfVV3kbLUA6bP4bNH4Fbc5i8SM1fCeDiD5OXQvQK8AtT0yjVITGziAWRSdzdPQBfF1sA+rbypG8rT54e0orvNx9nTkQige52PNq/xbU6M03TNE3T6lCfmbNwIFZKeRxACDEXGAPUDM4k4GT62RlINf08TYrvNwAAGlVJREFUBpgrpSwFTgghYk37216P5W180g7D4kfg1H7oMBFu/hBsXWuvY2amxjQ7j8/XxWBuJpg68OyBYX1cbHlrdChPD26FEOiG/ZqmaZrWwOozOPMFkmr8ngycOSLqW8BqIcSTgD0wpMa2O87Y1rd+itlIxa6DORPB2gkmzIKQUZe3m/QCFu9J5sG+zfFyOnfjfVd7q8stqaZpmqZpV5FZAx//TmCGlNIPGAH8KoS46DIJIR4WQkQKISIzMjLqrZDXXN5JWPQwuLeEx3dcMDA7lVtCZkHpWa9XGIx8uiYaG0tzHunXvL5Kq2mapmnaVVSfmbMUwL/G736m12qaAgwH/r+9e4+zqrzvPf75MtwFBOQSAwioo4KYoI5Ea2K8xaC2Xk7tkcS0akz0tBqNJ2mix9PEY097PD09WpOaRGsMaqyaqBhqNFbBaKyi4JWLoggqgygolxmQgbn8+sdag5sZBvYeZ83es/f3/XrNa/Z61rOH3zwuNz+eKxHxjKT+wIg830tE3AzcDFBTUxNdFnkxtTTDrAuTFZl/NhMGjdxl9bufe4erHlhESwRTxw3luANH8emhA3jy9bU88fpaNm5p5NLj92evQZ/sTE0zMzPrHlkmZ/OBakkTSRKrGcBX29R5BzgBmClpEtAfWAvMBv5V0nUkCwKqgecyjLV0PHUdrHgSTvtnGHlgh9UigusefZ0fz13GF6pHUDN+OHOXruH6x14nAkYM6suJk0Zz/EGjmD7lU934C5iZmdknkVlyFhFNki4BHiHZJuPWiFgs6RpgQUTMBr4D/Iuky0kWB5wXEQEslvQrksUDTcDFFbFS8+1n4PG/hyln7XIz2W1NLVxx3yvc/+IqZhwxjr89Ywp9qnpx2YnVfLBpK2vrt3Lg6MH06uXDx83MzHoaJbnQbipJ9wM/Bx6OiJbMo+qEmpqaWLBgQbHD6LyWZrhxGrQ0wUV/gP5DOqz6d79dwr/8YQXfPekALj5uf9TBFhpmZmZWmiQ9HxE1O7uX7+T7n5AMSb4h6VpJHY+3WecsnpUcyfSla3aZmC19r55b/+MtZhwxjkuOr3ZiZmZmVmbySs4i4rGIOAc4DHiLZFPYpyWdL6nPrt9tu9XSkmwyO3ISHNTxysyI4G9+s4jB/XvzvekHdWOAZmZm1l0K2bZiL+A84BvAiyTHMh0GPJpJZJXk1dmw9jU45rvJprIdmPXiKp5bsY7vTz+I4d6XzMzMrCzltSBA0izgQOAO4E8iYnV66x5JPXiiVwlo7TXbqxoOPnN7cUSw/IPNjBk6gP59qti4pZG/f+hVpo4bytk143bxA83MzKwny3e15o8i4vGd3ehoMpvl6fWH4f1FcOZN0Ovjo5P+6bE3uGHOG/TuJapHD6ZvlVi3eRszz5/mVZhmZmZlLN9hzcmShrZeSBom6a8yiqlyRMAT/wDDJibbZ6QeW/I+N8x5gy8fPJqLvrgvowb3Y/XGBi764n5MGbNnEQM2MzOzrOXbc/bNiLix9SIi1kv6JskqTitUcyMsfgCe/lFyqPnpN0JV8p9i+dpNXH7PS0wZM4QbZhzqg8jNzMwqTL7JWZUkpRvEIqkK8Iz0QkXAC7cnvWV1tTDiADjtxzD1HAA2b23iojuep0/vXvzsa4c7MTMzM6tA+SZnvyOZ/H9Ten1RWmb5qnsXfnMJvDkHxn0OTv3/UH3SDqszr569mDfXbuKOCz7H2GEDixismZmZFUu+ydn3SRKyv0yvHwVuySSicvTKr+Ch7ybDmaf8I9Rc0G7LjHWbt/HAS6v4i6MmcPT+I4oUqJmZmRVbXslZemTTT9MvK8Si++D+b8K4I+GMn8Be++202oOvvEtjc3D2Ed4mw8zMrJLlu89ZNfB/gMlA/9byiNg3o7jKw7oV8G/fhrHT4LwHoarjwxTue2EVk/YewqS9Oz66yczMzMpfvltp/IKk16wJOA64HfhlVkGVhaZtcO/XQYI/vWWXidmyNZt4eeUG/vSwMd0YoJmZmZWifJOzARExB1BEvB0RVwOnZhdWGZh7Dbz7Apz2zzBs/C6rznqxll6C06Z+upuCMzMzs1KV74KArZJ6AW9IugRYBQzKLqwe7o3H4OkfwxHfgMmn7bJqS0sw64VVHHPASEYN7r/LumZmZlb+8u05uwwYCFwKHA58DTg3q6B6tK318G+XwshJcNL/3m31ecs/5N2NDfyXw8Z2Q3BmZmZW6nbbc5ZuOHt2RHwX2AScn3lUPdncv0v2NLvgNugzYLfV73thFYP79eakyaO7ITgzMzMrdbvtOYuIZuDz3RBLz7fqeXj2Z8lw5rgjdlt909YmHl60mlM/s7dPAzAzMzMg/zlnL0qaDfwa2NxaGBH3ZxJVT9TcCLMvg8GfghN+sNvqH27aygW3LWBLY7P3NjMzM7Pt8k3O+gMfAsfnlAXg5KzVvJ/A+wvh7F9C/13vVbZ87SbOnzmf9zY28NNzDufQfYZ1U5BmZmZW6vI9IcDzzHZl22b4/bVw4Ckw6U92WfWFd9Zzwcz5SOKuC4/kMCdmZmZmliPfEwJ+QdJTtoOI+HqXR9QTvfsiNH4Eh5+3y2or133EBTPnM2RAH27/+jTG77VH98RnZmZmPUa+w5oP5rzuD5wJvNv14fRQtfOT72M7XgTQ0NjMX975PE0twczznZiZmZnZzuU7rHlf7rWku4CnMomoJ1o5H4bvBwOH7/R2RHDVrEUsWlXHz8+tYeIIJ2ZmZma2c/luQttWNTCqKwPpsSKSnrNx0zqscse8t7nvhVq+fWI1J0zyfmZmZmbWsXznnNWz45yz94DvZxJRT7PhHdi8BsbW7FDc2NzCnFfX8KsFK/n90jWcOGkUlx5fXaQgzczMrKfId1hzcGd+uKTpwA1AFXBLRFzb5v71wHHp5UBgVEQMTe81AwvTe+9ExK4PqSyW7fPNPu45e/y1Nfz1vS/zwaZtjB7Sj786dn/+27H70auXihSkmZmZ9RT59pydCcyNiI3p9VDg2Ih4YBfvqQJuBL4E1ALzJc2OiCWtdSLi8pz63wIOzfkRWyJiaiG/TFHUzoc+e8CoyduLrn/sdQb27c2t532GY6pH0ruqs6PHZmZmVmnyzRp+2JqYAUTEBuCHu3nPNGBZRCyPiG3A3cDpu6j/FeCuPOMpHSufgzGHQVWS565c9xGv1G7kq5/bh+MPGu3EzMzMzAqSb+aws3q763UbA6zMua5Ny9qRNB6YCMzNKe4vaYGkeZLOyDPO7tW4Bd57ZYf5Zg8vWg3AqYfsXayozMzMrAfLd5+zBZKuIxmmBLgYeL4L45gB3Jsest5qfESskrQvMFfSwoh4M/dNki4ELgTYZ599ujCcPK1+GVqadphv9tuF73HImD0ZN3xg98djZmZmPV6+PWffArYB95AMTzaQJGi7sgrIPdF7bFq2MzNoM6QZEavS78uB37PjfLTWOjdHRE1E1IwcOXL3v0VXa7P5bO36j3h55QZOca+ZmZmZdVK+qzU3A1cU+LPnA9WSJpIkZTOAr7atJOkgYBjwTE7ZMOCjiNgqaQRwNPAPBf752Vv5HAybAIOSxPDhhe8BHtI0MzOzzsur50zSo+kKzdbrYZIe2dV7IqIJuAR4BHgV+FVELJZ0jaTcbTFmAHdHRO4+apNIhlJfBh4Hrs1d5VkyahfscGTTbxeuZsqYIeyzl4c0zczMrHPynXM2Il2hCUBErJe02xMCIuIh4KE2ZT9oc331Tt73NHBInrEVx8ZaqH93+3yzVRu28NLKDXxv+oFFDszMzMx6snznnLVI2j7jXtIEdjwxoPJsn2+WrNR8eGGySvOUKR7SNDMzs87Lt+fsKuApSU8AAr5AukqyYr39DPQeAKOnAMmQ5uS9hzDBh5qbmZnZJ5BXz1lE/A6oAZaSrKr8DrAlw7hK34onYfxR0LsvH2zayovvbODkKZ8qdlRmZmbWw+V7fNM3gMtItsN4CTiSZHXl8dmFVsLq34e1r8JnZwAwb/mHAHy+ekQxozIzM7MykO+cs8uAI4C3I+I4kj3HNuz6LWXsrT8k3yceAyTJ2R59qzhkzJ5FDMrMzMzKQb7JWUNENABI6hcRrwGVuyxxxRPQf0/Y+7MAzFu+jiMmDvc5mmZmZvaJ5bsgoDbd5+wB4FFJ64G3swurxC1/AiZ8AXpVsaa+gWVrNnHW4WOLHZWZmZmVgXxPCDgzfXm1pMeBPYHfZRZVKVv/Fmx4G45KTq96dvk6AI7ad68iBmVmZmblIt+es+0i4oksAukxVjyZfJ/4RSCZbzaoX28O/vSQIgZlZmZm5cKTpAq14knYYxSMTKbcPbP8Q46YMMzzzczMzKxLOKMoRESSnE08BiTW1DWwfO1mjtrPQ5pmZmbWNZycFWLtUtj0PuybDmmuSOabHen5ZmZmZtZFnJwVYkU63S7d3+yZNz9kcL/eTN7b883MzMysazg5K8SKJ2HoeBg2AYBnl3/o/c3MzMysSzmryFdLc3IyQNpr9n5dA8s/2OwtNMzMzKxLFbyVRkU761YYmJyf2XqepuebmZmZWVdycpavXlWw/4nbL5et2UQvwWTvb2ZmZmZdyMOanVTf0MSgfr2p6qVih2JmZmZlxMlZJ9VtaWRw/z7FDsPMzMzKjJOzTqpraGLIACdnZmZm1rWcnHVSfUMjg/t7yp6ZmZl1LSdnnVTf0MQQJ2dmZmbWxZycdVJdQyNDPOfMzMzMupiTs06qb2jysKaZmZl1OSdnnRAR6Zwz95yZmZlZ13Jy1gmbtzXTEjBkgHvOzMzMrGtlmpxJmi5pqaRlkq7Yyf3rJb2Ufr0uaUPOvXMlvZF+nZtlnIWqb2gEcM+ZmZmZdbnMun4kVQE3Al8CaoH5kmZHxJLWOhFxeU79bwGHpq+HAz8EaoAAnk/fuz6reAtR39AE4DlnZmZm1uWy7DmbBiyLiOURsQ24Gzh9F/W/AtyVvv4y8GhErEsTskeB6RnGWpC6LUnPmVdrmpmZWVfLMjkbA6zMua5Ny9qRNB6YCMwt9L3F4J4zMzMzy0qpLAiYAdwbEc2FvEnShZIWSFqwdu3ajEJrr85zzszMzCwjWSZnq4BxOddj07KdmcHHQ5p5vzcibo6ImoioGTly5CcMN391ac+ZV2uamZlZV8syOZsPVEuaKKkvSQI2u20lSQcBw4BncoofAU6SNEzSMOCktKwktK7W9JwzMzMz62qZdf1ERJOkS0iSqirg1ohYLOkaYEFEtCZqM4C7IyJy3rtO0t+SJHgA10TEuqxiLVR9QxN9qkS/3qUyKmxmZmblItNxuYh4CHioTdkP2lxf3cF7bwVuzSy4T6BuS3KupqRih2JmZmZlxl0/neBzNc3MzCwrTs46wedqmpmZWVacnHVCXUOTV2qamZlZJpycdUJ9QyOD+7nnzMzMzLqek7NO8JwzMzMzy4qTs06o29LIkAHuOTMzM7Ou5+SsQM0tweZtze45MzMzs0w4OSvQpu2HnrvnzMzMzLqek7MCfXzouXvOzMzMrOs5OStQnc/VNDMzsww5OStQfTqsOcQ9Z2ZmZpYBJ2cFqtvSOqzpnjMzMzPrek7OCrS958wnBJiZmVkGnJwVqL7BPWdmZmaWHSdnBarfvpWGe87MzMys6zk5K1BdQyMD+lTRp8pNZ2ZmZl3PGUaBfK6mmZmZZcnJWYGcnJmZmVmWnJwVqK7Bh56bmZlZdpycFaiuockrNc3MzCwzTs4KVN/Q6GFNMzMzy4yTswLVbWnyuZpmZmaWGSdnBapvaPS5mmZmZpYZJ2cF2NrUzNamFg9rmpmZWWacnBXg43M1PaxpZmZm2XByVgAf3WRmZmZZc3JWgO2Hnvdzz5mZmZllI9PkTNJ0SUslLZN0RQd1/qukJZIWS/rXnPJmSS+lX7OzjDNfdVs8rGlmZmbZymx8TlIVcCPwJaAWmC9pdkQsyalTDVwJHB0R6yWNyvkRWyJialbxdcb2njMPa5qZmVlGsuw5mwYsi4jlEbENuBs4vU2dbwI3RsR6gIhYk2E8n5jnnJmZmVnWskzOxgArc65r07JcBwAHSPoPSfMkTc+511/SgrT8jJ39AZIuTOssWLt2bddGvxN1ac+ZhzXNzMwsK8XuAuoNVAPHAmOBJyUdEhEbgPERsUrSvsBcSQsj4s3cN0fEzcDNADU1NZF1sHUNTUgwqG+xm83MzMzKVZY9Z6uAcTnXY9OyXLXA7IhojIgVwOskyRoRsSr9vhz4PXBohrHmpb6hkUF9e9Orl4odipmZmZWpLJOz+UC1pImS+gIzgLarLh8g6TVD0giSYc7lkoZJ6pdTfjSwhCKr29LkIU0zMzPLVGbjcxHRJOkS4BGgCrg1IhZLugZYEBGz03snSVoCNAN/HREfSvoj4CZJLSQJ5LW5qzyLpb6h0YsBzMzMLFOZZhoR8RDwUJuyH+S8DuC/p1+5dZ4GDskyts6ob2hycmZmZmaZ8gkBBahraGRIfw9rmpmZWXacnBXAPWdmZmaWNSdnBUjmnLnnzMzMzLLjbqACnH3EPkwdt2exwzAzM7My5uSsAFecfFCxQzAzM7My52FNMzMzsxLi5MzMzMyshDg5MzMzMyshTs7MzMzMSoiTMzMzM7MS4uTMzMzMrIQ4OTMzMzMrIUrOHu/5JK0F3u6GP2oE8EE3/Dk9idukPbdJe26T9twm7blN2nObtFcObTI+Ikbu7EbZJGfdRdKCiKgpdhylxG3SntukPbdJe26T9twm7blN2iv3NvGwppmZmVkJcXJmZmZmVkKcnBXu5mIHUILcJu25Tdpzm7TnNmnPbdKe26S9sm4TzzkzMzMzKyHuOTMzMzMrIU7O8iRpuqSlkpZJuqLY8RSDpHGSHpe0RNJiSZel5cMlPSrpjfT7sGLH2t0kVUl6UdKD6fVESc+mz8s9kvoWO8buJGmopHslvSbpVUlHVfpzIuny9P+bRZLuktS/Ep8TSbdKWiNpUU7ZTp8NJX6Uts8rkg4rXuTZ6aBN/l/6/88rkmZJGppz78q0TZZK+nJxos7Wztok5953JIWkEel12T0nTs7yIKkKuBE4GZgMfEXS5OJGVRRNwHciYjJwJHBx2g5XAHMiohqYk15XmsuAV3Ou/y9wfUTsD6wHLihKVMVzA/C7iDgI+CxJ21TscyJpDHApUBMRU4AqYAaV+ZzMBKa3Kevo2TgZqE6/LgR+2k0xdreZtG+TR4EpEfEZ4HXgSoD0M3cGcHD6np+kf0eVm5m0bxMkjQNOAt7JKS6758TJWX6mAcsiYnlEbAPuBk4vckzdLiJWR8QL6et6kr9wx5C0xW1ptduAM4oTYXFIGgucCtySXgs4Hrg3rVJRbSJpT+AY4OcAEbEtIjZQ4c8J0BsYIKk3MBBYTQU+JxHxJLCuTXFHz8bpwO2RmAcMlbR390TafXbWJhHx7xHRlF7OA8amr08H7o6IrRGxAlhG8ndUWengOQG4HvgekDthvuyeEydn+RkDrMy5rk3LKpakCcChwLPA6IhYnd56DxhdpLCK5Z9IPixa0uu9gA05H6yV9rxMBNYCv0iHem+RtAcV/JxExCrgH0n+tb8a2Ag8T2U/J7k6ejb82Zv4OvBw+rpi20TS6cCqiHi5za2yaxMnZ1YwSYOA+4BvR0Rd7r1Ilv9WzBJgSX8MrImI54sdSwnpDRwG/DQiDgU202YIswKfk2Ek/7qfCHwa2IOdDNlY5T0buyPpKpIpJXcWO5ZikjQQ+B/AD4odS3dwcpafVcC4nOuxaVnFkdSHJDG7MyLuT4vfb+1CTr+vKVZ8RXA0cJqkt0iGu48nmW81NB2+gsp7XmqB2oh4Nr2+lyRZq+Tn5ERgRUSsjYhG4H6SZ6eSn5NcHT0bFf3ZK+k84I+Bc+Ljfa8qtU32I/nHzcvp5+1Y4AVJn6IM28TJWX7mA9Xpyqq+JJMxZxc5pm6XzqX6OfBqRFyXc2s2cG76+lzgN90dW7FExJURMTYiJpA8F3Mj4hzgceCstFqltcl7wEpJB6ZFJwBLqODnhGQ480hJA9P/j1rbpGKfkzY6ejZmA3+RrsY7EtiYM/xZ1iRNJ5kucVpEfJRzazYwQ1I/SRNJJsE/V4wYu1NELIyIURExIf28rQUOSz9vyu85iQh/5fEFnEKyYuZN4Kpix1OkNvg8yXDDK8BL6dcpJHOs5gBvAI8Bw4sda5Ha51jgwfT1viQfmMuAXwP9ih1fN7fFVGBB+qw8AAyr9OcE+F/Aa8Ai4A6gXyU+J8BdJPPuGkn+gr2go2cDEMlK+TeBhSSrXYv+O3RTmywjmUfV+ln7s5z6V6VtshQ4udjxd1ebtLn/FjCiXJ8TnxBgZmZmVkI8rGlmZmZWQpycmZmZmZUQJ2dmZmZmJcTJmZmZmVkJcXJmZmZmVkKcnJmZfUKSjpX0YLHjMLPy4OTMzMzMrIQ4OTOziiHpa5Kek/SSpJskVUnaJOl6SYslzZE0Mq07VdI8Sa9ImpWej4mk/SU9JullSS9I2i/98YMk3SvpNUl3picBmJkVzMmZmVUESZOAs4GjI2Iq0AycQ3II+YKIOBh4Avhh+pbbge9HxGdIdh1vLb8TuDEiPgv8Ecku5gCHAt8GJpPs/H905r+UmZWl3ruvYmZWFk4ADgfmp51aA0gO2G4B7knr/BK4X9KewNCIeCItvw34taTBwJiImAUQEQ0A6c97LiJq0+uXgAnAU9n/WmZWbpycmVmlEHBbRFy5Q6H0N23qdfZMu605r5vx56uZdZKHNc2sUswBzpI0CkDScEnjST4Hz0rrfBV4KiI2AuslfSEt/3PgiYioB2olnZH+jH6SBnbrb2FmZc//sjOzihARSyT9T+DfJfUCGoGLgc3AtPTeGpJ5aQDnAj9Lk6/lwPlp+Z8DN0m6Jv0Zf9aNv4aZVQBFdLYH38ys55O0KSIGFTsOM7NWHtY0MzMzKyHuOTMzMzMrIe45MzMzMyshTs7MzMzMSoiTMzMzM7MS4uTMzMzMrIQ4OTMzMzMrIU7OzMzMzErIfwJStTQr2/A1ugAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_splits = 8\n",
        "number_runs   = 5\n",
        "results_acc   = np.zeros(shape=(number_runs, number_splits))\n",
        "results_loss  = np.zeros(shape=(number_runs, number_splits))\n",
        "\n",
        "\n",
        "for run in range(number_runs):\n",
        "  \n",
        "  print(\"\\n\\n\\nDoing the run number \", run+1)\n",
        "  kfold = KFold(n_splits=number_splits, shuffle=True)\n",
        "\n",
        "  # K-fold Cross Validation model evaluation\n",
        "  fold_no = 1\n",
        "\n",
        "  for split,(fold_train, fold_test) in enumerate(kfold.split(data_incr, labels_incr)):\n",
        "\n",
        "    model = get_model()\n",
        "    print(\"Training the fold number \", fold_no,\"\\n\")\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "    history = model.fit(data_incr[fold_train], labels_incr[fold_train], epochs=160, callbacks=[callback])\n",
        "\n",
        "    scores = model.evaluate(data_incr[fold_test], labels_incr[fold_test], verbose=0)\n",
        "    print(\"For the fold number \",  fold_no, \":\\nloss = \", scores[0], \"\\naccuracy = \", scores[1]*100,\"%\")\n",
        "    results_acc[run][split] = scores[1] * 100\n",
        "    results_loss[run][split] = scores[0]\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "\n",
        "results_acc = np.mean(results_acc, axis=1)\n",
        "results_loss = np.mean(results_loss, axis=1)\n",
        "\n",
        "results_acc = np.mean(results_acc)\n",
        "results_loss = np.mean(results_loss)\n",
        "\n",
        "print(\"\\n\\n\\nWe obtain the following results:\\nmean accuracy: \",results_acc,\"%\", \"\\nmean loss:\",results_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9POXtAc-z8Pj",
        "outputId": "80c3aa89-df64-4b6d-c778-bdab2ecfe139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3815 - binary_accuracy: 0.8324\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8305\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3778 - binary_accuracy: 0.8259\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3750 - binary_accuracy: 0.8293\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3690 - binary_accuracy: 0.8320\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8282\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3696 - binary_accuracy: 0.8290\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3694 - binary_accuracy: 0.8328\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8354\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8370\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3679 - binary_accuracy: 0.8328\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8328\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3690 - binary_accuracy: 0.8377\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3655 - binary_accuracy: 0.8347\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3688 - binary_accuracy: 0.8396\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3653 - binary_accuracy: 0.8404\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8400\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3567 - binary_accuracy: 0.8434\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8377\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3566 - binary_accuracy: 0.8411\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3542 - binary_accuracy: 0.8415\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3625 - binary_accuracy: 0.8301\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8389\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8408\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8366\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3605 - binary_accuracy: 0.8423\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3525 - binary_accuracy: 0.8465\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8415\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3579 - binary_accuracy: 0.8373\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3493 - binary_accuracy: 0.8526\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8484\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8491\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8472\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8408\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8488\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8469\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8503\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3455 - binary_accuracy: 0.8446\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8442\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8442\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3403 - binary_accuracy: 0.8469\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8469\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8457\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3342 - binary_accuracy: 0.8518\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8518\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8537\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8442\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3344 - binary_accuracy: 0.8522\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8465\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8450\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8514\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3280 - binary_accuracy: 0.8522\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3313 - binary_accuracy: 0.8545\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8503\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3249 - binary_accuracy: 0.8598\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3455 - binary_accuracy: 0.8450\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3361 - binary_accuracy: 0.8533\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3275 - binary_accuracy: 0.8583\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3315 - binary_accuracy: 0.8503\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3389 - binary_accuracy: 0.8530\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8549\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3234 - binary_accuracy: 0.8598\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3196 - binary_accuracy: 0.8571\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8461\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3252 - binary_accuracy: 0.8575\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3164 - binary_accuracy: 0.8583\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3282 - binary_accuracy: 0.8571\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3254 - binary_accuracy: 0.8549\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3290 - binary_accuracy: 0.8507\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3167 - binary_accuracy: 0.8606\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3240 - binary_accuracy: 0.8606\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3250 - binary_accuracy: 0.8549\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3160 - binary_accuracy: 0.8663\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3218 - binary_accuracy: 0.8556\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3286 - binary_accuracy: 0.8533\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3231 - binary_accuracy: 0.8575\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8598\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8541\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3180 - binary_accuracy: 0.8651\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3126 - binary_accuracy: 0.8636\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8533\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8602\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8644\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3150 - binary_accuracy: 0.8648\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3104 - binary_accuracy: 0.8621\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3156 - binary_accuracy: 0.8640\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3165 - binary_accuracy: 0.8659\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3158 - binary_accuracy: 0.8564\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3145 - binary_accuracy: 0.8594\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3127 - binary_accuracy: 0.8617\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3100 - binary_accuracy: 0.8674\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3106 - binary_accuracy: 0.8625\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3063 - binary_accuracy: 0.8686\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3038 - binary_accuracy: 0.8678\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3031 - binary_accuracy: 0.8613\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3052 - binary_accuracy: 0.8636\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3071 - binary_accuracy: 0.8678\n",
            "Epoch 132/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3161 - binary_accuracy: 0.8598\n",
            "Epoch 133/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3090 - binary_accuracy: 0.8583\n",
            "Epoch 134/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3096 - binary_accuracy: 0.8674\n",
            "Epoch 135/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3135 - binary_accuracy: 0.8625\n",
            "Epoch 136/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2976 - binary_accuracy: 0.8686\n",
            "Epoch 137/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3050 - binary_accuracy: 0.8651\n",
            "Epoch 138/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3031 - binary_accuracy: 0.8705\n",
            "Epoch 139/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3185 - binary_accuracy: 0.8564\n",
            "Epoch 140/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3060 - binary_accuracy: 0.8728\n",
            "Epoch 141/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3101 - binary_accuracy: 0.8659\n",
            "Epoch 142/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3092 - binary_accuracy: 0.8610\n",
            "Epoch 143/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2994 - binary_accuracy: 0.8705\n",
            "Epoch 144/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2968 - binary_accuracy: 0.8678\n",
            "Epoch 145/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3079 - binary_accuracy: 0.8629\n",
            "Epoch 146/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3016 - binary_accuracy: 0.8697\n",
            "Epoch 147/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2968 - binary_accuracy: 0.8731\n",
            "Epoch 148/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3146 - binary_accuracy: 0.8617\n",
            "Epoch 149/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3010 - binary_accuracy: 0.8651\n",
            "Epoch 150/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3097 - binary_accuracy: 0.8651\n",
            "Epoch 151/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2968 - binary_accuracy: 0.8697\n",
            "Epoch 152/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2965 - binary_accuracy: 0.8697\n",
            "Epoch 153/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3040 - binary_accuracy: 0.8686\n",
            "Epoch 154/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3005 - binary_accuracy: 0.8651\n",
            "Epoch 155/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2901 - binary_accuracy: 0.8743\n",
            "Epoch 156/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2987 - binary_accuracy: 0.8690\n",
            "Epoch 157/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2976 - binary_accuracy: 0.8690\n",
            "Epoch 158/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3010 - binary_accuracy: 0.8670\n",
            "Epoch 159/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2961 - binary_accuracy: 0.8697\n",
            "Epoch 160/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2934 - binary_accuracy: 0.8712\n",
            "For the fold number  2 :\n",
            "loss =  0.3501925468444824 \n",
            "accuracy =  81.86666369438171 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7113 - binary_accuracy: 0.6004\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5821 - binary_accuracy: 0.7150\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5361 - binary_accuracy: 0.7436\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5077 - binary_accuracy: 0.7634\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4933 - binary_accuracy: 0.7550\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4826 - binary_accuracy: 0.7726\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4732 - binary_accuracy: 0.7718\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.7821\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.7855\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4469 - binary_accuracy: 0.7756\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4427 - binary_accuracy: 0.7966\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.7924\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4320 - binary_accuracy: 0.7977\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4247 - binary_accuracy: 0.8046\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4267 - binary_accuracy: 0.7973\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4135 - binary_accuracy: 0.8065\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4126 - binary_accuracy: 0.8023\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4131 - binary_accuracy: 0.8103\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4040 - binary_accuracy: 0.8156\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4132 - binary_accuracy: 0.8011\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4020 - binary_accuracy: 0.8126\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3992 - binary_accuracy: 0.8210\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3978 - binary_accuracy: 0.8160\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3913 - binary_accuracy: 0.8210\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3916 - binary_accuracy: 0.8274\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3883 - binary_accuracy: 0.8225\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3926 - binary_accuracy: 0.8194\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3862 - binary_accuracy: 0.8190\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3789 - binary_accuracy: 0.8301\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3769 - binary_accuracy: 0.8259\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3774 - binary_accuracy: 0.8236\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8248\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8347\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8358\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3676 - binary_accuracy: 0.8358\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3692 - binary_accuracy: 0.8373\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3698 - binary_accuracy: 0.8335\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3673 - binary_accuracy: 0.8286\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8381\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3644 - binary_accuracy: 0.8350\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8312\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3589 - binary_accuracy: 0.8358\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3550 - binary_accuracy: 0.8408\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8415\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8434\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3520 - binary_accuracy: 0.8446\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8370\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8373\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8354\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8408\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8583\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8430\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8347\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8430\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8472\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8480\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8430\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8469\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8503\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3392 - binary_accuracy: 0.8514\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3342 - binary_accuracy: 0.8549\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8453\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8465\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8503\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8495\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3403 - binary_accuracy: 0.8453\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3335 - binary_accuracy: 0.8537\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3274 - binary_accuracy: 0.8491\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3312 - binary_accuracy: 0.8575\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8499\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3292 - binary_accuracy: 0.8587\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8469\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3278 - binary_accuracy: 0.8503\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3238 - binary_accuracy: 0.8545\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8579\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8545\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8522\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8518\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8552\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8541\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3340 - binary_accuracy: 0.8495\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3332 - binary_accuracy: 0.8507\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3288 - binary_accuracy: 0.8602\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3168 - binary_accuracy: 0.8571\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3223 - binary_accuracy: 0.8571\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3269 - binary_accuracy: 0.8495\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3254 - binary_accuracy: 0.8541\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3183 - binary_accuracy: 0.8552\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3169 - binary_accuracy: 0.8629\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3250 - binary_accuracy: 0.8530\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3243 - binary_accuracy: 0.8533\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3120 - binary_accuracy: 0.8724\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_accuracy: 0.8491\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3150 - binary_accuracy: 0.8587\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8594\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3129 - binary_accuracy: 0.8625\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3213 - binary_accuracy: 0.8571\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.8575\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3136 - binary_accuracy: 0.8629\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3108 - binary_accuracy: 0.8636\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3170 - binary_accuracy: 0.8617\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3142 - binary_accuracy: 0.8598\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3200 - binary_accuracy: 0.8568\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3105 - binary_accuracy: 0.8621\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3169 - binary_accuracy: 0.8598\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3174 - binary_accuracy: 0.8636\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3083 - binary_accuracy: 0.8598\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3138 - binary_accuracy: 0.8636\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3122 - binary_accuracy: 0.8606\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3157 - binary_accuracy: 0.8560\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3057 - binary_accuracy: 0.8648\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3193 - binary_accuracy: 0.8602\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3094 - binary_accuracy: 0.8636\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3064 - binary_accuracy: 0.8682\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3128 - binary_accuracy: 0.8674\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3019 - binary_accuracy: 0.8709\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3116 - binary_accuracy: 0.8598\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3082 - binary_accuracy: 0.8674\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3104 - binary_accuracy: 0.8606\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3102 - binary_accuracy: 0.8651\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3067 - binary_accuracy: 0.8602\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3131 - binary_accuracy: 0.8583\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3027 - binary_accuracy: 0.8678\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3012 - binary_accuracy: 0.8636\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3024 - binary_accuracy: 0.8701\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3072 - binary_accuracy: 0.8632\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3036 - binary_accuracy: 0.8670\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3080 - binary_accuracy: 0.8613\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3066 - binary_accuracy: 0.8644\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3095 - binary_accuracy: 0.8636\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3011 - binary_accuracy: 0.8636\n",
            "Epoch 132/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2986 - binary_accuracy: 0.8743\n",
            "Epoch 133/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2991 - binary_accuracy: 0.8712\n",
            "Epoch 134/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3063 - binary_accuracy: 0.8682\n",
            "Epoch 135/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3104 - binary_accuracy: 0.8606\n",
            "Epoch 136/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3012 - binary_accuracy: 0.8655\n",
            "Epoch 137/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2990 - binary_accuracy: 0.8693\n",
            "Epoch 138/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2978 - binary_accuracy: 0.8705\n",
            "Epoch 139/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3050 - binary_accuracy: 0.8651\n",
            "Epoch 140/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2971 - binary_accuracy: 0.8705\n",
            "Epoch 141/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3025 - binary_accuracy: 0.8670\n",
            "Epoch 142/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3098 - binary_accuracy: 0.8613\n",
            "Epoch 143/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3038 - binary_accuracy: 0.8655\n",
            "Epoch 144/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2995 - binary_accuracy: 0.8636\n",
            "Epoch 145/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2966 - binary_accuracy: 0.8667\n",
            "Epoch 146/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.2989 - binary_accuracy: 0.8663\n",
            "Epoch 147/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3043 - binary_accuracy: 0.8632\n",
            "Epoch 148/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2991 - binary_accuracy: 0.8648\n",
            "Epoch 149/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3017 - binary_accuracy: 0.8674\n",
            "Epoch 150/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2990 - binary_accuracy: 0.8686\n",
            "Epoch 151/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2931 - binary_accuracy: 0.8743\n",
            "Epoch 152/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2996 - binary_accuracy: 0.8709\n",
            "Epoch 153/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2950 - binary_accuracy: 0.8682\n",
            "Epoch 154/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2986 - binary_accuracy: 0.8636\n",
            "Epoch 155/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2980 - binary_accuracy: 0.8728\n",
            "Epoch 156/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2944 - binary_accuracy: 0.8735\n",
            "Epoch 157/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.2940 - binary_accuracy: 0.8731\n",
            "Epoch 158/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3001 - binary_accuracy: 0.8617\n",
            "Epoch 159/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2962 - binary_accuracy: 0.8686\n",
            "Epoch 160/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3016 - binary_accuracy: 0.8667\n",
            "For the fold number  3 :\n",
            "loss =  0.35758161544799805 \n",
            "accuracy =  83.20000171661377 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.6583 - binary_accuracy: 0.6354\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5704 - binary_accuracy: 0.7040\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5251 - binary_accuracy: 0.7371\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5128 - binary_accuracy: 0.7470\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4923 - binary_accuracy: 0.7653\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4746 - binary_accuracy: 0.7684\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4717 - binary_accuracy: 0.7764\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4630 - binary_accuracy: 0.7756\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4541 - binary_accuracy: 0.7787\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.7836\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4434 - binary_accuracy: 0.7851\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4471 - binary_accuracy: 0.7886\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4376 - binary_accuracy: 0.7928\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4325 - binary_accuracy: 0.8034\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4262 - binary_accuracy: 0.8027\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4235 - binary_accuracy: 0.7985\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4246 - binary_accuracy: 0.7992\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4151 - binary_accuracy: 0.7977\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.7996\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8023\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4103 - binary_accuracy: 0.7992\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4077 - binary_accuracy: 0.8103\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4048 - binary_accuracy: 0.8072\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8069\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4014 - binary_accuracy: 0.8130\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3904 - binary_accuracy: 0.8206\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3939 - binary_accuracy: 0.8267\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3866 - binary_accuracy: 0.8198\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3871 - binary_accuracy: 0.8202\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3896 - binary_accuracy: 0.8225\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3886 - binary_accuracy: 0.8198\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8232\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3856 - binary_accuracy: 0.8312\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8190\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3747 - binary_accuracy: 0.8290\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3724 - binary_accuracy: 0.8350\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3698 - binary_accuracy: 0.8274\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3665 - binary_accuracy: 0.8301\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3706 - binary_accuracy: 0.8301\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3722 - binary_accuracy: 0.8267\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8236\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3748 - binary_accuracy: 0.8301\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3639 - binary_accuracy: 0.8335\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3724 - binary_accuracy: 0.8316\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8381\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8343\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8301\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_accuracy: 0.8377\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3662 - binary_accuracy: 0.8320\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3625 - binary_accuracy: 0.8347\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8350\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8381\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3618 - binary_accuracy: 0.8328\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3536 - binary_accuracy: 0.8373\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3544 - binary_accuracy: 0.8419\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8309\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3567 - binary_accuracy: 0.8442\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8385\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3550 - binary_accuracy: 0.8381\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3468 - binary_accuracy: 0.8434\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8385\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8339\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8472\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3518 - binary_accuracy: 0.8415\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8465\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3560 - binary_accuracy: 0.8438\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8526\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8419\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8343\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3416 - binary_accuracy: 0.8491\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3498 - binary_accuracy: 0.8461\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8465\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8453\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8507\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8514\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.8491\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8457\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3335 - binary_accuracy: 0.8526\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8514\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8411\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3273 - binary_accuracy: 0.8583\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8537\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8602\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3410 - binary_accuracy: 0.8450\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8453\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3299 - binary_accuracy: 0.8575\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3274 - binary_accuracy: 0.8590\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3292 - binary_accuracy: 0.8568\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3228 - binary_accuracy: 0.8533\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8629\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8465\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3336 - binary_accuracy: 0.8488\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8598\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3291 - binary_accuracy: 0.8533\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3303 - binary_accuracy: 0.8450\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3305 - binary_accuracy: 0.8518\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8583\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8583\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3249 - binary_accuracy: 0.8526\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3243 - binary_accuracy: 0.8575\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3254 - binary_accuracy: 0.8545\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3223 - binary_accuracy: 0.8629\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3211 - binary_accuracy: 0.8541\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3124 - binary_accuracy: 0.8621\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3240 - binary_accuracy: 0.8530\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8556\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3211 - binary_accuracy: 0.8518\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8598\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8610\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3221 - binary_accuracy: 0.8640\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3161 - binary_accuracy: 0.8590\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3207 - binary_accuracy: 0.8556\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3110 - binary_accuracy: 0.8644\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3112 - binary_accuracy: 0.8617\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8560\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3215 - binary_accuracy: 0.8621\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8629\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3171 - binary_accuracy: 0.8587\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3110 - binary_accuracy: 0.8610\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3157 - binary_accuracy: 0.8575\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3030 - binary_accuracy: 0.8682\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8503\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3201 - binary_accuracy: 0.8522\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3109 - binary_accuracy: 0.8613\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3126 - binary_accuracy: 0.8571\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3060 - binary_accuracy: 0.8648\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3076 - binary_accuracy: 0.8617\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3125 - binary_accuracy: 0.8659\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3146 - binary_accuracy: 0.8613\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3132 - binary_accuracy: 0.8651\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3002 - binary_accuracy: 0.8693\n",
            "Epoch 132/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3032 - binary_accuracy: 0.8632\n",
            "Epoch 133/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3137 - binary_accuracy: 0.8560\n",
            "Epoch 134/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3022 - binary_accuracy: 0.8644\n",
            "Epoch 135/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3097 - binary_accuracy: 0.8667\n",
            "Epoch 136/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.2967 - binary_accuracy: 0.8655\n",
            "Epoch 137/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3048 - binary_accuracy: 0.8655\n",
            "Epoch 138/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3085 - binary_accuracy: 0.8610\n",
            "Epoch 139/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3176 - binary_accuracy: 0.8651\n",
            "Epoch 140/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3107 - binary_accuracy: 0.8648\n",
            "Epoch 141/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3045 - binary_accuracy: 0.8659\n",
            "Epoch 142/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3048 - binary_accuracy: 0.8701\n",
            "Epoch 143/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3070 - binary_accuracy: 0.8632\n",
            "Epoch 144/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3077 - binary_accuracy: 0.8625\n",
            "Epoch 145/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3071 - binary_accuracy: 0.8648\n",
            "Epoch 146/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3038 - binary_accuracy: 0.8663\n",
            "For the fold number  4 :\n",
            "loss =  0.3587993085384369 \n",
            "accuracy =  84.79999899864197 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 2s 3ms/step - loss: 0.7066 - binary_accuracy: 0.5958\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5848 - binary_accuracy: 0.7017\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5409 - binary_accuracy: 0.7360\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5218 - binary_accuracy: 0.7371\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4978 - binary_accuracy: 0.7604\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4803 - binary_accuracy: 0.7589\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4732 - binary_accuracy: 0.7672\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4673 - binary_accuracy: 0.7627\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4608 - binary_accuracy: 0.7798\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4476 - binary_accuracy: 0.7829\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4454 - binary_accuracy: 0.7893\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4405 - binary_accuracy: 0.7874\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4261 - binary_accuracy: 0.8015\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7977\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4179 - binary_accuracy: 0.8038\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8038\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4084 - binary_accuracy: 0.8175\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4105 - binary_accuracy: 0.8137\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4017 - binary_accuracy: 0.8240\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3989 - binary_accuracy: 0.8225\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4071 - binary_accuracy: 0.8118\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8126\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3922 - binary_accuracy: 0.8244\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3872 - binary_accuracy: 0.8244\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3840 - binary_accuracy: 0.8255\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3869 - binary_accuracy: 0.8320\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3879 - binary_accuracy: 0.8286\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3816 - binary_accuracy: 0.8244\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3793 - binary_accuracy: 0.8263\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3792 - binary_accuracy: 0.8305\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3856 - binary_accuracy: 0.8221\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3680 - binary_accuracy: 0.8305\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3695 - binary_accuracy: 0.8286\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3753 - binary_accuracy: 0.8232\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3792 - binary_accuracy: 0.8312\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8255\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8324\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8362\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3617 - binary_accuracy: 0.8389\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.8385\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8430\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8377\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8339\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3625 - binary_accuracy: 0.8366\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8305\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3522 - binary_accuracy: 0.8408\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3476 - binary_accuracy: 0.8385\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8290\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8396\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3535 - binary_accuracy: 0.8415\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8495\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8427\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8350\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3394 - binary_accuracy: 0.8430\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8404\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8427\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8446\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8389\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3445 - binary_accuracy: 0.8438\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3379 - binary_accuracy: 0.8450\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8438\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8461\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3401 - binary_accuracy: 0.8423\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3339 - binary_accuracy: 0.8549\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3418 - binary_accuracy: 0.8495\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3344 - binary_accuracy: 0.8491\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8507\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8434\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3350 - binary_accuracy: 0.8507\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8503\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8453\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8533\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3381 - binary_accuracy: 0.8617\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3302 - binary_accuracy: 0.8518\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3280 - binary_accuracy: 0.8522\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8530\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3274 - binary_accuracy: 0.8541\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3342 - binary_accuracy: 0.8499\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3263 - binary_accuracy: 0.8522\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8560\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8514\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8503\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3308 - binary_accuracy: 0.8510\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3300 - binary_accuracy: 0.8533\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_accuracy: 0.8594\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3292 - binary_accuracy: 0.8560\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3210 - binary_accuracy: 0.8549\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.8530\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3288 - binary_accuracy: 0.8579\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8537\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8568\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3251 - binary_accuracy: 0.8640\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3281 - binary_accuracy: 0.8484\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3159 - binary_accuracy: 0.8602\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8583\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3244 - binary_accuracy: 0.8488\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8533\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3139 - binary_accuracy: 0.8629\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3186 - binary_accuracy: 0.8579\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3178 - binary_accuracy: 0.8629\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3184 - binary_accuracy: 0.8549\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3288 - binary_accuracy: 0.8560\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3149 - binary_accuracy: 0.8598\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3165 - binary_accuracy: 0.8575\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3145 - binary_accuracy: 0.8594\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3190 - binary_accuracy: 0.8552\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3183 - binary_accuracy: 0.8564\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3114 - binary_accuracy: 0.8613\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3138 - binary_accuracy: 0.8571\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3071 - binary_accuracy: 0.8693\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3201 - binary_accuracy: 0.8613\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3067 - binary_accuracy: 0.8651\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3163 - binary_accuracy: 0.8617\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3059 - binary_accuracy: 0.8655\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3143 - binary_accuracy: 0.8667\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3135 - binary_accuracy: 0.8590\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3067 - binary_accuracy: 0.8575\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3091 - binary_accuracy: 0.8659\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3051 - binary_accuracy: 0.8670\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3086 - binary_accuracy: 0.8644\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3099 - binary_accuracy: 0.8610\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3011 - binary_accuracy: 0.8632\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3014 - binary_accuracy: 0.8606\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3096 - binary_accuracy: 0.8648\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3025 - binary_accuracy: 0.8629\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3022 - binary_accuracy: 0.8697\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3046 - binary_accuracy: 0.8659\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3065 - binary_accuracy: 0.8670\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3138 - binary_accuracy: 0.8594\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3051 - binary_accuracy: 0.8640\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2957 - binary_accuracy: 0.8663\n",
            "Epoch 132/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3005 - binary_accuracy: 0.8625\n",
            "Epoch 133/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3132 - binary_accuracy: 0.8625\n",
            "Epoch 134/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2998 - binary_accuracy: 0.8693\n",
            "Epoch 135/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3070 - binary_accuracy: 0.8644\n",
            "Epoch 136/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3068 - binary_accuracy: 0.8644\n",
            "Epoch 137/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3022 - binary_accuracy: 0.8682\n",
            "Epoch 138/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3096 - binary_accuracy: 0.8594\n",
            "Epoch 139/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3029 - binary_accuracy: 0.8629\n",
            "Epoch 140/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3007 - binary_accuracy: 0.8690\n",
            "Epoch 141/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2989 - binary_accuracy: 0.8697\n",
            "For the fold number  5 :\n",
            "loss =  0.37477248907089233 \n",
            "accuracy =  84.26666855812073 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.6707 - binary_accuracy: 0.6225\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5631 - binary_accuracy: 0.7067\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5277 - binary_accuracy: 0.7288\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5042 - binary_accuracy: 0.7470\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4960 - binary_accuracy: 0.7547\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.7577\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.7752\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4536 - binary_accuracy: 0.7806\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4494 - binary_accuracy: 0.7867\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4367 - binary_accuracy: 0.7989\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4321 - binary_accuracy: 0.7859\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4291 - binary_accuracy: 0.7916\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4252 - binary_accuracy: 0.8023\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.7943\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4166 - binary_accuracy: 0.8034\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4085 - binary_accuracy: 0.8076\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4097 - binary_accuracy: 0.8027\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3973 - binary_accuracy: 0.8194\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4037 - binary_accuracy: 0.8122\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4008 - binary_accuracy: 0.8164\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3946 - binary_accuracy: 0.8175\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3985 - binary_accuracy: 0.8149\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3953 - binary_accuracy: 0.8240\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3918 - binary_accuracy: 0.8145\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3860 - binary_accuracy: 0.8217\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3831 - binary_accuracy: 0.8145\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3875 - binary_accuracy: 0.8240\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3796 - binary_accuracy: 0.8183\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3818 - binary_accuracy: 0.8255\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3767 - binary_accuracy: 0.8282\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3698 - binary_accuracy: 0.8240\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3718 - binary_accuracy: 0.8290\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3726 - binary_accuracy: 0.8316\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3654 - binary_accuracy: 0.8309\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3725 - binary_accuracy: 0.8324\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3685 - binary_accuracy: 0.8301\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3659 - binary_accuracy: 0.8392\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3724 - binary_accuracy: 0.8282\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3664 - binary_accuracy: 0.8309\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8381\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8331\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8423\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8366\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3627 - binary_accuracy: 0.8347\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3537 - binary_accuracy: 0.8404\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3557 - binary_accuracy: 0.8392\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8446\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8385\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3565 - binary_accuracy: 0.8396\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8442\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8430\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8381\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8465\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8385\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3526 - binary_accuracy: 0.8423\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8427\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8408\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3528 - binary_accuracy: 0.8400\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3490 - binary_accuracy: 0.8450\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8404\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3399 - binary_accuracy: 0.8404\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3387 - binary_accuracy: 0.8537\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3479 - binary_accuracy: 0.8423\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3379 - binary_accuracy: 0.8514\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8499\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8430\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3462 - binary_accuracy: 0.8465\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3444 - binary_accuracy: 0.8476\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3443 - binary_accuracy: 0.8411\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3430 - binary_accuracy: 0.8499\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3434 - binary_accuracy: 0.8469\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3371 - binary_accuracy: 0.8461\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3331 - binary_accuracy: 0.8514\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3340 - binary_accuracy: 0.8526\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8510\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8526\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3316 - binary_accuracy: 0.8450\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8510\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3329 - binary_accuracy: 0.8533\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3300 - binary_accuracy: 0.8507\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3318 - binary_accuracy: 0.8564\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8491\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8491\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8537\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3252 - binary_accuracy: 0.8560\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3317 - binary_accuracy: 0.8514\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3256 - binary_accuracy: 0.8579\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8564\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3252 - binary_accuracy: 0.8488\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3317 - binary_accuracy: 0.8488\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3282 - binary_accuracy: 0.8549\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3287 - binary_accuracy: 0.8541\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3236 - binary_accuracy: 0.8590\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3251 - binary_accuracy: 0.8552\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3289 - binary_accuracy: 0.8533\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8503\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3200 - binary_accuracy: 0.8568\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3181 - binary_accuracy: 0.8594\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8564\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3156 - binary_accuracy: 0.8606\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3131 - binary_accuracy: 0.8579\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3203 - binary_accuracy: 0.8590\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8629\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8571\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3145 - binary_accuracy: 0.8602\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3205 - binary_accuracy: 0.8579\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8602\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3115 - binary_accuracy: 0.8636\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3146 - binary_accuracy: 0.8575\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3204 - binary_accuracy: 0.8583\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3129 - binary_accuracy: 0.8564\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3191 - binary_accuracy: 0.8571\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8552\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3017 - binary_accuracy: 0.8636\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3204 - binary_accuracy: 0.8587\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3208 - binary_accuracy: 0.8571\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3039 - binary_accuracy: 0.8697\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3128 - binary_accuracy: 0.8682\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3132 - binary_accuracy: 0.8636\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3239 - binary_accuracy: 0.8625\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3072 - binary_accuracy: 0.8640\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3042 - binary_accuracy: 0.8625\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3076 - binary_accuracy: 0.8651\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3186 - binary_accuracy: 0.8594\n",
            "For the fold number  6 :\n",
            "loss =  0.35006654262542725 \n",
            "accuracy =  83.73333215713501 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.7554 - binary_accuracy: 0.5505\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.6250 - binary_accuracy: 0.6659\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5683 - binary_accuracy: 0.7154\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5211 - binary_accuracy: 0.7470\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5103 - binary_accuracy: 0.7470\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4896 - binary_accuracy: 0.7630\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4811 - binary_accuracy: 0.7592\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4728 - binary_accuracy: 0.7703\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.7722\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.7874\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4587 - binary_accuracy: 0.7787\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4403 - binary_accuracy: 0.7863\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4380 - binary_accuracy: 0.7924\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4296 - binary_accuracy: 0.7992\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4274 - binary_accuracy: 0.7939\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4182 - binary_accuracy: 0.7970\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4172 - binary_accuracy: 0.7992\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4208 - binary_accuracy: 0.8091\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.8088\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8156\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8160\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4153 - binary_accuracy: 0.8084\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4046 - binary_accuracy: 0.8042\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4059 - binary_accuracy: 0.8095\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4017 - binary_accuracy: 0.8053\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3971 - binary_accuracy: 0.8160\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3973 - binary_accuracy: 0.8133\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3907 - binary_accuracy: 0.8251\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3977 - binary_accuracy: 0.8137\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4011 - binary_accuracy: 0.8171\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8194\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3851 - binary_accuracy: 0.8248\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3874 - binary_accuracy: 0.8206\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8221\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8316\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8312\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3860 - binary_accuracy: 0.8305\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3774 - binary_accuracy: 0.8251\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3776 - binary_accuracy: 0.8290\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3798 - binary_accuracy: 0.8259\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3797 - binary_accuracy: 0.8213\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3798 - binary_accuracy: 0.8297\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3750 - binary_accuracy: 0.8293\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3731 - binary_accuracy: 0.8225\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3711 - binary_accuracy: 0.8328\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8248\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8423\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3687 - binary_accuracy: 0.8320\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8389\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8328\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8392\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8297\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3694 - binary_accuracy: 0.8354\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8419\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3574 - binary_accuracy: 0.8400\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3639 - binary_accuracy: 0.8381\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8472\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3546 - binary_accuracy: 0.8385\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8450\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8328\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3604 - binary_accuracy: 0.8366\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8465\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3433 - binary_accuracy: 0.8423\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3424 - binary_accuracy: 0.8469\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3591 - binary_accuracy: 0.8358\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8587\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8381\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8419\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8457\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8480\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_accuracy: 0.8389\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8400\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8495\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8507\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8545\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3421 - binary_accuracy: 0.8533\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3370 - binary_accuracy: 0.8495\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8457\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3351 - binary_accuracy: 0.8541\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3410 - binary_accuracy: 0.8453\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8636\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8476\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3314 - binary_accuracy: 0.8510\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3366 - binary_accuracy: 0.8514\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3360 - binary_accuracy: 0.8461\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8510\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3308 - binary_accuracy: 0.8537\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3309 - binary_accuracy: 0.8571\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8526\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8480\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8541\n",
            "For the fold number  7 :\n",
            "loss =  0.2894226312637329 \n",
            "accuracy =  87.99999952316284 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.9183 - binary_accuracy: 0.4206\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6429 - binary_accuracy: 0.6236\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5623 - binary_accuracy: 0.7185\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5295 - binary_accuracy: 0.7425\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5176 - binary_accuracy: 0.7531\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4956 - binary_accuracy: 0.7608\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4855 - binary_accuracy: 0.7650\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4672 - binary_accuracy: 0.7813\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4655 - binary_accuracy: 0.7768\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4529 - binary_accuracy: 0.7985\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4586 - binary_accuracy: 0.7851\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4517 - binary_accuracy: 0.7897\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4380 - binary_accuracy: 0.7958\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4397 - binary_accuracy: 0.7928\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4357 - binary_accuracy: 0.8008\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4257 - binary_accuracy: 0.8072\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4265 - binary_accuracy: 0.8011\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4250 - binary_accuracy: 0.7950\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4148 - binary_accuracy: 0.8130\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4137 - binary_accuracy: 0.8069\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4146 - binary_accuracy: 0.8095\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8061\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8088\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4094 - binary_accuracy: 0.8084\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4059 - binary_accuracy: 0.8206\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8099\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4043 - binary_accuracy: 0.8149\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.8130\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4011 - binary_accuracy: 0.8107\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8069\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4021 - binary_accuracy: 0.8141\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3959 - binary_accuracy: 0.8149\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3814 - binary_accuracy: 0.8278\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3899 - binary_accuracy: 0.8149\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3791 - binary_accuracy: 0.8229\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3885 - binary_accuracy: 0.8213\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3799 - binary_accuracy: 0.8293\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3800 - binary_accuracy: 0.8225\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3838 - binary_accuracy: 0.8187\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3775 - binary_accuracy: 0.8385\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8194\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3771 - binary_accuracy: 0.8244\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3715 - binary_accuracy: 0.8282\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3751 - binary_accuracy: 0.8255\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3795 - binary_accuracy: 0.8236\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8270\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8309\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3624 - binary_accuracy: 0.8385\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3758 - binary_accuracy: 0.8282\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3686 - binary_accuracy: 0.8370\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3753 - binary_accuracy: 0.8255\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3590 - binary_accuracy: 0.8339\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3628 - binary_accuracy: 0.8335\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3662 - binary_accuracy: 0.8320\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3649 - binary_accuracy: 0.8339\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3666 - binary_accuracy: 0.8274\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3616 - binary_accuracy: 0.8350\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8339\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8373\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3682 - binary_accuracy: 0.8259\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3628 - binary_accuracy: 0.8354\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8370\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3690 - binary_accuracy: 0.8328\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8370\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3486 - binary_accuracy: 0.8423\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8381\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3539 - binary_accuracy: 0.8392\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_accuracy: 0.8316\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3596 - binary_accuracy: 0.8320\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3594 - binary_accuracy: 0.8328\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3464 - binary_accuracy: 0.8423\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3396 - binary_accuracy: 0.8472\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3587 - binary_accuracy: 0.8396\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8404\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3479 - binary_accuracy: 0.8415\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3451 - binary_accuracy: 0.8419\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3469 - binary_accuracy: 0.8373\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3526 - binary_accuracy: 0.8404\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3400 - binary_accuracy: 0.8457\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3555 - binary_accuracy: 0.8347\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8385\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3471 - binary_accuracy: 0.8408\n",
            "For the fold number  8 :\n",
            "loss =  0.37611737847328186 \n",
            "accuracy =  83.99999737739563 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  4\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.7636 - binary_accuracy: 0.5528\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5919 - binary_accuracy: 0.6933\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5491 - binary_accuracy: 0.7238\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5120 - binary_accuracy: 0.7581\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4949 - binary_accuracy: 0.7577\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4698 - binary_accuracy: 0.7745\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4660 - binary_accuracy: 0.7733\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4611 - binary_accuracy: 0.7817\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4452 - binary_accuracy: 0.7916\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4467 - binary_accuracy: 0.7928\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4365 - binary_accuracy: 0.7973\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4280 - binary_accuracy: 0.7985\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4324 - binary_accuracy: 0.7920\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4231 - binary_accuracy: 0.8061\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4243 - binary_accuracy: 0.7973\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4080 - binary_accuracy: 0.8133\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4174 - binary_accuracy: 0.8069\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_accuracy: 0.8141\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4162 - binary_accuracy: 0.8015\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3981 - binary_accuracy: 0.8160\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4030 - binary_accuracy: 0.8107\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3958 - binary_accuracy: 0.8152\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3919 - binary_accuracy: 0.8225\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8229\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3908 - binary_accuracy: 0.8221\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3873 - binary_accuracy: 0.8202\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3783 - binary_accuracy: 0.8206\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8232\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3730 - binary_accuracy: 0.8350\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3727 - binary_accuracy: 0.8290\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3783 - binary_accuracy: 0.8251\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3711 - binary_accuracy: 0.8282\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3669 - binary_accuracy: 0.8324\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3676 - binary_accuracy: 0.8373\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3685 - binary_accuracy: 0.8335\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8324\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3655 - binary_accuracy: 0.8389\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8278\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3617 - binary_accuracy: 0.8339\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8392\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8392\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3571 - binary_accuracy: 0.8450\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3607 - binary_accuracy: 0.8335\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8465\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3472 - binary_accuracy: 0.8450\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3460 - binary_accuracy: 0.8480\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8446\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3559 - binary_accuracy: 0.8373\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8427\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3391 - binary_accuracy: 0.8488\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8415\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3467 - binary_accuracy: 0.8484\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3494 - binary_accuracy: 0.8427\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8450\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3538 - binary_accuracy: 0.8400\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3430 - binary_accuracy: 0.8469\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8446\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8476\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8491\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8465\n",
            "For the fold number  1 :\n",
            "loss =  0.3973240554332733 \n",
            "accuracy =  80.0000011920929 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7223 - binary_accuracy: 0.6183\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6051 - binary_accuracy: 0.6994\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5581 - binary_accuracy: 0.7276\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5163 - binary_accuracy: 0.7528\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5026 - binary_accuracy: 0.7570\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4811 - binary_accuracy: 0.7653\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.7810\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4542 - binary_accuracy: 0.7954\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4462 - binary_accuracy: 0.7870\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4397 - binary_accuracy: 0.7981\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4304 - binary_accuracy: 0.7970\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4285 - binary_accuracy: 0.7950\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4230 - binary_accuracy: 0.8042\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4265 - binary_accuracy: 0.8057\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.8091\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4021 - binary_accuracy: 0.8156\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4042 - binary_accuracy: 0.8164\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4088 - binary_accuracy: 0.8099\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4040 - binary_accuracy: 0.8126\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3990 - binary_accuracy: 0.8164\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3964 - binary_accuracy: 0.8145\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3894 - binary_accuracy: 0.8187\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3827 - binary_accuracy: 0.8225\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3905 - binary_accuracy: 0.8259\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3929 - binary_accuracy: 0.8251\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3841 - binary_accuracy: 0.8312\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3818 - binary_accuracy: 0.8282\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3873 - binary_accuracy: 0.8251\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3797 - binary_accuracy: 0.8301\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3767 - binary_accuracy: 0.8282\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3740 - binary_accuracy: 0.8309\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3774 - binary_accuracy: 0.8251\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3720 - binary_accuracy: 0.8343\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8343\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8320\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3670 - binary_accuracy: 0.8362\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8316\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3562 - binary_accuracy: 0.8404\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3659 - binary_accuracy: 0.8328\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8290\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8343\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8370\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3627 - binary_accuracy: 0.8354\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3620 - binary_accuracy: 0.8411\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3524 - binary_accuracy: 0.8400\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8438\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8389\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3565 - binary_accuracy: 0.8362\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8461\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8411\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3437 - binary_accuracy: 0.8438\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3521 - binary_accuracy: 0.8408\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3494 - binary_accuracy: 0.8480\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8419\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8381\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3391 - binary_accuracy: 0.8518\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8495\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3399 - binary_accuracy: 0.8484\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8423\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3541 - binary_accuracy: 0.8377\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8423\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8461\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8526\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3432 - binary_accuracy: 0.8450\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3398 - binary_accuracy: 0.8446\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3420 - binary_accuracy: 0.8423\n",
            "For the fold number  2 :\n",
            "loss =  0.37305891513824463 \n",
            "accuracy =  82.40000009536743 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7305 - binary_accuracy: 0.5657\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6119 - binary_accuracy: 0.6716\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5741 - binary_accuracy: 0.7002\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5331 - binary_accuracy: 0.7341\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5136 - binary_accuracy: 0.7524\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5006 - binary_accuracy: 0.7615\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4845 - binary_accuracy: 0.7730\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4646 - binary_accuracy: 0.7813\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4620 - binary_accuracy: 0.7775\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4549 - binary_accuracy: 0.7901\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4493 - binary_accuracy: 0.7890\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4409 - binary_accuracy: 0.7909\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4392 - binary_accuracy: 0.7943\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4348 - binary_accuracy: 0.8004\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4255 - binary_accuracy: 0.8053\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4257 - binary_accuracy: 0.8030\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4232 - binary_accuracy: 0.8015\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4136 - binary_accuracy: 0.8038\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4182 - binary_accuracy: 0.8069\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4095 - binary_accuracy: 0.8072\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4080 - binary_accuracy: 0.8114\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4053 - binary_accuracy: 0.8065\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4023 - binary_accuracy: 0.8187\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3958 - binary_accuracy: 0.8110\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3981 - binary_accuracy: 0.8114\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3893 - binary_accuracy: 0.8244\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3952 - binary_accuracy: 0.8168\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3880 - binary_accuracy: 0.8221\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3926 - binary_accuracy: 0.8107\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3778 - binary_accuracy: 0.8297\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8213\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3817 - binary_accuracy: 0.8278\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3772 - binary_accuracy: 0.8297\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8305\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8267\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3784 - binary_accuracy: 0.8286\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8293\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8347\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3712 - binary_accuracy: 0.8312\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8350\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3699 - binary_accuracy: 0.8290\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8328\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3705 - binary_accuracy: 0.8274\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3611 - binary_accuracy: 0.8343\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8324\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3634 - binary_accuracy: 0.8282\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3582 - binary_accuracy: 0.8389\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_accuracy: 0.8366\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3539 - binary_accuracy: 0.8446\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8396\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8347\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3601 - binary_accuracy: 0.8328\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8408\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3611 - binary_accuracy: 0.8347\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8488\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8495\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8347\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3482 - binary_accuracy: 0.8411\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3502 - binary_accuracy: 0.8377\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8434\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3440 - binary_accuracy: 0.8434\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8331\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8396\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3362 - binary_accuracy: 0.8488\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8427\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3455 - binary_accuracy: 0.8434\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3391 - binary_accuracy: 0.8457\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3411 - binary_accuracy: 0.8385\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3380 - binary_accuracy: 0.8465\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3370 - binary_accuracy: 0.8461\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3357 - binary_accuracy: 0.8491\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3380 - binary_accuracy: 0.8472\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3387 - binary_accuracy: 0.8396\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3339 - binary_accuracy: 0.8541\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8457\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3289 - binary_accuracy: 0.8545\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3298 - binary_accuracy: 0.8438\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8423\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8430\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8480\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3259 - binary_accuracy: 0.8575\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3306 - binary_accuracy: 0.8533\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3378 - binary_accuracy: 0.8465\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3444 - binary_accuracy: 0.8423\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3312 - binary_accuracy: 0.8457\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3272 - binary_accuracy: 0.8518\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3322 - binary_accuracy: 0.8499\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3346 - binary_accuracy: 0.8457\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3302 - binary_accuracy: 0.8533\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3286 - binary_accuracy: 0.8488\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3316 - binary_accuracy: 0.8446\n",
            "For the fold number  3 :\n",
            "loss =  0.37931448221206665 \n",
            "accuracy =  83.73333215713501 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.7632 - binary_accuracy: 0.5745\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.6212 - binary_accuracy: 0.6785\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.5648 - binary_accuracy: 0.7154\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5296 - binary_accuracy: 0.7345\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.5112 - binary_accuracy: 0.7543\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.4935 - binary_accuracy: 0.7531\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4720 - binary_accuracy: 0.7710\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4757 - binary_accuracy: 0.7749\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4524 - binary_accuracy: 0.7783\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4552 - binary_accuracy: 0.7802\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4517 - binary_accuracy: 0.7859\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4464 - binary_accuracy: 0.7844\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4408 - binary_accuracy: 0.7859\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4313 - binary_accuracy: 0.7882\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8019\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.8000\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4219 - binary_accuracy: 0.7939\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4139 - binary_accuracy: 0.8000\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4102 - binary_accuracy: 0.8053\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4018 - binary_accuracy: 0.8107\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4086 - binary_accuracy: 0.8046\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4116 - binary_accuracy: 0.8042\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3973 - binary_accuracy: 0.8171\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3984 - binary_accuracy: 0.8080\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3980 - binary_accuracy: 0.8137\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3962 - binary_accuracy: 0.8168\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8103\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3832 - binary_accuracy: 0.8297\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3902 - binary_accuracy: 0.8236\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3877 - binary_accuracy: 0.8270\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3870 - binary_accuracy: 0.8141\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3764 - binary_accuracy: 0.8305\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8324\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3854 - binary_accuracy: 0.8175\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3760 - binary_accuracy: 0.8297\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3731 - binary_accuracy: 0.8373\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3748 - binary_accuracy: 0.8312\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3803 - binary_accuracy: 0.8244\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3687 - binary_accuracy: 0.8290\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3730 - binary_accuracy: 0.8335\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3723 - binary_accuracy: 0.8229\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3742 - binary_accuracy: 0.8244\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3677 - binary_accuracy: 0.8301\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_accuracy: 0.8392\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8377\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3586 - binary_accuracy: 0.8392\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8430\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_accuracy: 0.8354\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3591 - binary_accuracy: 0.8396\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8400\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3643 - binary_accuracy: 0.8389\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3610 - binary_accuracy: 0.8320\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3574 - binary_accuracy: 0.8362\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8472\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8377\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3585 - binary_accuracy: 0.8408\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3450 - binary_accuracy: 0.8491\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3506 - binary_accuracy: 0.8400\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8415\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8453\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3599 - binary_accuracy: 0.8354\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3547 - binary_accuracy: 0.8423\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3463 - binary_accuracy: 0.8453\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3449 - binary_accuracy: 0.8510\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8480\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3390 - binary_accuracy: 0.8457\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3432 - binary_accuracy: 0.8503\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8518\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8472\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3444 - binary_accuracy: 0.8480\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3268 - binary_accuracy: 0.8625\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8522\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8530\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3403 - binary_accuracy: 0.8514\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8491\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8488\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8472\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8602\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3414 - binary_accuracy: 0.8510\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8575\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3300 - binary_accuracy: 0.8522\n",
            "For the fold number  4 :\n",
            "loss =  0.3477938175201416 \n",
            "accuracy =  83.46666693687439 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.6756 - binary_accuracy: 0.6305\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5867 - binary_accuracy: 0.6922\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5598 - binary_accuracy: 0.7116\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5261 - binary_accuracy: 0.7448\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5169 - binary_accuracy: 0.7429\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4966 - binary_accuracy: 0.7627\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4885 - binary_accuracy: 0.7535\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4750 - binary_accuracy: 0.7680\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4721 - binary_accuracy: 0.7707\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4641 - binary_accuracy: 0.7703\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.7783\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4519 - binary_accuracy: 0.7813\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.7878\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.7825\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4290 - binary_accuracy: 0.7943\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4323 - binary_accuracy: 0.7920\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4206 - binary_accuracy: 0.8023\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4178 - binary_accuracy: 0.7989\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4167 - binary_accuracy: 0.7992\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4134 - binary_accuracy: 0.8030\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4075 - binary_accuracy: 0.8057\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4047 - binary_accuracy: 0.8088\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4049 - binary_accuracy: 0.8091\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4025 - binary_accuracy: 0.8099\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4043 - binary_accuracy: 0.8099\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3936 - binary_accuracy: 0.8198\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3915 - binary_accuracy: 0.8145\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3955 - binary_accuracy: 0.8164\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3922 - binary_accuracy: 0.8194\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3890 - binary_accuracy: 0.8190\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3875 - binary_accuracy: 0.8286\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3807 - binary_accuracy: 0.8194\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3784 - binary_accuracy: 0.8301\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3811 - binary_accuracy: 0.8274\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8168\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3752 - binary_accuracy: 0.8290\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8320\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3670 - binary_accuracy: 0.8282\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3651 - binary_accuracy: 0.8408\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3654 - binary_accuracy: 0.8320\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8358\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8301\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3599 - binary_accuracy: 0.8347\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3574 - binary_accuracy: 0.8366\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3657 - binary_accuracy: 0.8316\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8362\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8381\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_accuracy: 0.8370\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8370\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8411\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8381\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8392\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8415\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8419\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3472 - binary_accuracy: 0.8438\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3457 - binary_accuracy: 0.8442\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8389\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3432 - binary_accuracy: 0.8389\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8510\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3489 - binary_accuracy: 0.8469\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8533\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3359 - binary_accuracy: 0.8526\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3417 - binary_accuracy: 0.8453\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3374 - binary_accuracy: 0.8507\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3369 - binary_accuracy: 0.8408\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3390 - binary_accuracy: 0.8469\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_accuracy: 0.8461\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8396\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8530\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8472\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3310 - binary_accuracy: 0.8499\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3281 - binary_accuracy: 0.8522\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8530\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8495\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8552\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3293 - binary_accuracy: 0.8537\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3217 - binary_accuracy: 0.8556\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3273 - binary_accuracy: 0.8499\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3236 - binary_accuracy: 0.8476\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3198 - binary_accuracy: 0.8522\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3311 - binary_accuracy: 0.8537\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.8510\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8552\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3213 - binary_accuracy: 0.8598\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3226 - binary_accuracy: 0.8507\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3329 - binary_accuracy: 0.8484\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3249 - binary_accuracy: 0.8476\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8636\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3217 - binary_accuracy: 0.8537\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3179 - binary_accuracy: 0.8549\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3277 - binary_accuracy: 0.8556\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3251 - binary_accuracy: 0.8530\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3048 - binary_accuracy: 0.8613\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8579\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3222 - binary_accuracy: 0.8549\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3188 - binary_accuracy: 0.8568\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.8617\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3162 - binary_accuracy: 0.8629\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3190 - binary_accuracy: 0.8606\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3252 - binary_accuracy: 0.8590\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3192 - binary_accuracy: 0.8556\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3027 - binary_accuracy: 0.8632\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3202 - binary_accuracy: 0.8499\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3106 - binary_accuracy: 0.8526\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3201 - binary_accuracy: 0.8571\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3164 - binary_accuracy: 0.8526\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3188 - binary_accuracy: 0.8594\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3120 - binary_accuracy: 0.8644\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3169 - binary_accuracy: 0.8560\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3114 - binary_accuracy: 0.8606\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3267 - binary_accuracy: 0.8560\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.8522\n",
            "For the fold number  5 :\n",
            "loss =  0.3632751405239105 \n",
            "accuracy =  82.93333053588867 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7157 - binary_accuracy: 0.5490\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5804 - binary_accuracy: 0.7063\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5327 - binary_accuracy: 0.7387\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5073 - binary_accuracy: 0.7585\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4859 - binary_accuracy: 0.7710\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4735 - binary_accuracy: 0.7726\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4668 - binary_accuracy: 0.7653\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4584 - binary_accuracy: 0.7790\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4529 - binary_accuracy: 0.7802\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4448 - binary_accuracy: 0.7890\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4382 - binary_accuracy: 0.7890\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4410 - binary_accuracy: 0.7912\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4345 - binary_accuracy: 0.7981\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4213 - binary_accuracy: 0.8061\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8069\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4155 - binary_accuracy: 0.8038\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4106 - binary_accuracy: 0.8091\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4149 - binary_accuracy: 0.8065\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4097 - binary_accuracy: 0.8107\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4087 - binary_accuracy: 0.8126\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4122 - binary_accuracy: 0.8152\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3987 - binary_accuracy: 0.8179\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3995 - binary_accuracy: 0.8126\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3957 - binary_accuracy: 0.8164\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4036 - binary_accuracy: 0.8130\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3914 - binary_accuracy: 0.8198\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3937 - binary_accuracy: 0.8168\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8156\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3853 - binary_accuracy: 0.8270\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3875 - binary_accuracy: 0.8183\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3849 - binary_accuracy: 0.8194\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3914 - binary_accuracy: 0.8198\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8305\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3773 - binary_accuracy: 0.8301\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3742 - binary_accuracy: 0.8286\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3755 - binary_accuracy: 0.8328\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3774 - binary_accuracy: 0.8316\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8255\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3722 - binary_accuracy: 0.8305\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3668 - binary_accuracy: 0.8331\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3718 - binary_accuracy: 0.8286\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8381\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3603 - binary_accuracy: 0.8415\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3759 - binary_accuracy: 0.8377\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3651 - binary_accuracy: 0.8362\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3669 - binary_accuracy: 0.8320\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3713 - binary_accuracy: 0.8370\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_accuracy: 0.8370\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3559 - binary_accuracy: 0.8457\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_accuracy: 0.8411\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8362\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3560 - binary_accuracy: 0.8450\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3553 - binary_accuracy: 0.8415\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3536 - binary_accuracy: 0.8377\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3530 - binary_accuracy: 0.8430\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3603 - binary_accuracy: 0.8324\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3483 - binary_accuracy: 0.8427\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8400\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8457\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8491\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3490 - binary_accuracy: 0.8469\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3493 - binary_accuracy: 0.8430\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3491 - binary_accuracy: 0.8400\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_accuracy: 0.8472\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8514\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3410 - binary_accuracy: 0.8392\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8404\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3379 - binary_accuracy: 0.8430\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8507\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8488\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_accuracy: 0.8465\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3344 - binary_accuracy: 0.8472\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8537\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3383 - binary_accuracy: 0.8476\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8545\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8480\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3377 - binary_accuracy: 0.8450\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3337 - binary_accuracy: 0.8503\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3357 - binary_accuracy: 0.8495\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3347 - binary_accuracy: 0.8480\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8518\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3391 - binary_accuracy: 0.8465\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3328 - binary_accuracy: 0.8491\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3358 - binary_accuracy: 0.8507\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3323 - binary_accuracy: 0.8507\n",
            "For the fold number  6 :\n",
            "loss =  0.44708165526390076 \n",
            "accuracy =  81.06666803359985 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7756 - binary_accuracy: 0.5215\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6187 - binary_accuracy: 0.6625\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5859 - binary_accuracy: 0.6937\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5546 - binary_accuracy: 0.7242\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5373 - binary_accuracy: 0.7394\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5086 - binary_accuracy: 0.7570\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5022 - binary_accuracy: 0.7562\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4865 - binary_accuracy: 0.7646\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4873 - binary_accuracy: 0.7653\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4755 - binary_accuracy: 0.7760\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.7779\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4647 - binary_accuracy: 0.7802\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.7848\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4569 - binary_accuracy: 0.7806\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4429 - binary_accuracy: 0.7916\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.7897\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4333 - binary_accuracy: 0.7939\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4417 - binary_accuracy: 0.7970\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4313 - binary_accuracy: 0.7935\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4254 - binary_accuracy: 0.7973\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4297 - binary_accuracy: 0.7935\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4122 - binary_accuracy: 0.8069\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4121 - binary_accuracy: 0.8046\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4147 - binary_accuracy: 0.8019\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4082 - binary_accuracy: 0.8015\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4074 - binary_accuracy: 0.8091\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4104 - binary_accuracy: 0.8046\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4113 - binary_accuracy: 0.8057\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4005 - binary_accuracy: 0.8091\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3984 - binary_accuracy: 0.8141\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3905 - binary_accuracy: 0.8107\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3960 - binary_accuracy: 0.8164\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3955 - binary_accuracy: 0.8187\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3906 - binary_accuracy: 0.8248\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3936 - binary_accuracy: 0.8152\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8141\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3858 - binary_accuracy: 0.8202\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3871 - binary_accuracy: 0.8156\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8255\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3744 - binary_accuracy: 0.8263\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3785 - binary_accuracy: 0.8206\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8270\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3819 - binary_accuracy: 0.8217\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8240\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8305\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3741 - binary_accuracy: 0.8278\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3679 - binary_accuracy: 0.8282\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3689 - binary_accuracy: 0.8305\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3636 - binary_accuracy: 0.8290\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3647 - binary_accuracy: 0.8309\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3762 - binary_accuracy: 0.8270\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8293\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8328\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8385\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3563 - binary_accuracy: 0.8381\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8358\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3589 - binary_accuracy: 0.8335\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3635 - binary_accuracy: 0.8373\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_accuracy: 0.8389\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3619 - binary_accuracy: 0.8339\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_accuracy: 0.8358\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3529 - binary_accuracy: 0.8423\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8370\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3589 - binary_accuracy: 0.8389\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8366\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3499 - binary_accuracy: 0.8465\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_accuracy: 0.8389\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8415\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3486 - binary_accuracy: 0.8472\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3531 - binary_accuracy: 0.8411\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8488\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8434\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8461\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3484 - binary_accuracy: 0.8404\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3469 - binary_accuracy: 0.8354\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3414 - binary_accuracy: 0.8484\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3475 - binary_accuracy: 0.8408\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3435 - binary_accuracy: 0.8408\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8419\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3458 - binary_accuracy: 0.8408\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3295 - binary_accuracy: 0.8491\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8453\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3328 - binary_accuracy: 0.8484\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3319 - binary_accuracy: 0.8450\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3411 - binary_accuracy: 0.8450\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8423\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3441 - binary_accuracy: 0.8408\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3364 - binary_accuracy: 0.8488\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8438\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8507\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3419 - binary_accuracy: 0.8465\n",
            "For the fold number  7 :\n",
            "loss =  0.2966955602169037 \n",
            "accuracy =  88.26666474342346 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.6552 - binary_accuracy: 0.6400\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5822 - binary_accuracy: 0.7021\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5428 - binary_accuracy: 0.7299\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5106 - binary_accuracy: 0.7459\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4984 - binary_accuracy: 0.7547\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4799 - binary_accuracy: 0.7661\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4677 - binary_accuracy: 0.7726\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4521 - binary_accuracy: 0.7775\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4522 - binary_accuracy: 0.7821\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.7794\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4389 - binary_accuracy: 0.7863\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4398 - binary_accuracy: 0.7901\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4361 - binary_accuracy: 0.7928\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4248 - binary_accuracy: 0.7981\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4201 - binary_accuracy: 0.8008\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4196 - binary_accuracy: 0.8027\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4213 - binary_accuracy: 0.8027\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8076\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4117 - binary_accuracy: 0.8069\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4116 - binary_accuracy: 0.7989\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4027 - binary_accuracy: 0.8156\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4082 - binary_accuracy: 0.8076\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4025 - binary_accuracy: 0.8171\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3952 - binary_accuracy: 0.8194\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4012 - binary_accuracy: 0.8103\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3974 - binary_accuracy: 0.8145\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3944 - binary_accuracy: 0.8107\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3949 - binary_accuracy: 0.8198\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3924 - binary_accuracy: 0.8152\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3893 - binary_accuracy: 0.8187\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3829 - binary_accuracy: 0.8236\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3859 - binary_accuracy: 0.8190\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8236\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3833 - binary_accuracy: 0.8236\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8331\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3742 - binary_accuracy: 0.8331\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3804 - binary_accuracy: 0.8202\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8248\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3699 - binary_accuracy: 0.8305\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3748 - binary_accuracy: 0.8217\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3792 - binary_accuracy: 0.8198\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3786 - binary_accuracy: 0.8255\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3713 - binary_accuracy: 0.8320\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_accuracy: 0.8251\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8301\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3626 - binary_accuracy: 0.8377\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3623 - binary_accuracy: 0.8377\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_accuracy: 0.8290\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3677 - binary_accuracy: 0.8331\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.8297\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3625 - binary_accuracy: 0.8297\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3604 - binary_accuracy: 0.8446\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3579 - binary_accuracy: 0.8331\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8446\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8320\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3581 - binary_accuracy: 0.8370\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3516 - binary_accuracy: 0.8385\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3513 - binary_accuracy: 0.8427\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3484 - binary_accuracy: 0.8404\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8400\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3526 - binary_accuracy: 0.8385\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3554 - binary_accuracy: 0.8335\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8408\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8320\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8415\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3474 - binary_accuracy: 0.8469\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8469\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8415\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3409 - binary_accuracy: 0.8491\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8415\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8362\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8472\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8415\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3454 - binary_accuracy: 0.8457\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3330 - binary_accuracy: 0.8423\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3424 - binary_accuracy: 0.8366\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8530\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3406 - binary_accuracy: 0.8430\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3395 - binary_accuracy: 0.8503\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3386 - binary_accuracy: 0.8404\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3328 - binary_accuracy: 0.8518\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3337 - binary_accuracy: 0.8461\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3357 - binary_accuracy: 0.8533\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8453\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3338 - binary_accuracy: 0.8484\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3349 - binary_accuracy: 0.8495\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3292 - binary_accuracy: 0.8442\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3404 - binary_accuracy: 0.8419\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8510\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8568\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3304 - binary_accuracy: 0.8514\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8461\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3302 - binary_accuracy: 0.8507\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3254 - binary_accuracy: 0.8518\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3370 - binary_accuracy: 0.8484\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3309 - binary_accuracy: 0.8560\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8392\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8537\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3358 - binary_accuracy: 0.8518\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8518\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3320 - binary_accuracy: 0.8530\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8507\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3279 - binary_accuracy: 0.8541\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3250 - binary_accuracy: 0.8514\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.8526\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3182 - binary_accuracy: 0.8644\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3186 - binary_accuracy: 0.8568\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3297 - binary_accuracy: 0.8411\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3148 - binary_accuracy: 0.8606\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8575\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3178 - binary_accuracy: 0.8560\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8560\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8510\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3227 - binary_accuracy: 0.8480\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3106 - binary_accuracy: 0.8632\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3181 - binary_accuracy: 0.8560\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3220 - binary_accuracy: 0.8530\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3160 - binary_accuracy: 0.8549\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3258 - binary_accuracy: 0.8530\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3018 - binary_accuracy: 0.8602\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3095 - binary_accuracy: 0.8644\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3098 - binary_accuracy: 0.8632\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3221 - binary_accuracy: 0.8480\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3138 - binary_accuracy: 0.8583\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3154 - binary_accuracy: 0.8568\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3086 - binary_accuracy: 0.8594\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3064 - binary_accuracy: 0.8632\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3103 - binary_accuracy: 0.8632\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3095 - binary_accuracy: 0.8632\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3141 - binary_accuracy: 0.8575\n",
            "For the fold number  8 :\n",
            "loss =  0.3356168270111084 \n",
            "accuracy =  88.26666474342346 %\n",
            "\n",
            "\n",
            "\n",
            "Doing the run number  5\n",
            "Training the fold number  1 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7081 - binary_accuracy: 0.6000\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5984 - binary_accuracy: 0.7010\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5469 - binary_accuracy: 0.7333\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5210 - binary_accuracy: 0.7486\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4933 - binary_accuracy: 0.7630\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4865 - binary_accuracy: 0.7615\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4750 - binary_accuracy: 0.7764\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4622 - binary_accuracy: 0.7722\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4650 - binary_accuracy: 0.7749\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.7886\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4399 - binary_accuracy: 0.7958\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4410 - binary_accuracy: 0.7909\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4295 - binary_accuracy: 0.7928\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.7989\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4236 - binary_accuracy: 0.8023\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4118 - binary_accuracy: 0.8122\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4176 - binary_accuracy: 0.8050\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4156 - binary_accuracy: 0.8046\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4089 - binary_accuracy: 0.8114\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4052 - binary_accuracy: 0.8198\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4098 - binary_accuracy: 0.8149\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8107\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3983 - binary_accuracy: 0.8160\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3940 - binary_accuracy: 0.8213\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3940 - binary_accuracy: 0.8175\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3897 - binary_accuracy: 0.8183\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3942 - binary_accuracy: 0.8183\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3963 - binary_accuracy: 0.8190\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3897 - binary_accuracy: 0.8183\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3909 - binary_accuracy: 0.8194\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3902 - binary_accuracy: 0.8122\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8324\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3870 - binary_accuracy: 0.8251\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8301\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3798 - binary_accuracy: 0.8240\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3723 - binary_accuracy: 0.8267\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3714 - binary_accuracy: 0.8301\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3680 - binary_accuracy: 0.8389\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3687 - binary_accuracy: 0.8343\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3722 - binary_accuracy: 0.8274\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3637 - binary_accuracy: 0.8358\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3728 - binary_accuracy: 0.8331\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3710 - binary_accuracy: 0.8244\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3714 - binary_accuracy: 0.8290\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3699 - binary_accuracy: 0.8328\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8270\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3559 - binary_accuracy: 0.8427\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3624 - binary_accuracy: 0.8389\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3578 - binary_accuracy: 0.8385\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8396\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3564 - binary_accuracy: 0.8389\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3577 - binary_accuracy: 0.8392\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3697 - binary_accuracy: 0.8335\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8461\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3540 - binary_accuracy: 0.8373\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3495 - binary_accuracy: 0.8385\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8404\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3511 - binary_accuracy: 0.8350\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3459 - binary_accuracy: 0.8442\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8381\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3455 - binary_accuracy: 0.8408\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3396 - binary_accuracy: 0.8484\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3420 - binary_accuracy: 0.8518\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_accuracy: 0.8434\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3464 - binary_accuracy: 0.8366\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3498 - binary_accuracy: 0.8392\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3455 - binary_accuracy: 0.8423\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8385\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8446\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3413 - binary_accuracy: 0.8434\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3320 - binary_accuracy: 0.8549\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3325 - binary_accuracy: 0.8522\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3468 - binary_accuracy: 0.8335\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3426 - binary_accuracy: 0.8423\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8411\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8442\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3375 - binary_accuracy: 0.8507\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3250 - binary_accuracy: 0.8484\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8392\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8438\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3392 - binary_accuracy: 0.8457\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3396 - binary_accuracy: 0.8510\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3349 - binary_accuracy: 0.8503\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3348 - binary_accuracy: 0.8541\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3261 - binary_accuracy: 0.8533\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3318 - binary_accuracy: 0.8568\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8453\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8514\n",
            "For the fold number  1 :\n",
            "loss =  0.39561036229133606 \n",
            "accuracy =  82.13333487510681 %\n",
            "Training the fold number  2 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 2ms/step - loss: 0.6714 - binary_accuracy: 0.6465\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5875 - binary_accuracy: 0.7090\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5463 - binary_accuracy: 0.7284\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5251 - binary_accuracy: 0.7432\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5039 - binary_accuracy: 0.7520\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5012 - binary_accuracy: 0.7547\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4844 - binary_accuracy: 0.7737\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4739 - binary_accuracy: 0.7779\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4686 - binary_accuracy: 0.7829\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4553 - binary_accuracy: 0.7802\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.7874\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4504 - binary_accuracy: 0.7825\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4414 - binary_accuracy: 0.7943\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4403 - binary_accuracy: 0.7947\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4389 - binary_accuracy: 0.7954\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.8019\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4322 - binary_accuracy: 0.8004\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8057\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4171 - binary_accuracy: 0.8072\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4108 - binary_accuracy: 0.8099\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4075 - binary_accuracy: 0.8110\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4090 - binary_accuracy: 0.8225\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4096 - binary_accuracy: 0.8122\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4040 - binary_accuracy: 0.8179\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4016 - binary_accuracy: 0.8137\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3999 - binary_accuracy: 0.8164\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3968 - binary_accuracy: 0.8183\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3948 - binary_accuracy: 0.8202\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3987 - binary_accuracy: 0.8141\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3938 - binary_accuracy: 0.8225\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3925 - binary_accuracy: 0.8270\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3863 - binary_accuracy: 0.8244\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3910 - binary_accuracy: 0.8240\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3830 - binary_accuracy: 0.8286\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3830 - binary_accuracy: 0.8225\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3799 - binary_accuracy: 0.8305\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3839 - binary_accuracy: 0.8221\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3872 - binary_accuracy: 0.8248\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3766 - binary_accuracy: 0.8297\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3736 - binary_accuracy: 0.8339\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8347\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8301\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3713 - binary_accuracy: 0.8309\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3709 - binary_accuracy: 0.8362\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8286\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3676 - binary_accuracy: 0.8301\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8373\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3652 - binary_accuracy: 0.8343\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3584 - binary_accuracy: 0.8389\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3648 - binary_accuracy: 0.8389\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3575 - binary_accuracy: 0.8438\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3595 - binary_accuracy: 0.8350\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8419\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3555 - binary_accuracy: 0.8328\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3531 - binary_accuracy: 0.8392\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3500 - binary_accuracy: 0.8366\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3528 - binary_accuracy: 0.8427\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8343\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3427 - binary_accuracy: 0.8495\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8408\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3378 - binary_accuracy: 0.8469\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8415\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_accuracy: 0.8446\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_accuracy: 0.8392\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_accuracy: 0.8404\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3391 - binary_accuracy: 0.8465\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8419\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8446\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3318 - binary_accuracy: 0.8461\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3404 - binary_accuracy: 0.8400\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3403 - binary_accuracy: 0.8430\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3447 - binary_accuracy: 0.8400\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8450\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3308 - binary_accuracy: 0.8476\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3293 - binary_accuracy: 0.8541\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3409 - binary_accuracy: 0.8446\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3351 - binary_accuracy: 0.8575\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3369 - binary_accuracy: 0.8472\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3266 - binary_accuracy: 0.8476\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8495\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8469\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3288 - binary_accuracy: 0.8507\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3324 - binary_accuracy: 0.8522\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3253 - binary_accuracy: 0.8545\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3290 - binary_accuracy: 0.8518\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3310 - binary_accuracy: 0.8507\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3239 - binary_accuracy: 0.8552\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8530\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3236 - binary_accuracy: 0.8510\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3208 - binary_accuracy: 0.8590\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3238 - binary_accuracy: 0.8526\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3212 - binary_accuracy: 0.8552\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3206 - binary_accuracy: 0.8598\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3246 - binary_accuracy: 0.8530\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3263 - binary_accuracy: 0.8533\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3186 - binary_accuracy: 0.8590\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3133 - binary_accuracy: 0.8625\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3209 - binary_accuracy: 0.8560\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8537\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3270 - binary_accuracy: 0.8518\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3193 - binary_accuracy: 0.8617\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3176 - binary_accuracy: 0.8617\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3170 - binary_accuracy: 0.8587\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3179 - binary_accuracy: 0.8541\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3149 - binary_accuracy: 0.8617\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3191 - binary_accuracy: 0.8594\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3228 - binary_accuracy: 0.8518\n",
            "For the fold number  2 :\n",
            "loss =  0.3134097754955292 \n",
            "accuracy =  84.79999899864197 %\n",
            "Training the fold number  3 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.8274 - binary_accuracy: 0.5204\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.6195 - binary_accuracy: 0.6644\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5504 - binary_accuracy: 0.7173\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5187 - binary_accuracy: 0.7379\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5006 - binary_accuracy: 0.7474\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4925 - binary_accuracy: 0.7604\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4918 - binary_accuracy: 0.7577\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.7722\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.7775\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4639 - binary_accuracy: 0.7806\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4511 - binary_accuracy: 0.7802\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4456 - binary_accuracy: 0.7916\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4474 - binary_accuracy: 0.7901\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.7943\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4390 - binary_accuracy: 0.7916\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4303 - binary_accuracy: 0.7928\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4248 - binary_accuracy: 0.8046\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4236 - binary_accuracy: 0.8095\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4245 - binary_accuracy: 0.8008\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8072\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4169 - binary_accuracy: 0.8088\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4107 - binary_accuracy: 0.8088\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4088 - binary_accuracy: 0.8156\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4053 - binary_accuracy: 0.8202\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4033 - binary_accuracy: 0.8152\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8160\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4023 - binary_accuracy: 0.8198\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4028 - binary_accuracy: 0.8130\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4022 - binary_accuracy: 0.8160\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3923 - binary_accuracy: 0.8202\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3953 - binary_accuracy: 0.8206\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3909 - binary_accuracy: 0.8259\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3863 - binary_accuracy: 0.8251\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3819 - binary_accuracy: 0.8328\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8290\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3822 - binary_accuracy: 0.8255\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3927 - binary_accuracy: 0.8251\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3828 - binary_accuracy: 0.8267\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3921 - binary_accuracy: 0.8248\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3863 - binary_accuracy: 0.8293\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3773 - binary_accuracy: 0.8301\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3730 - binary_accuracy: 0.8366\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3767 - binary_accuracy: 0.8305\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3782 - binary_accuracy: 0.8278\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_accuracy: 0.8362\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3734 - binary_accuracy: 0.8290\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3700 - binary_accuracy: 0.8350\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3728 - binary_accuracy: 0.8331\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3765 - binary_accuracy: 0.8263\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3675 - binary_accuracy: 0.8274\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3766 - binary_accuracy: 0.8251\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_accuracy: 0.8350\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3604 - binary_accuracy: 0.8423\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3689 - binary_accuracy: 0.8381\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3678 - binary_accuracy: 0.8347\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3673 - binary_accuracy: 0.8396\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3603 - binary_accuracy: 0.8415\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8339\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3635 - binary_accuracy: 0.8358\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3771 - binary_accuracy: 0.8339\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_accuracy: 0.8324\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3633 - binary_accuracy: 0.8404\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3545 - binary_accuracy: 0.8438\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8411\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3555 - binary_accuracy: 0.8373\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8427\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8392\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3673 - binary_accuracy: 0.8408\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3573 - binary_accuracy: 0.8328\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_accuracy: 0.8335\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3508 - binary_accuracy: 0.8373\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3502 - binary_accuracy: 0.8484\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3517 - binary_accuracy: 0.8430\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3556 - binary_accuracy: 0.8427\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8472\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8442\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3583 - binary_accuracy: 0.8442\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8465\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3401 - binary_accuracy: 0.8499\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3425 - binary_accuracy: 0.8480\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8480\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3452 - binary_accuracy: 0.8366\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8389\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3514 - binary_accuracy: 0.8408\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3476 - binary_accuracy: 0.8427\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8484\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3395 - binary_accuracy: 0.8450\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8461\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8457\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3427 - binary_accuracy: 0.8434\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8472\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3336 - binary_accuracy: 0.8469\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3326 - binary_accuracy: 0.8491\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8450\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3406 - binary_accuracy: 0.8461\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3340 - binary_accuracy: 0.8522\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3423 - binary_accuracy: 0.8408\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3311 - binary_accuracy: 0.8575\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3386 - binary_accuracy: 0.8469\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3360 - binary_accuracy: 0.8507\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3368 - binary_accuracy: 0.8503\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3336 - binary_accuracy: 0.8507\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3304 - binary_accuracy: 0.8541\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3388 - binary_accuracy: 0.8484\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3366 - binary_accuracy: 0.8442\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8469\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8526\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3310 - binary_accuracy: 0.8476\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3353 - binary_accuracy: 0.8510\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3299 - binary_accuracy: 0.8472\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3241 - binary_accuracy: 0.8556\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3237 - binary_accuracy: 0.8549\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3312 - binary_accuracy: 0.8476\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3351 - binary_accuracy: 0.8423\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3356 - binary_accuracy: 0.8423\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3229 - binary_accuracy: 0.8552\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3195 - binary_accuracy: 0.8541\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3209 - binary_accuracy: 0.8514\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3190 - binary_accuracy: 0.8549\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8590\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3180 - binary_accuracy: 0.8613\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3262 - binary_accuracy: 0.8514\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_accuracy: 0.8510\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3144 - binary_accuracy: 0.8537\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3146 - binary_accuracy: 0.8640\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8579\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3166 - binary_accuracy: 0.8560\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3232 - binary_accuracy: 0.8560\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3218 - binary_accuracy: 0.8568\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3132 - binary_accuracy: 0.8545\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3114 - binary_accuracy: 0.8613\n",
            "Epoch 132/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3182 - binary_accuracy: 0.8575\n",
            "Epoch 133/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3222 - binary_accuracy: 0.8530\n",
            "Epoch 134/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3195 - binary_accuracy: 0.8625\n",
            "Epoch 135/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3177 - binary_accuracy: 0.8560\n",
            "Epoch 136/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3113 - binary_accuracy: 0.8610\n",
            "Epoch 137/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3199 - binary_accuracy: 0.8533\n",
            "Epoch 138/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3120 - binary_accuracy: 0.8571\n",
            "Epoch 139/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3100 - binary_accuracy: 0.8590\n",
            "Epoch 140/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8545\n",
            "Epoch 141/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3163 - binary_accuracy: 0.8598\n",
            "Epoch 142/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3084 - binary_accuracy: 0.8621\n",
            "Epoch 143/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3143 - binary_accuracy: 0.8606\n",
            "Epoch 144/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3112 - binary_accuracy: 0.8568\n",
            "Epoch 145/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3261 - binary_accuracy: 0.8484\n",
            "Epoch 146/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3218 - binary_accuracy: 0.8587\n",
            "Epoch 147/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3102 - binary_accuracy: 0.8583\n",
            "Epoch 148/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3232 - binary_accuracy: 0.8594\n",
            "Epoch 149/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3084 - binary_accuracy: 0.8640\n",
            "Epoch 150/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3121 - binary_accuracy: 0.8575\n",
            "Epoch 151/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3071 - binary_accuracy: 0.8613\n",
            "Epoch 152/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3131 - binary_accuracy: 0.8549\n",
            "Epoch 153/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3113 - binary_accuracy: 0.8594\n",
            "Epoch 154/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3093 - binary_accuracy: 0.8583\n",
            "Epoch 155/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3078 - binary_accuracy: 0.8663\n",
            "Epoch 156/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3084 - binary_accuracy: 0.8571\n",
            "Epoch 157/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3043 - binary_accuracy: 0.8602\n",
            "Epoch 158/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3137 - binary_accuracy: 0.8617\n",
            "Epoch 159/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3135 - binary_accuracy: 0.8632\n",
            "Epoch 160/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3059 - binary_accuracy: 0.8640\n",
            "For the fold number  3 :\n",
            "loss =  0.34541624784469604 \n",
            "accuracy =  85.33333539962769 %\n",
            "Training the fold number  4 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7358 - binary_accuracy: 0.5897\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5993 - binary_accuracy: 0.6964\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5512 - binary_accuracy: 0.7288\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5250 - binary_accuracy: 0.7375\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5070 - binary_accuracy: 0.7474\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4873 - binary_accuracy: 0.7566\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4733 - binary_accuracy: 0.7749\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4582 - binary_accuracy: 0.7764\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.7752\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4363 - binary_accuracy: 0.7939\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4384 - binary_accuracy: 0.7977\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4282 - binary_accuracy: 0.7962\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4279 - binary_accuracy: 0.7962\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8030\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8053\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4085 - binary_accuracy: 0.8156\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4099 - binary_accuracy: 0.8110\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4077 - binary_accuracy: 0.8084\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3944 - binary_accuracy: 0.8187\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3998 - binary_accuracy: 0.8225\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4036 - binary_accuracy: 0.8141\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3990 - binary_accuracy: 0.8156\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3944 - binary_accuracy: 0.8194\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3899 - binary_accuracy: 0.8259\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3836 - binary_accuracy: 0.8240\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3870 - binary_accuracy: 0.8278\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3869 - binary_accuracy: 0.8282\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3859 - binary_accuracy: 0.8297\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3880 - binary_accuracy: 0.8297\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3774 - binary_accuracy: 0.8297\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3810 - binary_accuracy: 0.8290\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3748 - binary_accuracy: 0.8324\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3760 - binary_accuracy: 0.8320\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3784 - binary_accuracy: 0.8301\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8362\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3705 - binary_accuracy: 0.8339\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8343\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3708 - binary_accuracy: 0.8354\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3614 - binary_accuracy: 0.8430\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3656 - binary_accuracy: 0.8343\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3653 - binary_accuracy: 0.8347\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3558 - binary_accuracy: 0.8396\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3674 - binary_accuracy: 0.8305\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3594 - binary_accuracy: 0.8404\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8396\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8385\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3502 - binary_accuracy: 0.8411\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3507 - binary_accuracy: 0.8442\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_accuracy: 0.8343\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8408\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3532 - binary_accuracy: 0.8446\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3512 - binary_accuracy: 0.8423\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3542 - binary_accuracy: 0.8461\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3511 - binary_accuracy: 0.8442\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8404\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3472 - binary_accuracy: 0.8495\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_accuracy: 0.8461\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3470 - binary_accuracy: 0.8465\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3348 - binary_accuracy: 0.8545\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3503 - binary_accuracy: 0.8404\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3436 - binary_accuracy: 0.8510\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3346 - binary_accuracy: 0.8522\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3432 - binary_accuracy: 0.8453\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8510\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8476\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3409 - binary_accuracy: 0.8465\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8507\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8476\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3331 - binary_accuracy: 0.8514\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3346 - binary_accuracy: 0.8503\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3353 - binary_accuracy: 0.8453\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3331 - binary_accuracy: 0.8465\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8510\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3416 - binary_accuracy: 0.8461\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3315 - binary_accuracy: 0.8491\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3368 - binary_accuracy: 0.8450\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3283 - binary_accuracy: 0.8518\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3349 - binary_accuracy: 0.8564\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3242 - binary_accuracy: 0.8533\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3281 - binary_accuracy: 0.8522\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3242 - binary_accuracy: 0.8556\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3240 - binary_accuracy: 0.8518\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3297 - binary_accuracy: 0.8484\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3273 - binary_accuracy: 0.8522\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3136 - binary_accuracy: 0.8610\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3330 - binary_accuracy: 0.8556\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3244 - binary_accuracy: 0.8579\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3192 - binary_accuracy: 0.8552\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3329 - binary_accuracy: 0.8491\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3341 - binary_accuracy: 0.8476\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3152 - binary_accuracy: 0.8613\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3164 - binary_accuracy: 0.8636\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3256 - binary_accuracy: 0.8499\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3218 - binary_accuracy: 0.8533\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3278 - binary_accuracy: 0.8518\n",
            "For the fold number  4 :\n",
            "loss =  0.3384353518486023 \n",
            "accuracy =  84.79999899864197 %\n",
            "Training the fold number  5 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 5ms/step - loss: 0.6740 - binary_accuracy: 0.5893\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5710 - binary_accuracy: 0.7082\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5252 - binary_accuracy: 0.7288\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5125 - binary_accuracy: 0.7490\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4903 - binary_accuracy: 0.7550\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4807 - binary_accuracy: 0.7733\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4746 - binary_accuracy: 0.7779\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4606 - binary_accuracy: 0.7794\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4500 - binary_accuracy: 0.7848\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4374 - binary_accuracy: 0.7928\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4367 - binary_accuracy: 0.7901\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4327 - binary_accuracy: 0.7939\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4337 - binary_accuracy: 0.8019\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4245 - binary_accuracy: 0.8004\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4161 - binary_accuracy: 0.8091\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4163 - binary_accuracy: 0.8038\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8107\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4117 - binary_accuracy: 0.8145\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4110 - binary_accuracy: 0.8122\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4070 - binary_accuracy: 0.8133\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4034 - binary_accuracy: 0.8179\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3973 - binary_accuracy: 0.8183\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3895 - binary_accuracy: 0.8202\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3919 - binary_accuracy: 0.8286\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3928 - binary_accuracy: 0.8210\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3918 - binary_accuracy: 0.8179\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3883 - binary_accuracy: 0.8248\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3863 - binary_accuracy: 0.8251\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3841 - binary_accuracy: 0.8293\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3880 - binary_accuracy: 0.8217\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3743 - binary_accuracy: 0.8400\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3825 - binary_accuracy: 0.8221\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3754 - binary_accuracy: 0.8358\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3798 - binary_accuracy: 0.8210\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3767 - binary_accuracy: 0.8328\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3712 - binary_accuracy: 0.8370\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3779 - binary_accuracy: 0.8290\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3688 - binary_accuracy: 0.8377\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3740 - binary_accuracy: 0.8358\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3737 - binary_accuracy: 0.8328\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3692 - binary_accuracy: 0.8335\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3671 - binary_accuracy: 0.8350\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3656 - binary_accuracy: 0.8339\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_accuracy: 0.8373\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3686 - binary_accuracy: 0.8354\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3622 - binary_accuracy: 0.8373\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_accuracy: 0.8347\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3554 - binary_accuracy: 0.8453\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3586 - binary_accuracy: 0.8396\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3644 - binary_accuracy: 0.8347\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3649 - binary_accuracy: 0.8350\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3593 - binary_accuracy: 0.8419\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3470 - binary_accuracy: 0.8510\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3491 - binary_accuracy: 0.8480\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3581 - binary_accuracy: 0.8423\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3563 - binary_accuracy: 0.8396\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8411\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3497 - binary_accuracy: 0.8503\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8411\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3544 - binary_accuracy: 0.8404\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3483 - binary_accuracy: 0.8476\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3459 - binary_accuracy: 0.8495\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8533\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3483 - binary_accuracy: 0.8465\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8446\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3412 - binary_accuracy: 0.8457\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3442 - binary_accuracy: 0.8457\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3445 - binary_accuracy: 0.8461\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8480\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3389 - binary_accuracy: 0.8530\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3464 - binary_accuracy: 0.8465\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3488 - binary_accuracy: 0.8404\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3428 - binary_accuracy: 0.8514\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3468 - binary_accuracy: 0.8472\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3431 - binary_accuracy: 0.8499\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3361 - binary_accuracy: 0.8472\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3402 - binary_accuracy: 0.8560\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8438\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3340 - binary_accuracy: 0.8537\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3375 - binary_accuracy: 0.8450\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3419 - binary_accuracy: 0.8457\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3372 - binary_accuracy: 0.8495\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3330 - binary_accuracy: 0.8514\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3399 - binary_accuracy: 0.8396\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3283 - binary_accuracy: 0.8564\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3352 - binary_accuracy: 0.8503\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3380 - binary_accuracy: 0.8476\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3354 - binary_accuracy: 0.8499\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8472\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3272 - binary_accuracy: 0.8541\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3323 - binary_accuracy: 0.8545\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3273 - binary_accuracy: 0.8507\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3267 - binary_accuracy: 0.8564\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3194 - binary_accuracy: 0.8636\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3321 - binary_accuracy: 0.8526\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3236 - binary_accuracy: 0.8549\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3183 - binary_accuracy: 0.8602\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8541\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3325 - binary_accuracy: 0.8488\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3268 - binary_accuracy: 0.8556\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3305 - binary_accuracy: 0.8499\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3307 - binary_accuracy: 0.8484\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3214 - binary_accuracy: 0.8602\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3195 - binary_accuracy: 0.8571\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.8552\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8610\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3216 - binary_accuracy: 0.8552\n",
            "For the fold number  5 :\n",
            "loss =  0.3612295687198639 \n",
            "accuracy =  83.46666693687439 %\n",
            "Training the fold number  6 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.5737 - binary_accuracy: 0.7105\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5283 - binary_accuracy: 0.7288\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5044 - binary_accuracy: 0.7474\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4784 - binary_accuracy: 0.7665\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4769 - binary_accuracy: 0.7710\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.7779\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4496 - binary_accuracy: 0.7810\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4434 - binary_accuracy: 0.7882\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4420 - binary_accuracy: 0.7836\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4343 - binary_accuracy: 0.7977\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4330 - binary_accuracy: 0.7966\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4209 - binary_accuracy: 0.8076\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.7985\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4166 - binary_accuracy: 0.8046\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4110 - binary_accuracy: 0.8084\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3986 - binary_accuracy: 0.8156\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.4040 - binary_accuracy: 0.8130\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.8183\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3912 - binary_accuracy: 0.8183\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3907 - binary_accuracy: 0.8160\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3957 - binary_accuracy: 0.8107\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3861 - binary_accuracy: 0.8259\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8244\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3868 - binary_accuracy: 0.8255\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_accuracy: 0.8251\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3773 - binary_accuracy: 0.8251\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3777 - binary_accuracy: 0.8175\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_accuracy: 0.8309\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3770 - binary_accuracy: 0.8309\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3742 - binary_accuracy: 0.8286\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3688 - binary_accuracy: 0.8309\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3609 - binary_accuracy: 0.8331\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3691 - binary_accuracy: 0.8324\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3635 - binary_accuracy: 0.8392\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8362\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3650 - binary_accuracy: 0.8350\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3569 - binary_accuracy: 0.8366\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3595 - binary_accuracy: 0.8411\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3599 - binary_accuracy: 0.8362\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3608 - binary_accuracy: 0.8347\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3677 - binary_accuracy: 0.8305\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3577 - binary_accuracy: 0.8324\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3524 - binary_accuracy: 0.8381\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3473 - binary_accuracy: 0.8450\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3568 - binary_accuracy: 0.8381\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3481 - binary_accuracy: 0.8411\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8366\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3477 - binary_accuracy: 0.8465\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3521 - binary_accuracy: 0.8411\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8400\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3437 - binary_accuracy: 0.8450\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3420 - binary_accuracy: 0.8453\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3466 - binary_accuracy: 0.8488\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3448 - binary_accuracy: 0.8442\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3438 - binary_accuracy: 0.8389\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3485 - binary_accuracy: 0.8415\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3383 - binary_accuracy: 0.8472\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_accuracy: 0.8423\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3322 - binary_accuracy: 0.8545\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3429 - binary_accuracy: 0.8370\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3382 - binary_accuracy: 0.8461\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3357 - binary_accuracy: 0.8549\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3383 - binary_accuracy: 0.8457\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3362 - binary_accuracy: 0.8469\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3345 - binary_accuracy: 0.8465\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3391 - binary_accuracy: 0.8453\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3300 - binary_accuracy: 0.8552\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3329 - binary_accuracy: 0.8510\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3328 - binary_accuracy: 0.8453\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3387 - binary_accuracy: 0.8404\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8575\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3238 - binary_accuracy: 0.8564\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3308 - binary_accuracy: 0.8507\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3187 - binary_accuracy: 0.8552\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3222 - binary_accuracy: 0.8560\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3317 - binary_accuracy: 0.8465\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3210 - binary_accuracy: 0.8522\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8457\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3185 - binary_accuracy: 0.8568\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3143 - binary_accuracy: 0.8613\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3167 - binary_accuracy: 0.8571\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3206 - binary_accuracy: 0.8514\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3220 - binary_accuracy: 0.8598\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3093 - binary_accuracy: 0.8632\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.8526\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3186 - binary_accuracy: 0.8594\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3207 - binary_accuracy: 0.8507\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3276 - binary_accuracy: 0.8514\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3112 - binary_accuracy: 0.8625\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3108 - binary_accuracy: 0.8594\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3107 - binary_accuracy: 0.8583\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3155 - binary_accuracy: 0.8610\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3149 - binary_accuracy: 0.8590\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3188 - binary_accuracy: 0.8518\n",
            "For the fold number  6 :\n",
            "loss =  0.3955414593219757 \n",
            "accuracy =  84.26666855812073 %\n",
            "Training the fold number  7 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.6461 - binary_accuracy: 0.6362\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5573 - binary_accuracy: 0.7250\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5214 - binary_accuracy: 0.7349\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4994 - binary_accuracy: 0.7589\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4899 - binary_accuracy: 0.7623\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4691 - binary_accuracy: 0.7760\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4617 - binary_accuracy: 0.7810\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.7802\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4455 - binary_accuracy: 0.7844\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.7931\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.7924\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4408 - binary_accuracy: 0.7954\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4329 - binary_accuracy: 0.7989\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4244 - binary_accuracy: 0.8076\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4197 - binary_accuracy: 0.8084\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4195 - binary_accuracy: 0.8069\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4283 - binary_accuracy: 0.8046\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4143 - binary_accuracy: 0.8072\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4178 - binary_accuracy: 0.8027\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8038\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4036 - binary_accuracy: 0.8152\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4033 - binary_accuracy: 0.8141\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3988 - binary_accuracy: 0.8103\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4082 - binary_accuracy: 0.8080\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3910 - binary_accuracy: 0.8190\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3922 - binary_accuracy: 0.8156\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3935 - binary_accuracy: 0.8171\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3884 - binary_accuracy: 0.8168\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_accuracy: 0.8190\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3877 - binary_accuracy: 0.8210\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3858 - binary_accuracy: 0.8255\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3845 - binary_accuracy: 0.8210\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3910 - binary_accuracy: 0.8221\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3840 - binary_accuracy: 0.8255\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3860 - binary_accuracy: 0.8217\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3746 - binary_accuracy: 0.8305\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_accuracy: 0.8236\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3735 - binary_accuracy: 0.8282\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3735 - binary_accuracy: 0.8286\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3731 - binary_accuracy: 0.8232\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3692 - binary_accuracy: 0.8282\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3720 - binary_accuracy: 0.8240\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3615 - binary_accuracy: 0.8282\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3760 - binary_accuracy: 0.8217\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3611 - binary_accuracy: 0.8377\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3596 - binary_accuracy: 0.8419\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3621 - binary_accuracy: 0.8343\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3672 - binary_accuracy: 0.8274\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3606 - binary_accuracy: 0.8347\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3669 - binary_accuracy: 0.8278\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3523 - binary_accuracy: 0.8377\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3461 - binary_accuracy: 0.8396\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3551 - binary_accuracy: 0.8415\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3490 - binary_accuracy: 0.8381\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3520 - binary_accuracy: 0.8377\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8366\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3461 - binary_accuracy: 0.8438\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3549 - binary_accuracy: 0.8370\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3509 - binary_accuracy: 0.8430\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3504 - binary_accuracy: 0.8331\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3497 - binary_accuracy: 0.8423\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3422 - binary_accuracy: 0.8503\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3415 - binary_accuracy: 0.8476\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_accuracy: 0.8450\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3363 - binary_accuracy: 0.8446\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3324 - binary_accuracy: 0.8461\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3332 - binary_accuracy: 0.8491\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3378 - binary_accuracy: 0.8457\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3333 - binary_accuracy: 0.8461\n",
            "Epoch 70/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3327 - binary_accuracy: 0.8514\n",
            "Epoch 71/160\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.3320 - binary_accuracy: 0.8526\n",
            "Epoch 72/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3430 - binary_accuracy: 0.8415\n",
            "Epoch 73/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8526\n",
            "Epoch 74/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3308 - binary_accuracy: 0.8472\n",
            "Epoch 75/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3384 - binary_accuracy: 0.8484\n",
            "Epoch 76/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3378 - binary_accuracy: 0.8442\n",
            "Epoch 77/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3339 - binary_accuracy: 0.8476\n",
            "Epoch 78/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_accuracy: 0.8423\n",
            "Epoch 79/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3290 - binary_accuracy: 0.8465\n",
            "Epoch 80/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3233 - binary_accuracy: 0.8503\n",
            "Epoch 81/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3229 - binary_accuracy: 0.8541\n",
            "Epoch 82/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3281 - binary_accuracy: 0.8522\n",
            "Epoch 83/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3295 - binary_accuracy: 0.8469\n",
            "Epoch 84/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3356 - binary_accuracy: 0.8457\n",
            "Epoch 85/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3301 - binary_accuracy: 0.8533\n",
            "Epoch 86/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3231 - binary_accuracy: 0.8568\n",
            "Epoch 87/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3164 - binary_accuracy: 0.8571\n",
            "Epoch 88/160\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.3190 - binary_accuracy: 0.8556\n",
            "Epoch 89/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3229 - binary_accuracy: 0.8552\n",
            "Epoch 90/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3255 - binary_accuracy: 0.8552\n",
            "Epoch 91/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3175 - binary_accuracy: 0.8556\n",
            "Epoch 92/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3245 - binary_accuracy: 0.8568\n",
            "Epoch 93/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3266 - binary_accuracy: 0.8537\n",
            "Epoch 94/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3215 - binary_accuracy: 0.8549\n",
            "Epoch 95/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3225 - binary_accuracy: 0.8541\n",
            "Epoch 96/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3235 - binary_accuracy: 0.8522\n",
            "Epoch 97/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3145 - binary_accuracy: 0.8602\n",
            "Epoch 98/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3180 - binary_accuracy: 0.8549\n",
            "Epoch 99/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3122 - binary_accuracy: 0.8522\n",
            "Epoch 100/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3190 - binary_accuracy: 0.8579\n",
            "Epoch 101/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3158 - binary_accuracy: 0.8617\n",
            "Epoch 102/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3091 - binary_accuracy: 0.8587\n",
            "Epoch 103/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3117 - binary_accuracy: 0.8625\n",
            "Epoch 104/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3129 - binary_accuracy: 0.8598\n",
            "Epoch 105/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3103 - binary_accuracy: 0.8560\n",
            "Epoch 106/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3110 - binary_accuracy: 0.8587\n",
            "Epoch 107/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3061 - binary_accuracy: 0.8663\n",
            "Epoch 108/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3132 - binary_accuracy: 0.8610\n",
            "Epoch 109/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3098 - binary_accuracy: 0.8571\n",
            "Epoch 110/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3097 - binary_accuracy: 0.8606\n",
            "Epoch 111/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3134 - binary_accuracy: 0.8621\n",
            "Epoch 112/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3116 - binary_accuracy: 0.8564\n",
            "Epoch 113/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3153 - binary_accuracy: 0.8575\n",
            "Epoch 114/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3108 - binary_accuracy: 0.8625\n",
            "Epoch 115/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3167 - binary_accuracy: 0.8575\n",
            "Epoch 116/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3060 - binary_accuracy: 0.8579\n",
            "Epoch 117/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3024 - binary_accuracy: 0.8629\n",
            "Epoch 118/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3084 - binary_accuracy: 0.8571\n",
            "Epoch 119/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3005 - binary_accuracy: 0.8701\n",
            "Epoch 120/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3014 - binary_accuracy: 0.8625\n",
            "Epoch 121/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2947 - binary_accuracy: 0.8747\n",
            "Epoch 122/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2984 - binary_accuracy: 0.8709\n",
            "Epoch 123/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.2975 - binary_accuracy: 0.8667\n",
            "Epoch 124/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3022 - binary_accuracy: 0.8587\n",
            "Epoch 125/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3017 - binary_accuracy: 0.8606\n",
            "Epoch 126/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3077 - binary_accuracy: 0.8606\n",
            "Epoch 127/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3074 - binary_accuracy: 0.8613\n",
            "Epoch 128/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3047 - binary_accuracy: 0.8682\n",
            "Epoch 129/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3019 - binary_accuracy: 0.8670\n",
            "Epoch 130/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3012 - binary_accuracy: 0.8644\n",
            "Epoch 131/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3027 - binary_accuracy: 0.8625\n",
            "For the fold number  7 :\n",
            "loss =  0.31815284490585327 \n",
            "accuracy =  85.33333539962769 %\n",
            "Training the fold number  8 \n",
            "\n",
            "Epoch 1/160\n",
            "83/83 [==============================] - 1s 3ms/step - loss: 0.7289 - binary_accuracy: 0.5749\n",
            "Epoch 2/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5887 - binary_accuracy: 0.6971\n",
            "Epoch 3/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.5280 - binary_accuracy: 0.7440\n",
            "Epoch 4/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.5102 - binary_accuracy: 0.7550\n",
            "Epoch 5/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4952 - binary_accuracy: 0.7547\n",
            "Epoch 6/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4869 - binary_accuracy: 0.7653\n",
            "Epoch 7/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4758 - binary_accuracy: 0.7756\n",
            "Epoch 8/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4671 - binary_accuracy: 0.7707\n",
            "Epoch 9/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4533 - binary_accuracy: 0.7840\n",
            "Epoch 10/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4543 - binary_accuracy: 0.7840\n",
            "Epoch 11/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.7836\n",
            "Epoch 12/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4490 - binary_accuracy: 0.7897\n",
            "Epoch 13/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4367 - binary_accuracy: 0.7939\n",
            "Epoch 14/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4345 - binary_accuracy: 0.7947\n",
            "Epoch 15/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4334 - binary_accuracy: 0.7901\n",
            "Epoch 16/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4193 - binary_accuracy: 0.8061\n",
            "Epoch 17/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4290 - binary_accuracy: 0.8057\n",
            "Epoch 18/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4210 - binary_accuracy: 0.8030\n",
            "Epoch 19/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4156 - binary_accuracy: 0.8110\n",
            "Epoch 20/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.4117 - binary_accuracy: 0.8141\n",
            "Epoch 21/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4092 - binary_accuracy: 0.8084\n",
            "Epoch 22/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4083 - binary_accuracy: 0.8126\n",
            "Epoch 23/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4051 - binary_accuracy: 0.8164\n",
            "Epoch 24/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4082 - binary_accuracy: 0.8122\n",
            "Epoch 25/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3968 - binary_accuracy: 0.8118\n",
            "Epoch 26/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.4045 - binary_accuracy: 0.8164\n",
            "Epoch 27/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3994 - binary_accuracy: 0.8175\n",
            "Epoch 28/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3901 - binary_accuracy: 0.8244\n",
            "Epoch 29/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3954 - binary_accuracy: 0.8118\n",
            "Epoch 30/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3978 - binary_accuracy: 0.8130\n",
            "Epoch 31/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3909 - binary_accuracy: 0.8145\n",
            "Epoch 32/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3928 - binary_accuracy: 0.8267\n",
            "Epoch 33/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3848 - binary_accuracy: 0.8236\n",
            "Epoch 34/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3909 - binary_accuracy: 0.8198\n",
            "Epoch 35/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3884 - binary_accuracy: 0.8274\n",
            "Epoch 36/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3788 - binary_accuracy: 0.8248\n",
            "Epoch 37/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3825 - binary_accuracy: 0.8293\n",
            "Epoch 38/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3836 - binary_accuracy: 0.8316\n",
            "Epoch 39/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3765 - binary_accuracy: 0.8316\n",
            "Epoch 40/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3812 - binary_accuracy: 0.8305\n",
            "Epoch 41/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3711 - binary_accuracy: 0.8343\n",
            "Epoch 42/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3845 - binary_accuracy: 0.8198\n",
            "Epoch 43/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3712 - binary_accuracy: 0.8335\n",
            "Epoch 44/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3722 - binary_accuracy: 0.8263\n",
            "Epoch 45/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3711 - binary_accuracy: 0.8335\n",
            "Epoch 46/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3705 - binary_accuracy: 0.8362\n",
            "Epoch 47/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3703 - binary_accuracy: 0.8255\n",
            "Epoch 48/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3656 - binary_accuracy: 0.8343\n",
            "Epoch 49/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3653 - binary_accuracy: 0.8328\n",
            "Epoch 50/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3630 - binary_accuracy: 0.8350\n",
            "Epoch 51/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3562 - binary_accuracy: 0.8396\n",
            "Epoch 52/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3600 - binary_accuracy: 0.8362\n",
            "Epoch 53/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3589 - binary_accuracy: 0.8362\n",
            "Epoch 54/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3625 - binary_accuracy: 0.8343\n",
            "Epoch 55/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3495 - binary_accuracy: 0.8450\n",
            "Epoch 56/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3544 - binary_accuracy: 0.8453\n",
            "Epoch 57/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3561 - binary_accuracy: 0.8366\n",
            "Epoch 58/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_accuracy: 0.8347\n",
            "Epoch 59/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3459 - binary_accuracy: 0.8495\n",
            "Epoch 60/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3594 - binary_accuracy: 0.8370\n",
            "Epoch 61/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3520 - binary_accuracy: 0.8415\n",
            "Epoch 62/160\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.3581 - binary_accuracy: 0.8476\n",
            "Epoch 63/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_accuracy: 0.8389\n",
            "Epoch 64/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3538 - binary_accuracy: 0.8362\n",
            "Epoch 65/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3462 - binary_accuracy: 0.8419\n",
            "Epoch 66/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3556 - binary_accuracy: 0.8377\n",
            "Epoch 67/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_accuracy: 0.8484\n",
            "Epoch 68/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3465 - binary_accuracy: 0.8339\n",
            "Epoch 69/160\n",
            "83/83 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_accuracy: 0.8396\n",
            "For the fold number  8 :\n",
            "loss =  0.3460891842842102 \n",
            "accuracy =  83.46666693687439 %\n",
            "\n",
            "\n",
            "\n",
            "We obtain the following results:\n",
            "mean accuracy:  84.11333322525024 % \n",
            "mean loss: 0.35342724025249483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Pg15xQ16-SCR"
      }
    }
  ]
}